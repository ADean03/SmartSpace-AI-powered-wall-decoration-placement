{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDoP29gKE0CdylfqsG3KiM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ADean03/SmartSpace-AI-powered-wall-decoration-placement/blob/main/wallseg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "#from models.models import SegmentationModule, build_encoder, build_decoder\n",
        "#from src.eval import segment_image\n",
        "#from utils.constants import DEVICE\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from tqdm import tqdm  # progress bar\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "import torchvision.ops as ops"
      ],
      "metadata": {
        "id": "rCM31zM0BuxR"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRt483sFDD3R",
        "outputId": "cf65833e-8e3c-4932-e45e-440c46bbe4e3"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.ops as ops\n",
        "from torchmetrics.detection import IntersectionOverUnion"
      ],
      "metadata": {
        "id": "sQ1CBfTQDCnr"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7NmqSFNG3c4",
        "outputId": "ac7bfbdf-1416-4de9-d1bd-66aef3217f15"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ADean03/WallSegmentation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXcGq_ckILeB",
        "outputId": "44791161-1de8-4e4f-fe46-f9ed0a7f07df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WallSegmentation'...\n",
            "remote: Enumerating objects: 356, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 356 (delta 32), reused 45 (delta 14), pack-reused 271 (from 1)\u001b[K\n",
            "Receiving objects: 100% (356/356), 84.54 MiB | 18.93 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd WallSegmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPZSbGwTIRyh",
        "outputId": "4997822d-71b0-475c-f404-41c4ddc97b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/WallSegmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFBlHAPUIc8q",
        "outputId": "e80fc232-b65f-4f16-c9b7-1a16de4b2716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mckpt\u001b[0m/     LICENSE         README.md              \u001b[01;34msrc\u001b[0m/             \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mconfigs\u001b[0m/  \u001b[01;34mmodels\u001b[0m/         \u001b[01;34mreadme_supplementary\u001b[0m/  testing.ipynb\n",
            "\u001b[01;34mdata\u001b[0m/     \u001b[01;34mmodel_weights\u001b[0m/  requirements.txt       train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIC-0RKPIrvu",
        "outputId": "18eb9be8-7db4-4247-f19b-bfb46d39e044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 4)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 4)) (3.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 4)) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 4)) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYqiNeOrGGcS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "72806850-db4d-4067-bd96-3d7adc760592"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'models'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3871591071.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSegmentationModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegment_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from models.models import SegmentationModule, build_encoder, build_decoder\n",
        "from src.eval import segment_image\n",
        "from utils.constants import DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_path = '/content/drive/My Drive/SmartSpace'\n",
        "os.listdir('/content/drive/MyDrive/SmartSpace')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq0kS52_IvKo",
        "outputId": "55d15590-2f27-44e6-b535-ce473d66823e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wallsegWeights',\n",
              " 'homeobjects-3K',\n",
              " 'visualizations',\n",
              " 'YOLOWeights',\n",
              " 'Copy of how-to-train-ultralytics-yolo-on-homeobjects-dataset.ipynb',\n",
              " 'PaintingPredictor.ipynb',\n",
              " 'wallseg.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing getting segmented image"
      ],
      "metadata": {
        "id": "Joy04UpULIjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/SmartSpace/homeobjects-3K/images/train/living_room_1p (133).jpg'\n",
        "print(os.path.exists(file_path))\n",
        "#os.listdir('/content/drive/My Drive/SmartSpace/homeobjects-3K/images/train/living_room_1p (133).jpg')\n",
        "#os.listdir('/content/drive/MyDrive/SmartSpace/wallsegWeights')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSDtVkTCLSsw",
        "outputId": "a80f5bf3-0074-4cbf-b00d-71ecae49f750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_image = file_path\n",
        "\n",
        "# Model weights (encoder and decoder)\n",
        "weights_encoder = '/content/drive/MyDrive/SmartSpace/wallsegWeights/best_encoder_epoch_19.pth'\n",
        "weights_decoder = '/content/drive/MyDrive/SmartSpace/wallsegWeights/best_decoder_epoch_19.pth'"
      ],
      "metadata": {
        "id": "tbtlA0RIM_oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_encoder = build_encoder(weights_encoder)\n",
        "net_decoder = build_decoder(weights_decoder)\n",
        "\n",
        "segmentation_module = SegmentationModule(net_encoder, net_decoder)\n",
        "segmentation_module = segmentation_module.to(DEVICE).eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnfkOxlSOS1r",
        "outputId": "53728254-6261-4bff-e2c4-4888dd872bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder: resnet50-dilated\n",
            "Loading weights for net_encoder\n",
            "Loading weights for net_decoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation_mask = segment_image(segmentation_module, path_image)"
      ],
      "metadata": {
        "id": "IwYAxLKxOaMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(segmentation_mask)\n",
        "plt.axis('off')        # hides the x/y axis\n",
        "plt.tight_layout()     # removes padding\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "XDgL_JsEQHNh",
        "outputId": "852c82a9-38f4-489a-c5a1-92f6389b93f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image above was testing generating a binary wall/not mask. Ultimately this approach was not used as the not-wall mask has the painting/picture frames clearly outlined and while could theoritically could be removed based off existing bounding box data, simpiler approach would be to just predict based off bounding boxes"
      ],
      "metadata": {
        "id": "A4t580Vn6Mdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(segmentation_mask))\n",
        "print(segmentation_mask.shape)\n",
        "print(segmentation_mask.min(), segmentation_mask.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iduzatZKSS6V",
        "outputId": "e0240c11-c8bb-4f97-d24a-03b8806d3bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(853, 1280)\n",
            "0 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "label_dir = '/content/drive/My Drive/SmartSpace/homeobjects-3K/labels/train'\n",
        "\n",
        "train_paintings_per_file = []  # list to store how many paintings are in each file\n",
        "\n",
        "for label_file in os.listdir(label_dir):\n",
        "    if not label_file.endswith('.txt'):\n",
        "        continue\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        count_paintings = 0\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            if len(parts) == 0:\n",
        "                continue\n",
        "            class_id = int(parts[0])\n",
        "            if class_id == 11:\n",
        "                count_paintings += 1\n",
        "\n",
        "        if count_paintings > 0:\n",
        "            train_paintings_per_file.append(count_paintings)\n",
        "\n",
        "train_num_files_with_paintings = len(train_paintings_per_file)\n",
        "train_total_paintings = sum(train_paintings_per_file)\n",
        "train_avg_paintings_per_file = train_total_paintings / train_num_files_with_paintings if train_num_files_with_paintings > 0 else 0\n",
        "\n",
        "print(f\"Found {train_num_files_with_paintings} images with paintings\")\n",
        "print(f\"Average number of paintings per such image: {train_avg_paintings_per_file:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RdMSOMNVJVX",
        "outputId": "9421656c-7b84-4f07-e3ce-6a74c4b0fb1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1062 images with paintings\n",
            "Average number of paintings per such image: 2.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "label_dir = '/content/drive/My Drive/SmartSpace/homeobjects-3K/labels/val'\n",
        "\n",
        "val_paintings_per_file = []  # list to store how many paintings are in each file\n",
        "\n",
        "for label_file in os.listdir(label_dir):\n",
        "    if not label_file.endswith('.txt'):\n",
        "        continue\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        count_paintings = 0\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            if len(parts) == 0:\n",
        "                continue\n",
        "            class_id = int(parts[0])\n",
        "            if class_id == 11:\n",
        "                count_paintings += 1\n",
        "\n",
        "        if count_paintings > 0:\n",
        "            val_paintings_per_file.append(count_paintings)\n",
        "\n",
        "val_num_files_with_paintings = len(val_paintings_per_file)\n",
        "val_total_paintings = sum(val_paintings_per_file)\n",
        "val_avg_paintings_per_file = val_total_paintings / val_num_files_with_paintings if val_num_files_with_paintings > 0 else 0\n",
        "\n",
        "print(f\"Found {val_num_files_with_paintings} images with paintings\")\n",
        "print(f\"Average number of paintings per such image: {val_avg_paintings_per_file:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvgJ97Y0UIRk",
        "outputId": "5647daa9-207a-493e-e560-8ba7d974a7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 211 images with paintings\n",
            "Average number of paintings per such image: 2.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Paths\n",
        "base_dir = '/content/drive/My Drive/SmartSpace/homeobjects-3K/labels'\n",
        "val_input_dir = os.path.join(base_dir, 'val_input')\n",
        "val_input_aug_dir = os.path.join(base_dir, 'val_input_aug')\n",
        "\n",
        "# Create the output folder if it doesnt exist\n",
        "os.makedirs(val_input_aug_dir, exist_ok=True)\n",
        "\n",
        "for label_file in os.listdir(val_input_dir):\n",
        "    if not label_file.endswith('.txt'):\n",
        "        continue\n",
        "\n",
        "    file_path = os.path.join(val_input_dir, label_file)\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = [l.strip() for l in f.readlines() if l.strip()]\n",
        "\n",
        "    # Separate class 11 and other objects\n",
        "    class11_lines = [l for l in lines if l.split()[0] == '11']\n",
        "    other_lines = [l for l in lines if l.split()[0] != '11']\n",
        "\n",
        "    # 1 Overwrite the original file (in val_input) with all class 11s removed\n",
        "    with open(file_path, 'w') as f:\n",
        "        for line in other_lines:\n",
        "            f.write(line + '\\n')\n",
        "\n",
        "    # 2 If more than 2 paintings, create an augmented copy in val_input_aug\n",
        "    if len(class11_lines) > 2:\n",
        "        num_to_keep = random.randint(1, len(class11_lines) - 1)\n",
        "        kept_class11 = random.sample(class11_lines, num_to_keep)\n",
        "\n",
        "        new_lines = other_lines + kept_class11\n",
        "        random.shuffle(new_lines)  # optional\n",
        "\n",
        "        new_filename = label_file.replace('.txt', '_aug.txt')\n",
        "        new_file_path = os.path.join(val_input_aug_dir, new_filename)\n",
        "\n",
        "        with open(new_file_path, 'w') as f:\n",
        "            for line in new_lines:\n",
        "                f.write(line + '\\n')\n",
        "\n",
        "        print(f\"Created augmented file: {new_filename} (kept {num_to_keep} of {len(class11_lines)})\")\n",
        "\n",
        "print(\" Finished cleaning val_input and creating val_input_aug.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqTn1PnjIRRv",
        "outputId": "b567c302-eec1-45b2-edcc-ba6448372e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created augmented file: living_room_1p (143)_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1p (365)_aug.txt (kept 3 of 7)\n",
            "Created augmented file: living_room_1p (218)_aug.txt (kept 5 of 8)\n",
            "Created augmented file: living_room_1p (169)_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1p (260)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (353)_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1p (131)_aug.txt (kept 5 of 6)\n",
            "Created augmented file: living_room_1p (164)_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_1p (160)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (272)_aug.txt (kept 1 of 5)\n",
            "Created augmented file: living_room_1p (35)_aug.txt (kept 1 of 7)\n",
            "Created augmented file: living_room_1p (412)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (3)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (374)_aug.txt (kept 2 of 6)\n",
            "Created augmented file: living_room_1p (101)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (439)_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1p (314)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (209)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_180_aug.txt (kept 6 of 13)\n",
            "Created augmented file: living_room_107_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_115_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1012_aug.txt (kept 6 of 7)\n",
            "Created augmented file: living_room_1024_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_160_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1082_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1036_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1072_aug.txt (kept 4 of 10)\n",
            "Created augmented file: living_room_987_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_971_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_975_aug.txt (kept 14 of 19)\n",
            "Created augmented file: living_room_896_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_892_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_805_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_954_aug.txt (kept 15 of 17)\n",
            "Created augmented file: living_room_82_aug.txt (kept 8 of 9)\n",
            "Created augmented file: living_room_958_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_801_aug.txt (kept 6 of 7)\n",
            "Created augmented file: living_room_760_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_768_aug.txt (kept 8 of 9)\n",
            "Created augmented file: living_room_744_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_728_aug.txt (kept 3 of 7)\n",
            "Created augmented file: living_room_908_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_74_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_627_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_598_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_62_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_570_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_46_aug.txt (kept 3 of 7)\n",
            "Created augmented file: living_room_542_aug.txt (kept 4 of 6)\n",
            "Created augmented file: living_room_50_aug.txt (kept 3 of 6)\n",
            "Created augmented file: living_room_404_aug.txt (kept 4 of 6)\n",
            "Created augmented file: living_room_408_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_550_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_323_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_311_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_266_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_392_aug.txt (kept 8 of 10)\n",
            "Created augmented file: living_room_1p (97)_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_278_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_270_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_42_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1p (93)_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_282_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_262_aug.txt (kept 5 of 6)\n",
            "Created augmented file: living_room_1p (64)_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1p (469)_aug.txt (kept 6 of 7)\n",
            "Created augmented file: living_room_1p (501)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (597)_aug.txt (kept 1 of 5)\n",
            "Created augmented file: living_room_1p (52)_aug.txt (kept 2 of 6)\n",
            "Created augmented file: living_room_1p (546)_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1p (56)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (514)_aug.txt (kept 2 of 8)\n",
            "Created augmented file: living_room_1p (584)_aug.txt (kept 3 of 4)\n",
            " Finished cleaning val_input and creating val_input_aug.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LeC0SOTuPivs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "base_dir = '/content/drive/My Drive/SmartSpace/homeobjects-3K/labels'\n",
        "train_input_dir = os.path.join(base_dir, 'train_input')\n",
        "train_input_aug_dir = os.path.join(base_dir, 'train_input_aug')\n",
        "\n",
        "# Create the output folder if it doesnt exist\n",
        "os.makedirs(train_input_aug_dir, exist_ok=True)\n",
        "\n",
        "for label_file in os.listdir(train_input_dir):\n",
        "    if not label_file.endswith('.txt'):\n",
        "        continue\n",
        "\n",
        "    file_path = os.path.join(train_input_dir, label_file)\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = [l.strip() for l in f.readlines() if l.strip()]\n",
        "\n",
        "    # Separate class 11 and other objects\n",
        "    class11_lines = [l for l in lines if l.split()[0] == '11']\n",
        "    other_lines = [l for l in lines if l.split()[0] != '11']\n",
        "\n",
        "    # 1 Overwrite the original file (in train_input) with all class 11s removed\n",
        "    with open(file_path, 'w') as f:\n",
        "        for line in other_lines:\n",
        "            f.write(line + '\\n')\n",
        "\n",
        "    # 2 If more than 2 paintings, create an augmented copy in train_input_aug\n",
        "    if len(class11_lines) > 2:\n",
        "        num_to_keep = random.randint(1, len(class11_lines) - 1)\n",
        "        kept_class11 = random.sample(class11_lines, num_to_keep)\n",
        "\n",
        "        new_lines = other_lines + kept_class11\n",
        "        random.shuffle(new_lines)  # optional\n",
        "\n",
        "        new_filename = label_file.replace('.txt', '_aug.txt')\n",
        "        new_file_path = os.path.join(train_input_aug_dir, new_filename)\n",
        "\n",
        "        with open(new_file_path, 'w') as f:\n",
        "            for line in new_lines:\n",
        "                f.write(line + '\\n')\n",
        "\n",
        "        print(f\"Created augmented file: {new_filename} (kept {num_to_keep} of {len(class11_lines)})\")\n",
        "\n",
        "print(\" Finished cleaning train_input and creating train_input_aug.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46234674-d1c6-423c-df09-fd5a5e35b966",
        "id": "r_Zn6ymRPn3h"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created augmented file: living_room_1320_aug.txt (kept 7 of 8)\n",
            "Created augmented file: living_room_1237_aug.txt (kept 4 of 11)\n",
            "Created augmented file: living_room_13_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_133_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_1303_aug.txt (kept 6 of 13)\n",
            "Created augmented file: living_room_1302_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1291_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_134_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1256_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_1257_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1228_aug.txt (kept 6 of 7)\n",
            "Created augmented file: living_room_1211_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1214_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_121_aug.txt (kept 5 of 7)\n",
            "Created augmented file: living_room_1208_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1192_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_1204_aug.txt (kept 2 of 6)\n",
            "Created augmented file: living_room_1216_aug.txt (kept 7 of 10)\n",
            "Created augmented file: living_room_1235_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1149_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1155_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_1132_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1166_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1138_aug.txt (kept 8 of 9)\n",
            "Created augmented file: living_room_1158_aug.txt (kept 17 of 22)\n",
            "Created augmented file: living_room_1167_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1151_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1152_aug.txt (kept 12 of 14)\n",
            "Created augmented file: living_room_1128_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1109_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_1130_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_106_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1159_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1056_aug.txt (kept 8 of 9)\n",
            "Created augmented file: living_room_1102_aug.txt (kept 2 of 7)\n",
            "Created augmented file: living_room_1137_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1143_aug.txt (kept 4 of 19)\n",
            "Created augmented file: living_room_114_aug.txt (kept 8 of 10)\n",
            "Created augmented file: living_room_1157_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1083_aug.txt (kept 7 of 12)\n",
            "Created augmented file: living_room_1096_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1108_aug.txt (kept 3 of 7)\n",
            "Created augmented file: living_room_1111_aug.txt (kept 4 of 6)\n",
            "Created augmented file: living_room_109_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1062_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_108_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1090_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1030_aug.txt (kept 3 of 21)\n",
            "Created augmented file: living_room_1005_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_101_aug.txt (kept 2 of 8)\n",
            "Created augmented file: living_room_1011_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1010_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1626_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1659_aug.txt (kept 4 of 6)\n",
            "Created augmented file: living_room_1622_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_159_aug.txt (kept 3 of 7)\n",
            "Created augmented file: living_room_1580_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1630_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1562_aug.txt (kept 1 of 5)\n",
            "Created augmented file: living_room_1603_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1602_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1608_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1593_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_1557_aug.txt (kept 3 of 8)\n",
            "Created augmented file: living_room_1507_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1512_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_1474_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1503_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_1539_aug.txt (kept 8 of 10)\n",
            "Created augmented file: living_room_154_aug.txt (kept 1 of 5)\n",
            "Created augmented file: living_room_1447_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1470_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1448_aug.txt (kept 4 of 9)\n",
            "Created augmented file: living_room_1457_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1465_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_149_aug.txt (kept 5 of 6)\n",
            "Created augmented file: living_room_1410_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1468_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1390_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1391_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_1435_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1421_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1400_aug.txt (kept 6 of 8)\n",
            "Created augmented file: living_room_1395_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1428_aug.txt (kept 1 of 12)\n",
            "Created augmented file: living_room_1344_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1380_aug.txt (kept 6 of 8)\n",
            "Created augmented file: living_room_1379_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1366_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1369_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1405_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_136_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1358_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1382_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1342_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1p (343)_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1p (44)_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1p (418)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (445)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (41)_aug.txt (kept 3 of 13)\n",
            "Created augmented file: living_room_1p (40)_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1p (358)_aug.txt (kept 3 of 7)\n",
            "Created augmented file: living_room_1p (45)_aug.txt (kept 1 of 5)\n",
            "Created augmented file: living_room_1p (421)_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_1p (359)_aug.txt (kept 5 of 6)\n",
            "Created augmented file: living_room_1p (352)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (402)_aug.txt (kept 5 of 8)\n",
            "Created augmented file: living_room_1p (355)_aug.txt (kept 4 of 12)\n",
            "Created augmented file: living_room_1p (424)_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1p (461)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (446)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (398)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (375)_aug.txt (kept 1 of 6)\n",
            "Created augmented file: living_room_1p (219)_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_1p (31)_aug.txt (kept 4 of 11)\n",
            "Created augmented file: living_room_1p (334)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (312)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (202)_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_1p (317)_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1p (342)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (329)_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1p (332)_aug.txt (kept 7 of 11)\n",
            "Created augmented file: living_room_1p (257)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (267)_aug.txt (kept 2 of 7)\n",
            "Created augmented file: living_room_1p (281)_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1p (299)_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_1p (255)_aug.txt (kept 3 of 7)\n",
            "Created augmented file: living_room_1p (186)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (195)_aug.txt (kept 11 of 15)\n",
            "Created augmented file: living_room_1p (300)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (241)_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_1p (278)_aug.txt (kept 10 of 15)\n",
            "Created augmented file: living_room_1p (176)_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1p (109)_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1p (132)_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_1p (244)_aug.txt (kept 6 of 7)\n",
            "Created augmented file: living_room_1p (180)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (17)_aug.txt (kept 1 of 6)\n",
            "Created augmented file: living_room_1p (141)_aug.txt (kept 4 of 7)\n",
            "Created augmented file: living_room_1p (210)_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1p (194)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (220)_aug.txt (kept 1 of 7)\n",
            "Created augmented file: living_room_1p (262)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1963_aug.txt (kept 3 of 6)\n",
            "Created augmented file: living_room_1p (136)_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_197_aug.txt (kept 1 of 6)\n",
            "Created augmented file: living_room_1p (1)_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1971_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_198_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1960_aug.txt (kept 4 of 7)\n",
            "Created augmented file: living_room_1953_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (161)_aug.txt (kept 1 of 6)\n",
            "Created augmented file: living_room_1p (133)_aug.txt (kept 7 of 8)\n",
            "Created augmented file: living_room_1958_aug.txt (kept 8 of 11)\n",
            "Created augmented file: living_room_1921_aug.txt (kept 3 of 6)\n",
            "Created augmented file: living_room_1911_aug.txt (kept 3 of 6)\n",
            "Created augmented file: living_room_191_aug.txt (kept 4 of 6)\n",
            "Created augmented file: living_room_1897_aug.txt (kept 2 of 6)\n",
            "Created augmented file: living_room_1948_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_1903_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1885_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_185_aug.txt (kept 3 of 6)\n",
            "Created augmented file: living_room_1783_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_183_aug.txt (kept 1 of 7)\n",
            "Created augmented file: living_room_1804_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1809_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_186_aug.txt (kept 2 of 9)\n",
            "Created augmented file: living_room_1806_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_177_aug.txt (kept 2 of 6)\n",
            "Created augmented file: living_room_1802_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1764_aug.txt (kept 1 of 6)\n",
            "Created augmented file: living_room_1827_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1788_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_1782_aug.txt (kept 3 of 6)\n",
            "Created augmented file: living_room_1719_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1721_aug.txt (kept 2 of 16)\n",
            "Created augmented file: living_room_1717_aug.txt (kept 2 of 6)\n",
            "Created augmented file: living_room_1735_aug.txt (kept 3 of 10)\n",
            "Created augmented file: living_room_1700_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_1677_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_1688_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_293_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_317_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (539)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_284_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1p (547)_aug.txt (kept 1 of 5)\n",
            "Created augmented file: living_room_271_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_353_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_316_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_385_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_302_aug.txt (kept 3 of 7)\n",
            "Created augmented file: living_room_352_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_268_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_31_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_32_aug.txt (kept 8 of 12)\n",
            "Created augmented file: living_room_236_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_354_aug.txt (kept 6 of 8)\n",
            "Created augmented file: living_room_232_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (91)_aug.txt (kept 4 of 7)\n",
            "Created augmented file: living_room_28_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_337_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_251_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_225_aug.txt (kept 2 of 6)\n",
            "Created augmented file: living_room_1p (59)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_285_aug.txt (kept 1 of 5)\n",
            "Created augmented file: living_room_368_aug.txt (kept 3 of 15)\n",
            "Created augmented file: living_room_273_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_29_aug.txt (kept 4 of 6)\n",
            "Created augmented file: living_room_252_aug.txt (kept 5 of 8)\n",
            "Created augmented file: living_room_1p (73)_aug.txt (kept 2 of 6)\n",
            "Created augmented file: living_room_1p (526)_aug.txt (kept 4 of 6)\n",
            "Created augmented file: living_room_1p (585)_aug.txt (kept 2 of 6)\n",
            "Created augmented file: living_room_1p (86)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (517)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_1p (506)_aug.txt (kept 3 of 8)\n",
            "Created augmented file: living_room_1p (507)_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_1p (530)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (61)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (84)_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_1p (590)_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_1p (516)_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_1p (555)_aug.txt (kept 1 of 6)\n",
            "Created augmented file: living_room_1p (57)_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_1p (499)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_1p (87)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_84_aug.txt (kept 3 of 12)\n",
            "Created augmented file: living_room_606_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_665_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_676_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_802_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_705_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_672_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_616_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_572_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_656_aug.txt (kept 1 of 8)\n",
            "Created augmented file: living_room_80_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_604_aug.txt (kept 5 of 6)\n",
            "Created augmented file: living_room_695_aug.txt (kept 1 of 5)\n",
            "Created augmented file: living_room_71_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_516_aug.txt (kept 4 of 6)\n",
            "Created augmented file: living_room_646_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_798_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_491_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_680_aug.txt (kept 1 of 6)\n",
            "Created augmented file: living_room_664_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_762_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_697_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_65_aug.txt (kept 6 of 11)\n",
            "Created augmented file: living_room_499_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_561_aug.txt (kept 3 of 5)\n",
            "Created augmented file: living_room_759_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_507_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_650_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_811_aug.txt (kept 21 of 22)\n",
            "Created augmented file: living_room_709_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_820_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_59_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_608_aug.txt (kept 5 of 9)\n",
            "Created augmented file: living_room_535_aug.txt (kept 2 of 7)\n",
            "Created augmented file: living_room_549_aug.txt (kept 3 of 6)\n",
            "Created augmented file: living_room_430_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_49_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_406_aug.txt (kept 1 of 4)\n",
            "Created augmented file: living_room_418_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_520_aug.txt (kept 2 of 4)\n",
            "Created augmented file: living_room_427_aug.txt (kept 4 of 16)\n",
            "Created augmented file: living_room_443_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_525_aug.txt (kept 3 of 6)\n",
            "Created augmented file: living_room_464_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_423_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_477_aug.txt (kept 3 of 9)\n",
            "Created augmented file: living_room_485_aug.txt (kept 1 of 5)\n",
            "Created augmented file: living_room_529_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_402_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_435_aug.txt (kept 1 of 4)\n",
            "Created augmented file: s (349)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: s (233)_aug.txt (kept 5 of 9)\n",
            "Created augmented file: s (385)_aug.txt (kept 3 of 5)\n",
            "Created augmented file: s (238)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: s (320)_aug.txt (kept 1 of 4)\n",
            "Created augmented file: s (350)_aug.txt (kept 6 of 8)\n",
            "Created augmented file: s (324)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: s (327)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: s (247)_aug.txt (kept 4 of 5)\n",
            "Created augmented file: s (27)_aug.txt (kept 2 of 4)\n",
            "Created augmented file: s (325)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: s (159)_aug.txt (kept 2 of 6)\n",
            "Created augmented file: s (70)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: s (323)_aug.txt (kept 3 of 4)\n",
            "Created augmented file: s (2)_aug.txt (kept 3 of 5)\n",
            "Created augmented file: s (295)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: s (237)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: s (294)_aug.txt (kept 6 of 13)\n",
            "Created augmented file: s (360)_aug.txt (kept 1 of 4)\n",
            "Created augmented file: s (5)_aug.txt (kept 1 of 3)\n",
            "Created augmented file: s (19)_aug.txt (kept 2 of 5)\n",
            "Created augmented file: living_room_89_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_849_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_885_aug.txt (kept 3 of 6)\n",
            "Created augmented file: living_room_925_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_95_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_9_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_935_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_957_aug.txt (kept 1 of 6)\n",
            "Created augmented file: living_room_891_aug.txt (kept 5 of 7)\n",
            "Created augmented file: s (135)_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_871_aug.txt (kept 1 of 3)\n",
            "Created augmented file: living_room_949_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_886_aug.txt (kept 4 of 6)\n",
            "Created augmented file: living_room_942_aug.txt (kept 1 of 13)\n",
            "Created augmented file: living_room_861_aug.txt (kept 2 of 3)\n",
            "Created augmented file: living_room_918_aug.txt (kept 3 of 4)\n",
            "Created augmented file: living_room_986_aug.txt (kept 19 of 24)\n",
            "Created augmented file: living_room_874_aug.txt (kept 4 of 5)\n",
            "Created augmented file: living_room_953_aug.txt (kept 9 of 22)\n",
            "Created augmented file: living_room_994_aug.txt (kept 1 of 4)\n",
            " Finished cleaning train_input and creating train_input_aug.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model traing"
      ],
      "metadata": {
        "id": "4FaiadAPglhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels\"\n",
        "\n",
        "train_input_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels/train_input\"\n",
        "train_input_aug_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels/train_input_aug\"\n",
        "val_input_dir   = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels/val_input\"\n",
        "val_input_aug_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels/val_input_aug\"\n",
        "train_target_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels/train\"\n",
        "val_target_dir   = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels/val\""
      ],
      "metadata": {
        "id": "FPVOtHuAo2dg"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from tqdm import tqdm  # progress bar\n",
        "\n",
        "def load_labels(path):\n",
        "    \"\"\"Load bounding boxes from a YOLO-format label file.\"\"\"\n",
        "    boxes = []\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                if len(parts) > 0:\n",
        "                    print(f\" Skipped bad line in {path}: {parts}\")\n",
        "                continue\n",
        "            cls, xc, yc, w, h = map(float, parts)\n",
        "            boxes.append([int(cls), xc, yc, w, h])\n",
        "    return torch.tensor(boxes) if boxes else torch.zeros((0,5))\n",
        "\n",
        "def make_all_pairs(input_dir, target_dir, desc=\"Pairing files\"):\n",
        "    \"\"\"\n",
        "    Pairs every file in input_dir with the correct target in target_dir.\n",
        "    Handles '_aug' filenames by stripping '_aug' to find the original target.\n",
        "    Shows a progress bar with tqdm.\n",
        "    \"\"\"\n",
        "    pairs = []\n",
        "    files = [f for f in os.listdir(input_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "    for fname in tqdm(files, desc=desc):\n",
        "        input_path = os.path.join(input_dir, fname)\n",
        "\n",
        "        # If the file is an augmented file, strip '_aug' to find the original target\n",
        "        target_fname = fname.replace(\"_aug\", \"\") if \"_aug\" in fname else fname\n",
        "        target_path = os.path.join(target_dir, target_fname)\n",
        "\n",
        "        if os.path.exists(target_path):\n",
        "            X = load_labels(input_path)\n",
        "            Y = load_labels(target_path)\n",
        "            pairs.append((X, Y))\n",
        "        else:\n",
        "            print(f\" Skipped {fname}, target {target_fname} not found in {target_dir}\")\n",
        "\n",
        "    return pairs\n",
        "\n",
        "train_pairs = make_all_pairs(train_input_dir, train_target_dir, desc=\"Pairing train_input\")\n",
        "train_pairs += make_all_pairs(train_input_aug_dir, train_target_dir, desc=\"Pairing train_input_aug\")\n",
        "\n",
        "val_pairs = make_all_pairs(val_input_dir, val_target_dir, desc=\"Pairing val_input\")\n",
        "val_pairs += make_all_pairs(val_input_aug_dir, val_target_dir, desc=\"Pairing val_input_aug\")\n",
        "\n",
        "print(f\"Loaded {len(train_pairs)} training pairs, {len(val_pairs)} validation pairs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3-dCeyMpHGW",
        "outputId": "e59f4143-75ba-4c76-b8e5-03e7dd89b3c3"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pairing train_input: 100%|| 2285/2285 [01:23<00:00, 27.23it/s] \n",
            "Pairing train_input_aug: 100%|| 316/316 [00:04<00:00, 71.51it/s]\n",
            "Pairing val_input: 100%|| 404/404 [00:07<00:00, 51.92it/s]\n",
            "Pairing val_input_aug: 100%|| 73/73 [00:01<00:00, 69.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2601 training pairs, 477 validation pairs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train pairs: {len(train_pairs)}\")\n",
        "print(f\"Validation pairs: {len(val_pairs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gLhqfLhw--2",
        "outputId": "05a65613-f413-40d9-a2bc-62e589316c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train pairs: 2601\n",
            "Validation pairs: 477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (X, Y) in enumerate(train_pairs[:10]):\n",
        "    print(f\"Train pair {i}: X={X.shape}, Y={Y.shape}\")\n",
        "for i, (X, Y) in enumerate(val_pairs[:10]):\n",
        "    print(f\"Val pair {i}: X={X.shape}, Y={Y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAMaFdE3y5pb",
        "outputId": "5da456f7-bd10-4f23-b4d0-dd8b1f878361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train pair 0: X=torch.Size([1, 5]), Y=torch.Size([1, 5])\n",
            "Train pair 1: X=torch.Size([5, 5]), Y=torch.Size([5, 5])\n",
            "Train pair 2: X=torch.Size([18, 5]), Y=torch.Size([19, 5])\n",
            "Train pair 3: X=torch.Size([2, 5]), Y=torch.Size([2, 5])\n",
            "Train pair 4: X=torch.Size([4, 5]), Y=torch.Size([4, 5])\n",
            "Train pair 5: X=torch.Size([7, 5]), Y=torch.Size([7, 5])\n",
            "Train pair 6: X=torch.Size([5, 5]), Y=torch.Size([6, 5])\n",
            "Train pair 7: X=torch.Size([8, 5]), Y=torch.Size([9, 5])\n",
            "Train pair 8: X=torch.Size([9, 5]), Y=torch.Size([11, 5])\n",
            "Train pair 9: X=torch.Size([3, 5]), Y=torch.Size([5, 5])\n",
            "Val pair 0: X=torch.Size([10, 5]), Y=torch.Size([10, 5])\n",
            "Val pair 1: X=torch.Size([9, 5]), Y=torch.Size([10, 5])\n",
            "Val pair 2: X=torch.Size([19, 5]), Y=torch.Size([19, 5])\n",
            "Val pair 3: X=torch.Size([9, 5]), Y=torch.Size([13, 5])\n",
            "Val pair 4: X=torch.Size([8, 5]), Y=torch.Size([10, 5])\n",
            "Val pair 5: X=torch.Size([4, 5]), Y=torch.Size([4, 5])\n",
            "Val pair 6: X=torch.Size([5, 5]), Y=torch.Size([5, 5])\n",
            "Val pair 7: X=torch.Size([10, 5]), Y=torch.Size([14, 5])\n",
            "Val pair 8: X=torch.Size([2, 5]), Y=torch.Size([10, 5])\n",
            "Val pair 9: X=torch.Size([4, 5]), Y=torch.Size([7, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def encode_objects(boxes, num_classes=12):\n",
        "    feats = []\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        if cls == 11:  # skip picture frames\n",
        "            continue\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_classes-1)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "    return torch.stack(feats) if feats else torch.zeros((1, num_classes+3))"
      ],
      "metadata": {
        "id": "v0dYcz0KznWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SceneLayoutPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=4, num_pred=2):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=8),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 4 * num_pred)\n",
        "        )\n",
        "        self.num_pred = num_pred\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.encoder(x.unsqueeze(1)).squeeze(1)\n",
        "        scene_feat = x.mean(0)\n",
        "        preds = self.output_head(scene_feat)\n",
        "        return preds.view(self.num_pred, 4)"
      ],
      "metadata": {
        "id": "Tkm_Wn5hz7H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = SceneLayoutPredictor(input_dim=15, num_pred=2).to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "def train_epoch(pairs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X, Y in pairs:\n",
        "        X_enc = encode_objects(X).to(device)\n",
        "        frame_boxes = Y[Y[:,0]==11][:,1:].to(device)\n",
        "        if len(frame_boxes) == 0:\n",
        "            continue\n",
        "\n",
        "        preds = model(X_enc)\n",
        "        target = torch.zeros_like(preds)\n",
        "        target[:len(frame_boxes)] = frame_boxes[:preds.shape[0]]\n",
        "\n",
        "        loss = F.smooth_l1_loss(preds, target)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(pairs)\n",
        "\n",
        "for epoch in range(20):\n",
        "    loss = train_epoch(train_pairs)\n",
        "    print(f\"Epoch {epoch+1:02d} | Train loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T2VnOvez-fJ",
        "outputId": "adcdbfff-6731-49e1-a18c-0ef1dbcbc1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train loss: 0.0090\n",
            "Epoch 02 | Train loss: 0.0086\n",
            "Epoch 03 | Train loss: 0.0084\n",
            "Epoch 04 | Train loss: 0.0084\n",
            "Epoch 05 | Train loss: 0.0083\n",
            "Epoch 06 | Train loss: 0.0081\n",
            "Epoch 07 | Train loss: 0.0079\n",
            "Epoch 08 | Train loss: 0.0078\n",
            "Epoch 09 | Train loss: 0.0077\n",
            "Epoch 10 | Train loss: 0.0074\n",
            "Epoch 11 | Train loss: 0.0073\n",
            "Epoch 12 | Train loss: 0.0070\n",
            "Epoch 13 | Train loss: 0.0068\n",
            "Epoch 14 | Train loss: 0.0066\n",
            "Epoch 15 | Train loss: 0.0064\n",
            "Epoch 16 | Train loss: 0.0061\n",
            "Epoch 17 | Train loss: 0.0060\n",
            "Epoch 18 | Train loss: 0.0057\n",
            "Epoch 19 | Train loss: 0.0054\n",
            "Epoch 20 | Train loss: 0.0052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(pairs):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for X, Y in pairs:\n",
        "        X_enc = encode_objects(X).to(device)\n",
        "        frame_boxes = Y[Y[:,0]==11][:,1:].to(device)\n",
        "        if len(frame_boxes) == 0:\n",
        "            continue\n",
        "        preds = model(X_enc)\n",
        "        target = torch.zeros_like(preds)\n",
        "        target[:len(frame_boxes)] = frame_boxes[:preds.shape[0]]\n",
        "        loss = F.smooth_l1_loss(preds, target)\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(pairs)\n",
        "\n",
        "val_loss = evaluate(val_pairs)\n",
        "print(f\"Validation loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyLp7iRO1Ujd",
        "outputId": "e429b99f-a6af-4852-c5d3-3a9cdd149843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.0129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def show_boxes(preds, targets, img_w=640, img_h=480):\n",
        "    fig, ax = plt.subplots()\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "    targets = targets.detach().cpu().numpy()\n",
        "\n",
        "    for (x, y, w, h) in preds:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='r', facecolor='none', linewidth=2\n",
        "        ))\n",
        "\n",
        "    for (x, y, w, h) in targets:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='g', facecolor='none', linewidth=2\n",
        "        ))\n",
        "\n",
        "    # Set axes limits explicitly\n",
        "    ax.set_xlim(0, img_w)\n",
        "    ax.set_ylim(img_h, 0)  # invert y-axis for image coordinates\n",
        "    ax.set_aspect('equal')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "X, Y = val_pairs[292]\n",
        "preds = model(encode_objects(X).to(device)).cpu()\n",
        "targets = Y[Y[:,0]==11][:,1:].cpu()\n",
        "show_boxes(preds, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "pzOBbuIP1VPh",
        "outputId": "ed5ad6ad-b052-4f39-fce4-f84e9c3c19c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modifying original since it appeared to work the best, now weights samples towards ones with class 11 in them"
      ],
      "metadata": {
        "id": "o8aOt7NmjQAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "# --- Dataset wrapper for pairs ---\n",
        "\n",
        "class PairDataset(Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.pairs[idx]\n",
        "\n",
        "train_dataset = PairDataset(train_pairs)\n",
        "\n",
        "# --- Compute sample weights based on presence of class 11 (frames) ---\n",
        "\n",
        "labels = []\n",
        "for _, Y in train_pairs:\n",
        "    has_frame = (Y[:,0] == 11).any().item()\n",
        "    labels.append(1 if has_frame else 0)\n",
        "labels = torch.tensor(labels)\n",
        "class_counts = torch.bincount(labels)\n",
        "weights_per_class = 1. / class_counts.float()\n",
        "sample_weights = weights_per_class[labels]\n",
        "\n",
        "# Create WeightedRandomSampler\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# DataLoader with sampler, batch size=1 as per your original single sample processing\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, sampler=sampler)"
      ],
      "metadata": {
        "id": "SZHgvYNzjU16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Encoding function ---\n",
        "\n",
        "def encode_objects(boxes, num_classes=12):\n",
        "    feats = []\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        if cls == 11:  # skip picture frames\n",
        "            continue\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_classes-1)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "    return torch.stack(feats) if feats else torch.zeros((1, num_classes+3))"
      ],
      "metadata": {
        "id": "VcfgXT3ymnF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model definition ---\n",
        "\n",
        "class SceneLayoutPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=4, num_pred=2):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=8),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 4 * num_pred)\n",
        "        )\n",
        "        self.num_pred = num_pred\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.encoder(x.unsqueeze(1)).squeeze(1)\n",
        "        scene_feat = x.mean(0)\n",
        "        preds = self.output_head(scene_feat)\n",
        "        return preds.view(self.num_pred, 4)"
      ],
      "metadata": {
        "id": "OEGkKsgfmrtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setup device, model, optimizer ---\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SceneLayoutPredictor(input_dim=15, num_pred=2).to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# --- Training loop using DataLoader with weighted sampling ---\n",
        "\n",
        "def train_epoch_loader(loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X, Y in loader:\n",
        "        X_enc = encode_objects(X[0]).to(device)\n",
        "        frame_boxes = Y[0][Y[0][:,0]==11][:,1:].to(device)\n",
        "        if len(frame_boxes) == 0:\n",
        "            continue\n",
        "        preds = model(X_enc)\n",
        "        target = torch.zeros_like(preds)\n",
        "        target[:len(frame_boxes)] = frame_boxes[:preds.shape[0]]\n",
        "        loss = F.smooth_l1_loss(preds, target)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n"
      ],
      "metadata": {
        "id": "rTJjKoYQmwYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Validation function, unchanged ---\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(pairs):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for X, Y in pairs:\n",
        "        X_enc = encode_objects(X).to(device)\n",
        "        frame_boxes = Y[Y[:,0]==11][:,1:].to(device)\n",
        "        if len(frame_boxes) == 0:\n",
        "            continue\n",
        "        preds = model(X_enc)\n",
        "        target = torch.zeros_like(preds)\n",
        "        target[:len(frame_boxes)] = frame_boxes[:preds.shape[0]]\n",
        "        loss = F.smooth_l1_loss(preds, target)\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(pairs)"
      ],
      "metadata": {
        "id": "YHeLogRamzkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training execution ---\n",
        "\n",
        "for epoch in range(20):\n",
        "    loss = train_epoch_loader(train_loader)\n",
        "    print(f\"Epoch {epoch+1:02d} | Train loss: {loss:.4f}\")\n",
        "\n",
        "val_loss = evaluate(val_pairs)\n",
        "print(f\"Validation loss: {val_loss:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV6eyrUFm4VT",
        "outputId": "54830a9c-ac2a-49a9-aa02-2110c356d28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train loss: 0.0087\n",
            "Epoch 02 | Train loss: 0.0079\n",
            "Epoch 03 | Train loss: 0.0082\n",
            "Epoch 04 | Train loss: 0.0081\n",
            "Epoch 05 | Train loss: 0.0082\n",
            "Epoch 06 | Train loss: 0.0079\n",
            "Epoch 07 | Train loss: 0.0079\n",
            "Epoch 08 | Train loss: 0.0076\n",
            "Epoch 09 | Train loss: 0.0077\n",
            "Epoch 10 | Train loss: 0.0071\n",
            "Epoch 11 | Train loss: 0.0070\n",
            "Epoch 12 | Train loss: 0.0067\n",
            "Epoch 13 | Train loss: 0.0068\n",
            "Epoch 14 | Train loss: 0.0067\n",
            "Epoch 15 | Train loss: 0.0066\n",
            "Epoch 16 | Train loss: 0.0060\n",
            "Epoch 17 | Train loss: 0.0058\n",
            "Epoch 18 | Train loss: 0.0059\n",
            "Epoch 19 | Train loss: 0.0052\n",
            "Epoch 20 | Train loss: 0.0056\n",
            "Validation loss: 0.0121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualization ---\n",
        "\n",
        "def show_boxes(preds, targets, img_w=640, img_h=480):\n",
        "    fig, ax = plt.subplots()\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "    targets = targets.detach().cpu().numpy()\n",
        "\n",
        "    for (x, y, w, h) in preds:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='r', facecolor='none', linewidth=2\n",
        "        ))\n",
        "\n",
        "    for (x, y, w, h) in targets:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='g', facecolor='none', linewidth=2\n",
        "        ))\n",
        "\n",
        "    ax.set_xlim(0, img_w)\n",
        "    ax.set_ylim(img_h, 0)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.show()\n",
        "\n",
        "# Example prediction visualization\n",
        "X, Y = val_pairs[292]\n",
        "preds = model(encode_objects(X).to(device)).cpu()\n",
        "targets = Y[Y[:,0]==11][:,1:].cpu()\n",
        "show_boxes(preds, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "VWPfIWh-m7dL",
        "outputId": "e9e63593-419b-45ad-fa65-cbbaa529f169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modifying to attempt predictions for variable number of paintings. Note large number of paintings usually result in smaller size of them in train/val sets"
      ],
      "metadata": {
        "id": "7nwUZ038nkVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Current method always prediciting 10 paintings per, but filtering them based on cofidence thresholds and then removing overlapping ones"
      ],
      "metadata": {
        "id": "RDRtqJWTqHOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SceneLayoutPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=4, num_pred=10):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=8),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 5 * num_pred)  # 4 box coords + 1 confidence\n",
        "        )\n",
        "        self.num_pred = num_pred\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.encoder(x.unsqueeze(1)).squeeze(1)\n",
        "        scene_feat = x.mean(0)\n",
        "        preds = self.output_head(scene_feat)\n",
        "        preds = preds.view(self.num_pred, 5)\n",
        "        boxes = preds[:, :4]\n",
        "        confidences = torch.sigmoid(preds[:, 4])\n",
        "        return boxes, confidences\n"
      ],
      "metadata": {
        "id": "VZS3_MqDqOO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SceneLayoutPredictor(input_dim=15, num_pred=10).to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# --- Loss function ---\n",
        "\n",
        "def compute_loss(pred_boxes, pred_conf, target_boxes):\n",
        "    # Simplified loss: match pred boxes to targets by index (limit to targets or pred count)\n",
        "    n = min(len(target_boxes), pred_boxes.size(0))\n",
        "    if n == 0:\n",
        "        # No target frames, encourage confidence to zero\n",
        "        conf_loss = F.binary_cross_entropy(pred_conf, torch.zeros_like(pred_conf))\n",
        "        box_loss = torch.tensor(0., device=pred_boxes.device)\n",
        "    else:\n",
        "        conf_target = torch.zeros_like(pred_conf)\n",
        "        conf_target[:n] = 1.0\n",
        "        conf_loss = F.binary_cross_entropy(pred_conf, conf_target)\n",
        "        box_loss = F.smooth_l1_loss(pred_boxes[:n], target_boxes[:n])\n",
        "    return conf_loss + box_loss"
      ],
      "metadata": {
        "id": "az1bbiErqvTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training function ---\n",
        "\n",
        "def train_epoch_loader(loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X, Y in loader:\n",
        "        X_enc = encode_objects(X[0]).to(device)\n",
        "        frame_boxes = Y[0][Y[0][:,0] == 11][:, 1:].to(device)\n",
        "        opt.zero_grad()\n",
        "        pred_boxes, pred_conf = model(X_enc)\n",
        "        loss = compute_loss(pred_boxes, pred_conf, frame_boxes)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# --- Validation function (no sampling) ---\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(pairs):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for X, Y in pairs:\n",
        "        X_enc = encode_objects(X).to(device)\n",
        "        frame_boxes = Y[Y[:,0] == 11][:, 1:].to(device)\n",
        "        pred_boxes, pred_conf = model(X_enc)\n",
        "        loss = compute_loss(pred_boxes, pred_conf, frame_boxes)\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(pairs)"
      ],
      "metadata": {
        "id": "CgEpgk5mq1Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #--- Inference helper with confidence threshold and NMS ---\n",
        "\n",
        "def inference_with_nms(model, X_enc, conf_thresh=0.5, nms_thresh=0.4):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        boxes, confidences = model(X_enc)\n",
        "        keep = confidences > conf_thresh\n",
        "        if keep.sum() == 0:\n",
        "            return torch.empty((0,4), device=X_enc.device)\n",
        "        boxes = boxes[keep]\n",
        "        scores = confidences[keep]\n",
        "        x1 = boxes[:,0] - boxes[:,2]/2\n",
        "        y1 = boxes[:,1] - boxes[:,3]/2\n",
        "        x2 = boxes[:,0] + boxes[:,2]/2\n",
        "        y2 = boxes[:,1] + boxes[:,3]/2\n",
        "        boxes_xyxy = torch.stack([x1, y1, x2, y2], dim=1)\n",
        "        keep_indices = ops.nms(boxes_xyxy, scores, nms_thresh)\n",
        "        return boxes[keep_indices]"
      ],
      "metadata": {
        "id": "zxyjsPnIq5yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training loop ---\n",
        "\n",
        "for epoch in range(20):\n",
        "    train_loss = train_epoch_loader(train_loader)\n",
        "    val_loss = evaluate(val_pairs)\n",
        "    print(f\"Epoch {epoch+1:02d} | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZxXayvmrB7u",
        "outputId": "42dab98c-3e67-4528-9852-a32620d63af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train loss: 0.3642 | Val loss: 0.3843\n",
            "Epoch 02 | Train loss: 0.3469 | Val loss: 0.3894\n",
            "Epoch 03 | Train loss: 0.3442 | Val loss: 0.4343\n",
            "Epoch 04 | Train loss: 0.3535 | Val loss: 0.3934\n",
            "Epoch 05 | Train loss: 0.3470 | Val loss: 0.3899\n",
            "Epoch 06 | Train loss: 0.3427 | Val loss: 0.3946\n",
            "Epoch 07 | Train loss: 0.3394 | Val loss: 0.4073\n",
            "Epoch 08 | Train loss: 0.3525 | Val loss: 0.4019\n",
            "Epoch 09 | Train loss: 0.3569 | Val loss: 0.3946\n",
            "Epoch 10 | Train loss: 0.3432 | Val loss: 0.4021\n",
            "Epoch 11 | Train loss: 0.3462 | Val loss: 0.3948\n",
            "Epoch 12 | Train loss: 0.3440 | Val loss: 0.3892\n",
            "Epoch 13 | Train loss: 0.3484 | Val loss: 0.3875\n",
            "Epoch 14 | Train loss: 0.3269 | Val loss: 0.3918\n",
            "Epoch 15 | Train loss: 0.3522 | Val loss: 0.3959\n",
            "Epoch 16 | Train loss: 0.3391 | Val loss: 0.4033\n",
            "Epoch 17 | Train loss: 0.3585 | Val loss: 0.3923\n",
            "Epoch 18 | Train loss: 0.3378 | Val loss: 0.3987\n",
            "Epoch 19 | Train loss: 0.3434 | Val loss: 0.3994\n",
            "Epoch 20 | Train loss: 0.3648 | Val loss: 0.3885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualization (unchanged) ---\n",
        "import torchvision.ops as ops\n",
        "\n",
        "\n",
        "def show_boxes(preds, targets, img_w=640, img_h=480):\n",
        "    fig, ax = plt.subplots()\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "    targets = targets.detach().cpu().numpy()\n",
        "    for (x, y, w, h) in preds:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='r', facecolor='none', linewidth=2))\n",
        "    for (x, y, w, h) in targets:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='g', facecolor='none', linewidth=2))\n",
        "    ax.set_xlim(0, img_w)\n",
        "    ax.set_ylim(img_h, 0)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.show()\n",
        "\n",
        "X, Y = val_pairs[292]\n",
        "X_enc = encode_objects(X).to(device)\n",
        "predicted_boxes = inference_with_nms(model, X_enc, conf_thresh=0.5, nms_thresh=0.4)\n",
        "target_boxes = Y[Y[:,0] == 11][:, 1:].to(device)\n",
        "show_boxes(predicted_boxes, target_boxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Ooa49ZS5rCNN",
        "outputId": "023cfd70-1711-4493-f5a5-553b7405df29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updating to IoU, ran with 20 num_pred"
      ],
      "metadata": {
        "id": "TYNclGYrw9Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p6iJ_uKxPLw",
        "outputId": "f16bc8b4-7c36-402b-a7ba-6c89e644aca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.ops as ops\n",
        "from torchmetrics.detection import IntersectionOverUnion\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches"
      ],
      "metadata": {
        "id": "DTHmyJhkxAXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Dataset wrapper ---\n",
        "\n",
        "class PairDataset(Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.pairs[idx]\n",
        "\n",
        "train_dataset = PairDataset(train_pairs)\n",
        "\n",
        "# --- Sample weights for imbalance handling ---\n",
        "\n",
        "labels = []\n",
        "for _, Y in train_pairs:\n",
        "    has_frame = (Y[:,0] == 11).any().item()\n",
        "    labels.append(1 if has_frame else 0)\n",
        "\n",
        "labels = torch.tensor(labels)\n",
        "class_counts = torch.bincount(labels)\n",
        "weights_per_class = 1. / class_counts.float()\n",
        "sample_weights = weights_per_class[labels]\n",
        "\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, sampler=sampler)\n",
        "\n",
        "# --- Encoding objects ---\n",
        "\n",
        "def encode_objects(boxes, num_classes=12):\n",
        "    feats = []\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        if cls == 11:\n",
        "            continue\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_classes-1)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "    return torch.stack(feats) if feats else torch.zeros((1, num_classes+3))"
      ],
      "metadata": {
        "id": "m-yoh6NQxEDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model with boxes + confidence ---\n",
        "\n",
        "class SceneLayoutPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=4, num_pred=20):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=8),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 5 * num_pred)  # 4 coords + 1 conf\n",
        "        )\n",
        "        self.num_pred = num_pred\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.encoder(x.unsqueeze(1)).squeeze(1)\n",
        "        scene_feat = x.mean(0)\n",
        "        preds = self.output_head(scene_feat).view(self.num_pred, 5)\n",
        "        boxes = preds[:, :4]\n",
        "        confidences = torch.sigmoid(preds[:, 4])\n",
        "        return boxes, confidences\n"
      ],
      "metadata": {
        "id": "P4jYplRrxjZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Setup model, optimizer, device ---\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SceneLayoutPredictor(input_dim=15, num_pred=20).to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# --- Loss function combining box regression & confidence ---\n",
        "\n",
        "def compute_loss(pred_boxes, pred_conf, target_boxes):\n",
        "    n = min(len(target_boxes), pred_boxes.size(0))\n",
        "    if n == 0:\n",
        "        conf_loss = F.binary_cross_entropy(pred_conf, torch.zeros_like(pred_conf))\n",
        "        box_loss = torch.tensor(0., device=pred_boxes.device)\n",
        "    else:\n",
        "        conf_target = torch.zeros_like(pred_conf)\n",
        "        conf_target[:n] = 1.0\n",
        "        conf_loss = F.binary_cross_entropy(pred_conf, conf_target)\n",
        "        box_loss = F.smooth_l1_loss(pred_boxes[:n], target_boxes[:n])\n",
        "    return conf_loss + box_loss"
      ],
      "metadata": {
        "id": "zUGG_9b1xjvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- IoU metric ---\n",
        "\n",
        "iou_metric = IntersectionOverUnion(box_format='xyxy')\n",
        "\n",
        "def boxes_cxcywh_to_xyxy(boxes):\n",
        "    cx, cy, w, h = boxes.unbind(-1)\n",
        "    return torch.stack([cx - w/2, cy - h/2, cx + w/2, cy + h/2], dim=-1)"
      ],
      "metadata": {
        "id": "Gvr-RD_DxroO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training epoch ---\n",
        "\n",
        "def train_epoch_loader(loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X, Y in loader:\n",
        "        X_enc = encode_objects(X[0]).to(device)\n",
        "        frame_boxes = Y[0][Y[0][:,0] == 11][:,1:].to(device)\n",
        "        opt.zero_grad()\n",
        "        pred_boxes, pred_conf = model(X_enc)\n",
        "        loss = compute_loss(pred_boxes, pred_conf, frame_boxes)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# --- Validation with IoU ---\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_with_iou(pairs):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    iou_metric.reset()\n",
        "    for X, Y in pairs:\n",
        "        X_enc = encode_objects(X).to(device)\n",
        "        target_boxes = Y[Y[:,0] == 11][:,1:].to(device)\n",
        "\n",
        "        pred_boxes, pred_conf = model(X_enc)\n",
        "        conf_thresh = 0.5\n",
        "        nms_thresh = 0.4\n",
        "        keep = pred_conf > conf_thresh\n",
        "        if keep.sum() == 0:\n",
        "            continue\n",
        "        pred_boxes = pred_boxes[keep]\n",
        "\n",
        "        # NMS requires xyxy boxes\n",
        "        boxes_xyxy = boxes_cxcywh_to_xyxy(pred_boxes)\n",
        "        scores = pred_conf[keep]\n",
        "        keep_indices = ops.nms(boxes_xyxy, scores, nms_thresh)\n",
        "        pred_boxes = pred_boxes[keep_indices]\n",
        "\n",
        "        target_boxes_xyxy = boxes_cxcywh_to_xyxy(target_boxes)\n",
        "        pred_boxes_xyxy = boxes_cxcywh_to_xyxy(pred_boxes)\n",
        "\n",
        "        preds = [{'boxes': pred_boxes_xyxy, 'labels': torch.zeros(len(pred_boxes_xyxy), dtype=torch.int, device=device)}]\n",
        "        targets = [{'boxes': target_boxes_xyxy, 'labels': torch.zeros(len(target_boxes_xyxy), dtype=torch.int, device=device)}]\n",
        "\n",
        "        iou_metric.update(preds, targets)\n",
        "\n",
        "        loss = compute_loss(pred_boxes, pred_conf[keep][keep_indices], target_boxes)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    mean_iou = iou_metric.compute()['iou'].item()\n",
        "    avg_loss = total_loss / len(pairs)\n",
        "    return avg_loss, mean_iou"
      ],
      "metadata": {
        "id": "bSNYSUryx0n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training loop ---\n",
        "\n",
        "for epoch in range(20):\n",
        "    train_loss = train_epoch_loader(train_loader)\n",
        "    val_loss, val_iou = evaluate_with_iou(val_pairs)\n",
        "    print(f\"Epoch {epoch+1:02d} | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val mean IoU: {val_iou:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz6kU-tjx542",
        "outputId": "020bd6c4-ac8d-4d65-f1f2-7729f80866b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train loss: 0.2149 | Val loss: 0.3720 | Val mean IoU: 0.0309\n",
            "Epoch 02 | Train loss: 0.2062 | Val loss: 0.0896 | Val mean IoU: 0.0174\n",
            "Epoch 03 | Train loss: 0.2011 | Val loss: 0.2685 | Val mean IoU: 0.0220\n",
            "Epoch 04 | Train loss: 0.1906 | Val loss: 0.4728 | Val mean IoU: 0.0244\n",
            "Epoch 05 | Train loss: 0.2000 | Val loss: 0.2603 | Val mean IoU: 0.0294\n",
            "Epoch 06 | Train loss: 0.1971 | Val loss: 0.5726 | Val mean IoU: 0.0230\n",
            "Epoch 07 | Train loss: 0.2023 | Val loss: 0.6243 | Val mean IoU: 0.0297\n",
            "Epoch 08 | Train loss: 0.1970 | Val loss: 0.3955 | Val mean IoU: 0.0242\n",
            "Epoch 09 | Train loss: 0.1898 | Val loss: 0.0162 | Val mean IoU: 0.0166\n",
            "Epoch 10 | Train loss: 0.2061 | Val loss: 0.5417 | Val mean IoU: 0.0316\n",
            "Epoch 11 | Train loss: 0.1858 | Val loss: 0.2819 | Val mean IoU: 0.0284\n",
            "Epoch 12 | Train loss: 0.2000 | Val loss: 0.3262 | Val mean IoU: 0.0347\n",
            "Epoch 13 | Train loss: 0.1912 | Val loss: 0.3948 | Val mean IoU: 0.0303\n",
            "Epoch 14 | Train loss: 0.1988 | Val loss: 0.3371 | Val mean IoU: 0.0334\n",
            "Epoch 15 | Train loss: 0.1826 | Val loss: 0.3203 | Val mean IoU: 0.0260\n",
            "Epoch 16 | Train loss: 0.1938 | Val loss: 0.5083 | Val mean IoU: 0.0191\n",
            "Epoch 17 | Train loss: 0.1940 | Val loss: 0.2473 | Val mean IoU: 0.0328\n",
            "Epoch 18 | Train loss: 0.1908 | Val loss: 0.4206 | Val mean IoU: 0.0239\n",
            "Epoch 19 | Train loss: 0.1888 | Val loss: 0.4020 | Val mean IoU: 0.0263\n",
            "Epoch 20 | Train loss: 0.1898 | Val loss: 0.3856 | Val mean IoU: 0.0279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualization ---\n",
        "\n",
        "def show_boxes(preds, targets, img_w=640, img_h=480):\n",
        "    fig, ax = plt.subplots()\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "    targets = targets.detach().cpu().numpy()\n",
        "    for (x, y, w, h) in preds:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='r', facecolor='none', linewidth=2))\n",
        "    for (x, y, w, h) in targets:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='g', facecolor='none', linewidth=2))\n",
        "    ax.set_xlim(0, img_w)\n",
        "    ax.set_ylim(img_h, 0)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.show()\n",
        "\n",
        "    # --- Example prediction visualization---\n",
        "\n",
        "X, Y = val_pairs[292]\n",
        "X_enc = encode_objects(X).to(device)\n",
        "pred_boxes, pred_conf = model(X_enc)\n",
        "\n",
        "# Apply confidence threshold and NMS for visualization\n",
        "conf_thresh = 0.5\n",
        "nms_thresh = 0.4\n",
        "keep = pred_conf > conf_thresh\n",
        "pred_boxes = pred_boxes[keep]\n",
        "scores = pred_conf[keep]\n",
        "\n",
        "boxes_xyxy = boxes_cxcywh_to_xyxy(pred_boxes)\n",
        "keep_indices = ops.nms(boxes_xyxy, scores, nms_thresh)\n",
        "pred_boxes = pred_boxes[keep_indices]\n",
        "\n",
        "target_boxes = Y[Y[:,0]==11][:,1:].to(device)\n",
        "\n",
        "show_boxes(pred_boxes, target_boxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Q2UJKCd0yDK-",
        "outputId": "f91ba23e-15d1-4302-d75d-424ef292cbbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updating loss to CIoU + smoothL1, IoU NMS, adding Explicit Box Matching, further increasing weight of class 11"
      ],
      "metadata": {
        "id": "UfKs0oNAklBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision.ops import box_iou, nms, complete_box_iou_loss\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from torchvision import ops\n",
        "\n",
        "# --- Dataset wrapper ---\n",
        "class PairDataset(Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.pairs[idx]\n",
        "\n",
        "train_dataset = PairDataset(train_pairs)\n",
        "\n",
        "# --- Sample weights for imbalance handling ---\n",
        "labels = []\n",
        "for _, Y in train_pairs:\n",
        "    has_frame = (Y[:,0] == 11).any().item()\n",
        "    labels.append(1 if has_frame else 0)\n",
        "\n",
        "labels = torch.tensor(labels)\n",
        "class_counts = torch.bincount(labels)\n",
        "weights_per_class = 1. / class_counts.float()\n",
        "weights_per_class[1] *= 3  # 3x weight for painting-containing samples (label=1)\n",
        "sample_weights = weights_per_class[labels]\n",
        "\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, sampler=sampler)"
      ],
      "metadata": {
        "id": "T1wuHkUVkmF3"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Encoding objects ---\n",
        "def encode_objects(boxes, num_classes=12):\n",
        "    feats = []\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        if cls == 11:\n",
        "            continue\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_classes-1)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "    return torch.stack(feats) if feats else torch.zeros((1, num_classes+3))\n"
      ],
      "metadata": {
        "id": "Iq9Sw62_mh4d"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model with boxes + confidence ---\n",
        "class SceneLayoutPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=4, num_pred=20):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=8),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 5 * num_pred)  # 4 coords + 1 conf\n",
        "        )\n",
        "        self.num_pred = num_pred\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.encoder(x.unsqueeze(1)).squeeze(1)\n",
        "        scene_feat = x.mean(0)\n",
        "        preds = self.output_head(scene_feat).view(self.num_pred, 5)\n",
        "        boxes = preds[:, :4]\n",
        "        confidences = torch.sigmoid(preds[:, 4])\n",
        "        return boxes, confidences\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SceneLayoutPredictor(input_dim=15, num_pred=20).to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "bgMjxrmOmrxx"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Utility functions ---\n",
        "def boxes_cxcywh_to_xyxy(boxes):\n",
        "    cx, cy, w, h = boxes.unbind(-1)\n",
        "    return torch.stack([cx - w/2, cy - h/2, cx + w/2, cy + h/2], dim=-1)\n",
        "\n",
        "def ciou_nms(boxes, scores, iou_threshold=0.4):\n",
        "    # Actually standard IoU NMS cause CIoU NMS very complicated apparently\n",
        "    return nms(boxes, scores, iou_threshold)"
      ],
      "metadata": {
        "id": "8o1HNLQtm8Q-"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Loss with explicit Hungarian matching + Smooth L1 + CIoU ---\n",
        "def compute_loss(pred_boxes, pred_conf, target_boxes):\n",
        "    num_pred = pred_boxes.size(0)\n",
        "    num_target = target_boxes.size(0)\n",
        "    if num_target == 0:\n",
        "        conf_loss = F.binary_cross_entropy(pred_conf, torch.zeros_like(pred_conf))\n",
        "        box_loss = torch.tensor(0., device=pred_boxes.device)\n",
        "        return conf_loss + box_loss\n",
        "\n",
        "    pred_xyxy = boxes_cxcywh_to_xyxy(pred_boxes)\n",
        "    target_xyxy = boxes_cxcywh_to_xyxy(target_boxes)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        iou_matrix = box_iou(pred_xyxy, target_xyxy)  # [num_pred, num_target]\n",
        "        cost_matrix = 1 - iou_matrix.cpu().numpy()\n",
        "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
        "\n",
        "    matched_pred_boxes = pred_boxes[row_ind]\n",
        "    matched_pred_conf = pred_conf[row_ind]\n",
        "    matched_target_boxes = target_boxes[col_ind]\n",
        "\n",
        "    conf_target = torch.zeros_like(pred_conf)\n",
        "    conf_target[row_ind] = 1.0\n",
        "\n",
        "    conf_loss = F.binary_cross_entropy(pred_conf, conf_target)\n",
        "\n",
        "    smooth_l1_loss = F.smooth_l1_loss(matched_pred_boxes, matched_target_boxes)\n",
        "\n",
        "    ciou_loss = complete_box_iou_loss(\n",
        "        boxes_cxcywh_to_xyxy(matched_pred_boxes),\n",
        "        boxes_cxcywh_to_xyxy(matched_target_boxes),\n",
        "        reduction='mean'\n",
        "    )\n",
        "\n",
        "    box_loss = 0.5 * smooth_l1_loss + 0.5 * ciou_loss\n",
        "\n",
        "    return conf_loss + box_loss"
      ],
      "metadata": {
        "id": "0s2G6JThm_8H"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#debugging loss function\n",
        "def compute_loss(pred_boxes, pred_conf, target_boxes):\n",
        "    num_pred = pred_boxes.size(0)\n",
        "    num_target = target_boxes.size(0)\n",
        "    if num_target == 0:\n",
        "        conf_loss = F.binary_cross_entropy(pred_conf, torch.zeros_like(pred_conf))\n",
        "        box_loss = torch.tensor(0., device=pred_boxes.device)\n",
        "        print(f\"No targets: conf_loss={conf_loss.item()}, box_loss={box_loss.item()}\")\n",
        "        return conf_loss + box_loss\n",
        "\n",
        "    pred_xyxy = boxes_cxcywh_to_xyxy(pred_boxes)\n",
        "    target_xyxy = boxes_cxcywh_to_xyxy(target_boxes)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        iou_matrix = box_iou(pred_xyxy, target_xyxy)  # [num_pred, num_target]\n",
        "        cost_matrix = 1 - iou_matrix.cpu().numpy()\n",
        "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
        "    print(f\"Hungarian matching: row_ind={row_ind}, col_ind={col_ind}\")\n",
        "\n",
        "    matched_pred_boxes = pred_boxes[row_ind]\n",
        "    matched_pred_conf = pred_conf[row_ind]\n",
        "    matched_target_boxes = target_boxes[col_ind]\n",
        "\n",
        "    conf_target = torch.zeros_like(pred_conf)\n",
        "    conf_target[row_ind] = 1.0\n",
        "\n",
        "    conf_loss = F.binary_cross_entropy(pred_conf, conf_target)\n",
        "\n",
        "    smooth_l1_loss = F.smooth_l1_loss(matched_pred_boxes, matched_target_boxes)\n",
        "\n",
        "    ciou_loss = complete_box_iou_loss(\n",
        "        boxes_cxcywh_to_xyxy(matched_pred_boxes),\n",
        "        boxes_cxcywh_to_xyxy(matched_target_boxes),\n",
        "        reduction='mean'\n",
        "    )\n",
        "\n",
        "    box_loss = 0.5 * smooth_l1_loss + 0.5 * ciou_loss\n",
        "\n",
        "    print(f\"conf_loss: {conf_loss.item()}, smooth_l1_loss: {smooth_l1_loss.item()}, ciou_loss: {ciou_loss.item()}, box_loss: {box_loss.item()}\")\n",
        "\n",
        "    return conf_loss + box_loss"
      ],
      "metadata": {
        "id": "tKcTdwy7ulNR"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training epoch ---\n",
        "def train_epoch_loader(loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X, Y in loader:\n",
        "        X_enc = encode_objects(X[0]).to(device)\n",
        "        frame_boxes = Y[0][Y[0][:,0] == 11][:,1:].to(device)\n",
        "        opt.zero_grad()\n",
        "        pred_boxes, pred_conf = model(X_enc)\n",
        "        loss = compute_loss(pred_boxes, pred_conf, frame_boxes)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# --- Validation with IoU ---\n",
        "iou_metric = IntersectionOverUnion(box_format='xyxy')\n",
        "@torch.no_grad()\n",
        "def evaluate_with_iou(pairs):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    iou_metric.reset()  # <-- reset here before processing all samples\n",
        "    updated = False\n",
        "\n",
        "    for X, Y in pairs:\n",
        "        X_enc = encode_objects(X).to(device)\n",
        "        target_boxes = Y[Y[:,0] == 11][:,1:].to(device)\n",
        "\n",
        "        pred_boxes, pred_conf = model(X_enc)\n",
        "        conf_thresh = 0.5\n",
        "        nms_thresh = 0.4\n",
        "        keep = pred_conf > conf_thresh\n",
        "        if keep.sum() == 0:\n",
        "            continue\n",
        "        pred_boxes = pred_boxes[keep]\n",
        "        scores = pred_conf[keep]\n",
        "\n",
        "        boxes_xyxy = boxes_cxcywh_to_xyxy(pred_boxes)\n",
        "        keep_indices = ciou_nms(boxes_xyxy, scores, nms_thresh)\n",
        "        pred_boxes = pred_boxes[keep_indices]\n",
        "\n",
        "        target_boxes_xyxy = boxes_cxcywh_to_xyxy(target_boxes)\n",
        "        pred_boxes_xyxy = boxes_cxcywh_to_xyxy(pred_boxes)\n",
        "\n",
        "        preds = [{'boxes': pred_boxes_xyxy, 'labels': torch.zeros(len(pred_boxes_xyxy), dtype=torch.int, device=device)}]\n",
        "        targets = [{'boxes': target_boxes_xyxy, 'labels': torch.zeros(len(target_boxes_xyxy), dtype=torch.int, device=device)}]\n",
        "\n",
        "        iou_metric.update(preds, targets)\n",
        "        updated = True\n",
        "\n",
        "        loss = compute_loss(pred_boxes, pred_conf[keep][keep_indices], target_boxes)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if not updated:\n",
        "        mean_iou = 0.0\n",
        "    else:\n",
        "        mean_iou = iou_metric.compute()['iou'].item()\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / len(pairs)\n",
        "    return avg_loss, mean_iou\n"
      ],
      "metadata": {
        "id": "2WH4X06CnEfp"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train debug\n",
        "def train_epoch_loader(loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, (X, Y) in enumerate(loader):\n",
        "        X_enc = encode_objects(X[0]).to(device)\n",
        "        frame_boxes = Y[0][Y[0][:,0] == 11][:,1:].to(device)\n",
        "        opt.zero_grad()\n",
        "        pred_boxes, pred_conf = model(X_enc)\n",
        "        loss = compute_loss(pred_boxes, pred_conf, frame_boxes)\n",
        "        loss.backward()\n",
        "\n",
        "        # Check gradients stats\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.grad is None:\n",
        "                print(f\"No grad for {name}\")\n",
        "            else:\n",
        "                print(f\"Grad stats for {name}: mean={param.grad.mean().item()}, std={param.grad.std().item()}\")\n",
        "\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if i % 10 == 0:  # Print every 10 batches\n",
        "            print(f\"Batch {i}, Loss: {loss.item()}\")\n",
        "    return total_loss / len(loader)"
      ],
      "metadata": {
        "id": "hTEIzlKluwhB"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training loop ---\n",
        "for epoch in range(20):\n",
        "    train_loss = train_epoch_loader(train_loader)\n",
        "    val_loss, val_iou = evaluate_with_iou(val_pairs)\n",
        "    print(f\"Epoch {epoch+1:02d} | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val mean IoU: {val_iou:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-QyQyCdunJBn",
        "outputId": "ba2bebcc-f45f-4322-a924-ed346d560b2f"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-4.756593341426196e-08, std=1.6097793604785693e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=3.476543497527018e-09, std=6.761812983313575e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-2.081568197809247e-07, std=7.079179795255186e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-9.442461396114155e-11, std=2.1450186977745034e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.7213596947840415e-07, std=2.2209540020412533e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-7.404652890841135e-09, std=6.8464610194496345e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-7.495484055652923e-08, std=5.367618086893344e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-6.899286697503726e-12, std=1.842588744693785e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=5.513905332321656e-09, std=1.8981226048708777e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=4.7768846656026653e-08, std=5.978004082862753e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=5.665068414373309e-08, std=5.130920271767536e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=3.138146098535799e-08, std=1.5012993571872357e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=9.610138818061387e-08, std=1.3926053725299425e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=8.478422159896581e-07, std=0.00010850610851775855\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.929502559505636e-06, std=0.00010063248919323087\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-8.585570587804625e-10, std=3.158915933454409e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.998741936404258e-07, std=3.241824742872268e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=1.4179867946495506e-08, std=0.00013974714966025203\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-2.501150220268755e-07, std=8.72712698765099e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=1.2304290919473715e-09, std=2.8411028324626386e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.924284561027889e-06, std=2.7711528673535213e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=2.5885772174660815e-06, std=0.000305990397464484\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=6.847114946140209e-06, std=0.0003417162806726992\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=4.020937922177836e-06, std=0.00034438102738931775\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-4.305096354073612e-06, std=0.00034398093703202903\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0037496951408684254, std=0.009863183833658695\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-3.739802195923403e-05, std=0.006563371047377586\n",
            "Grad stats for input_proj.weight: mean=-2.906248797174271e-09, std=7.199416813818971e-07\n",
            "Grad stats for input_proj.bias: mean=-1.9806925877219328e-08, std=2.862792143787374e-06\n",
            "Grad stats for output_head.0.weight: mean=-1.7675847630016506e-06, std=0.010051769204437733\n",
            "Grad stats for output_head.0.bias: mean=0.0033304751850664616, std=0.010156798176467419\n",
            "Grad stats for output_head.2.weight: mean=-0.00152197212446481, std=0.0210075993090868\n",
            "Grad stats for output_head.2.bias: mean=-0.006474326364696026, std=0.037656743079423904\n",
            "Hungarian matching: row_ind=[ 2 16 19], col_ind=[2 1 0]\n",
            "conf_loss: 0.4019988179206848, smooth_l1_loss: 0.02353695221245289, ciou_loss: 0.8143630027770996, box_loss: 0.41894999146461487\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=8.012823043967998e-12, std=7.848331762261296e-09\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.835169904929046e-09, std=3.91559353829507e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-6.4457614593060875e-12, std=1.733686794125333e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=3.1924707322161794e-10, std=1.0137878092564279e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.6807635972181387e-13, std=5.201482355943199e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=1.0309606640612756e-10, std=5.718113982311479e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.0322149385233459e-10, std=1.306170460679823e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-2.0886548046661346e-10, std=1.508676916728291e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.6603718400176604e-11, std=2.9676398227707068e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.1325587134791704e-09, std=3.113044400038234e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=7.342224606077252e-10, std=1.7469530178004788e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.5296484079385664e-09, std=1.7309908173501753e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=7.004864136656019e-12, std=5.544027104065208e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=2.4761936945338903e-09, std=5.618765541726134e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-4.7134900149625736e-12, std=1.6652816725581943e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=8.312017740763622e-11, std=1.340441571073825e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-3.1281505163960333e-12, std=3.140911886134745e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=3.800570524958857e-09, std=3.161506612059384e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-3.572062368117912e-10, std=1.529503492747608e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-7.217808573045659e-10, std=1.682503238953359e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.132453325032202e-09, std=2.9213276775408303e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=4.737720438185988e-09, std=2.933253711034922e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=6.934479657161319e-09, std=1.923958279803628e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-6.37649080204028e-08, std=2.164791794712073e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.3881710884955378e-11, std=6.700409471704916e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.4613455334711034e-08, std=6.866119406367943e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=5.550874426774044e-09, std=2.2373390038410434e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=4.72388350658548e-08, std=1.8528912733017933e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=2.903788320907097e-12, std=6.411169692910335e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-2.489688633033893e-08, std=6.551885007866076e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=5.405155079074575e-08, std=5.1395222726569045e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=6.216271231096471e-08, std=4.3795494093501475e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=1.9890023850166472e-08, std=4.530731530394405e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.2080584471950715e-08, std=4.676059688790701e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=1.0753972219390562e-06, std=7.384140917565674e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.49299614552001e-06, std=8.842402894515544e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=5.130805558195561e-09, std=3.262575046392158e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-2.415782319076243e-06, std=3.2632884540362284e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=6.565487709053741e-09, std=0.00015829407493583858\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-2.9388729672064073e-07, std=9.482209134148434e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=3.587885544220626e-10, std=2.9586153686977923e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.935577529366128e-06, std=2.9018628993071616e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-9.963554248315631e-07, std=0.00034994512679986656\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.802016751957126e-06, std=0.0003960344474762678\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=2.7784635676653124e-06, std=0.0003879067371599376\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.0491639841347933e-06, std=0.0003763494605664164\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0017099219840019941, std=0.006547517143189907\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0007891782443039119, std=0.006465971004217863\n",
            "Grad stats for input_proj.weight: mean=-5.579577910808098e-10, std=3.72118016400691e-08\n",
            "Grad stats for input_proj.bias: mean=-3.0250086879846094e-09, std=1.307006698425539e-07\n",
            "Grad stats for output_head.0.weight: mean=-1.3929129636380821e-06, std=0.012271998450160027\n",
            "Grad stats for output_head.0.bias: mean=0.0017856196500360966, std=0.012697129510343075\n",
            "Grad stats for output_head.2.weight: mean=0.0006364951259456575, std=0.03927058354020119\n",
            "Grad stats for output_head.2.bias: mean=0.0026681022718548775, std=0.07031995058059692\n",
            "Batch 90, Loss: 0.8209488391876221\n",
            "Hungarian matching: row_ind=[14], col_ind=[0]\n",
            "conf_loss: 0.22149574756622314, smooth_l1_loss: 0.002854106482118368, ciou_loss: 0.6447639465332031, box_loss: 0.32380902767181396\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=6.885527703559546e-10, std=3.268449972892995e-06\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-2.3480019706312305e-07, std=1.853471803769935e-05\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=7.764457521375334e-09, std=1.9405979401199147e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-9.538575795886572e-07, std=2.5040057153091766e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-9.033196413099631e-11, std=3.4101185519830324e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=4.2967656099790474e-08, std=3.8068847629801894e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.32153052390116e-10, std=3.2991914622471086e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=5.390550228412394e-10, std=1.0029270924860612e-06\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.3014243904763134e-08, std=4.210871338727884e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.830275747101041e-08, std=4.836606876779115e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.1220591034089011e-07, std=2.156929667762597e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-9.0904627825239e-08, std=2.6908967356575886e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.8320826800088952e-10, std=7.74891475430195e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=7.808640845041737e-08, std=9.10228663997259e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-6.066962487949468e-10, std=1.6836987697388395e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-4.772789452545112e-08, std=1.990965074583073e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-3.879607746171132e-11, std=2.9980779459037876e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=4.741657377849151e-08, std=3.264302108618722e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.5029824496082256e-08, std=9.949540071829688e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=3.630798417475489e-08, std=1.4087049748923164e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.497878253710951e-08, std=2.752057071120362e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=5.3464145111092876e-08, std=3.449783889664104e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-4.1091340108323493e-07, std=1.0828613085323013e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=5.849187800777145e-07, std=1.5312343748519197e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.4412353522306205e-10, std=3.5105308597849216e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.969020324097073e-07, std=4.641602572519332e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-3.737103071443926e-08, std=1.0130763257620856e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-4.3830422669088875e-07, std=1.3239407962828409e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=5.4232618396099497e-11, std=3.214437811038806e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-1.8278045388342434e-07, std=3.36447396875883e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.7269005070374988e-07, std=2.0437853891053237e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-2.743070126598468e-07, std=2.522322211007122e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=2.9616046504088445e-08, std=1.8758906662696972e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.1917159099539276e-06, std=3.1172581657301635e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-6.027676136000082e-06, std=0.0004430847184266895\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.4371366887644399e-05, std=0.0004119901277590543\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-2.1781147552246694e-08, std=0.00010934728925349191\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.0899534572672565e-05, std=0.00011434850603109226\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-4.207969084291108e-08, std=0.0006030274089425802\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=4.578612788463943e-06, std=0.0004098164790775627\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-4.652520146919414e-09, std=0.00012563157361000776\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=3.375241249159444e-06, std=0.0001255188399227336\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.258995234820759e-05, std=0.0014245436759665608\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-3.314216883154586e-05, std=0.001630857470445335\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-5.752954166382551e-06, std=0.001674966886639595\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-2.985849278047681e-05, std=0.0014430369483307004\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.005018807016313076, std=0.02603183686733246\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.001954725943505764, std=0.024750184267759323\n",
            "Grad stats for input_proj.weight: mean=-2.5127636149591126e-07, std=1.887765756691806e-05\n",
            "Grad stats for input_proj.bias: mean=-1.622297986614285e-06, std=8.035978680709377e-05\n",
            "Grad stats for output_head.0.weight: mean=6.520294846268371e-07, std=0.04432445392012596\n",
            "Grad stats for output_head.0.bias: mean=-0.000593983568251133, std=0.04826594144105911\n",
            "Grad stats for output_head.2.weight: mean=-0.004395142663270235, std=0.13258764147758484\n",
            "Grad stats for output_head.2.bias: mean=-0.019539272412657738, std=0.24727633595466614\n",
            "Hungarian matching: row_ind=[3], col_ind=[0]\n",
            "conf_loss: 0.21841835975646973, smooth_l1_loss: 0.0028920304030179977, ciou_loss: 0.734318733215332, box_loss: 0.368605375289917\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-9.740691098159004e-08, std=0.00014148645277600735\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=2.115564711857587e-05, std=0.0008587224874645472\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-6.562631682527353e-08, std=9.732007310958579e-05\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=9.257490091840737e-06, std=0.0011272323317825794\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-5.589217977330918e-10, std=1.028771475830581e-05\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.475910039516748e-06, std=1.092163165594684e-05\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.958599682438944e-07, std=5.832934220961761e-06\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.0763798172774841e-06, std=1.636138949834276e-05\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=4.591629476635717e-07, std=0.00017342648061458021\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.2620101844950113e-06, std=0.00020149446208961308\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=5.019252057536505e-06, std=2.8186002964503132e-05\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=9.405042646903894e-07, std=2.8712460334645584e-05\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=4.496805983134067e-10, std=6.1997779994271696e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=2.3550603600597242e-07, std=6.5106141846627e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.8479243852075342e-08, std=7.627642844454385e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-6.594631258849404e-07, std=1.323197557212552e-05\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-8.262190931418445e-11, std=1.1342682455506292e-06\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-2.842057611474047e-08, std=1.2981899999431334e-06\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-8.576916954439184e-09, std=1.9055009943258483e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-3.0783063209582906e-08, std=3.549067969288444e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=8.18442913441686e-08, std=1.3382910765358247e-05\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=7.531464234489249e-07, std=1.5137412447074894e-05\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=1.0486807013876387e-06, std=1.704136229818687e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=4.277544007891265e-07, std=2.351033253944479e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.9157860020602158e-10, std=6.109547939558979e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.928740509058116e-07, std=6.863342605356593e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=7.840231797118236e-10, std=1.8209906556876376e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-4.044949264425668e-09, std=1.859606709331274e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=6.362466109521847e-12, std=5.192471235204721e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=5.118224066791299e-09, std=5.4500069381901994e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.0076916368007005e-07, std=2.1059831851744093e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-2.190224677178776e-07, std=2.058534482785035e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-9.042241799761541e-08, std=3.771338742808439e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=3.4309329066672944e-07, std=4.3642285163514316e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=4.183833880233578e-06, std=0.0004011435084976256\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.905468525364995e-05, std=0.00039850606117397547\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-8.567018205951626e-09, std=0.00011172428639838472\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=5.664566629093315e-07, std=0.00011512485070852563\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=1.1989936865575146e-07, std=0.0005517695681191981\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.2876403161499184e-06, std=0.00035849082632921636\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.2380106656783028e-09, std=0.00010716828546719626\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=4.275672836229205e-06, std=0.00010663863940862939\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.459076543142146e-06, std=0.001126107177697122\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=3.893967004842125e-06, std=0.0012808040482923388\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-8.229006198234856e-06, std=0.0009713246836327016\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-2.6663907192414626e-05, std=0.0012986353831365705\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.00404084799811244, std=0.01818707212805748\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0019585881382226944, std=0.019711202010512352\n",
            "Grad stats for input_proj.weight: mean=1.672698272159323e-05, std=0.0008340850472450256\n",
            "Grad stats for input_proj.bias: mean=0.00011768468539230525, std=0.003829586785286665\n",
            "Grad stats for output_head.0.weight: mean=-2.1954620024189353e-06, std=0.04015672579407692\n",
            "Grad stats for output_head.0.bias: mean=0.0016327135963365436, std=0.043395284563302994\n",
            "Grad stats for output_head.2.weight: mean=0.005416433792561293, std=0.10368678718805313\n",
            "Grad stats for output_head.2.bias: mean=0.023732654750347137, std=0.19083675742149353\n",
            "Hungarian matching: row_ind=[ 0  2 16], col_ind=[1 0 2]\n",
            "conf_loss: 0.40094342827796936, smooth_l1_loss: 0.03594135865569115, ciou_loss: 1.1443489789962769, box_loss: 0.5901451706886292\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-1.8551649105802426e-10, std=8.738590622670017e-06\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=6.518455961668224e-07, std=4.9588707042858005e-05\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-2.887746430868532e-10, std=5.60989610676188e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=2.2012898170942208e-08, std=6.36909608147107e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-6.545886055420169e-11, std=6.365358444782032e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-7.356854325735185e-08, std=6.427046628232347e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.3768205181795565e-09, std=3.525452143549046e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.2925731596169499e-08, std=9.349654419565923e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.6868974600802176e-08, std=9.953421795216855e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.0517038617763319e-07, std=1.1374813766451553e-05\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.515110395506781e-07, std=1.5553118828393053e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=9.851829929630185e-08, std=1.640621690057742e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=3.286040536898405e-11, std=4.021306381218892e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.3246443053560597e-08, std=4.034658047658013e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-7.255042122622513e-10, std=4.451441100172815e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.18230989443191e-08, std=6.115389510341629e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.2897252710253326e-12, std=6.855330525468162e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-5.637984745732183e-09, std=6.420156495323681e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=3.3670057852930313e-09, std=2.425366574243526e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.1517752085410393e-08, std=3.685405260966945e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.990315467992332e-09, std=6.403653856068559e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=2.2360710616453616e-08, std=6.799481866437418e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=4.646521034601392e-08, std=2.505810016373289e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-5.879741138414829e-09, std=3.5549578569771256e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.5431952590794218e-11, std=7.934507380014111e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-5.570720773562243e-09, std=9.72796328824188e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=7.36391214672949e-09, std=2.7946791760768974e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=6.249719319839642e-08, std=3.0165483622113243e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-5.202449582242252e-12, std=8.670532452015323e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-2.9382482225059903e-08, std=9.072737157111987e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.306747859392999e-08, std=6.812482297391398e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-5.390997159793187e-08, std=7.307453870453173e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.79392145582824e-08, std=6.164205842651427e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.3479561289386766e-07, std=7.2775333137542475e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=6.144240387584432e-07, std=0.00014866610581520945\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.4823376659478527e-06, std=0.00012609393161255866\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=3.5766045680674097e-09, std=3.8621034036623314e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-8.588756941207976e-07, std=4.049422204843722e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-8.528097339421947e-09, std=0.00019582205277401954\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=8.847459866956342e-07, std=0.00012984086060896516\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.714692470817681e-09, std=4.17405208281707e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=3.841858415398747e-06, std=4.12745212088339e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=6.075447345210705e-07, std=0.0004824737261515111\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.5291197996702977e-06, std=0.0005548259941861033\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-5.690902980859391e-06, std=0.0005870845052413642\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=6.567380296473857e-06, std=0.00046929591917432845\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.005504037253558636, std=0.011692741885781288\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0002951567876152694, std=0.010208958759903908\n",
            "Grad stats for input_proj.weight: mean=6.567613581864862e-07, std=5.691559999831952e-05\n",
            "Grad stats for input_proj.bias: mean=3.941296199627686e-06, std=0.0002175716363126412\n",
            "Grad stats for output_head.0.weight: mean=4.019901098217815e-06, std=0.016274750232696533\n",
            "Grad stats for output_head.0.bias: mean=-0.0035671605728566647, std=0.017290422692894936\n",
            "Grad stats for output_head.2.weight: mean=-0.002827534917742014, std=0.03850458562374115\n",
            "Grad stats for output_head.2.bias: mean=-0.012489224784076214, std=0.07111925631761551\n",
            "Hungarian matching: row_ind=[19], col_ind=[0]\n",
            "conf_loss: 0.2203861027956009, smooth_l1_loss: 0.0027563879266381264, ciou_loss: 0.5248208045959473, box_loss: 0.2637886106967926\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-1.551441891622929e-10, std=2.9839353032912186e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=4.311348789087788e-08, std=1.3954246469438658e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-2.8544616670345135e-10, std=3.277743019225454e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=2.6117469076325506e-08, std=2.1976291009195847e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-2.8456854928027298e-12, std=7.225269627042508e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-8.777482074506793e-10, std=8.064743184377221e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-9.864651318025608e-10, std=1.103719995398933e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-3.154990491083254e-09, std=1.8918372290954721e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.7901236876459734e-09, std=4.3773241031885846e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=1.5292956234702615e-08, std=5.450346520774474e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-3.2365043978188623e-08, std=1.2805548976757564e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=2.9221617126040655e-08, std=1.2778415339198546e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-4.211468326853485e-11, std=3.919894595583173e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-1.5822537946519333e-08, std=4.0315435967386293e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.4274142695901446e-09, std=1.113955477194395e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=2.8727415113394272e-08, std=9.244539000974328e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=1.9077295299041452e-11, std=2.0212290507970465e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-2.3168496454673004e-08, std=2.0510117337835254e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.587266401121724e-09, std=6.39534675883624e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-4.9788515532611655e-09, std=7.052894943626598e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-2.287492861796636e-08, std=1.8457540136296302e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-3.742768228676141e-08, std=1.923453964991495e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-4.4509732788355905e-08, std=7.970002116053365e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-5.549234316504226e-08, std=8.865120435075369e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-6.67733993098274e-11, std=2.583571813374874e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-9.775477138873612e-08, std=2.6811355837708106e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.5046406787178057e-08, std=9.071552995010279e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.250865295787662e-07, std=7.02293255017139e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-1.4997336705846465e-11, std=2.4340840809600195e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=4.7380659395912517e-08, std=2.500821892681415e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.7564578058681946e-07, std=1.6269545085378923e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=2.0157568769718637e-07, std=1.3869696886104066e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.317594625215861e-08, std=1.80844926944701e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.8495929882410564e-07, std=1.870226697064936e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-4.39827999798581e-07, std=0.0003160656779073179\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=7.893570000305772e-06, std=0.0002779543283395469\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-1.0665459626579832e-09, std=9.293754555983469e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=7.691122050346166e-07, std=9.377489914186299e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-4.454785766938585e-07, std=0.00046630206634290516\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=4.241595888743177e-06, std=0.0002889410243369639\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.6728325391568433e-09, std=9.205935202771798e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.5363968941528583e-06, std=8.955634257290512e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-4.069552232977003e-06, std=0.0010423589264973998\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-1.1633977919700556e-05, std=0.0011722635244950652\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-5.351648724172264e-07, std=0.0011697852751240134\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.6992635210044682e-05, std=0.0011207596398890018\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0011265715584158897, std=0.01696106791496277\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.001066325232386589, std=0.01869252137839794\n",
            "Grad stats for input_proj.weight: mean=2.3494241219168543e-08, std=2.0542170204862487e-06\n",
            "Grad stats for input_proj.bias: mean=1.0783478643361377e-07, std=5.8289538173994515e-06\n",
            "Grad stats for output_head.0.weight: mean=1.8208047549705952e-06, std=0.0454004630446434\n",
            "Grad stats for output_head.0.bias: mean=-0.0019971905276179314, std=0.04807617887854576\n",
            "Grad stats for output_head.2.weight: mean=-0.001077095395885408, std=0.10659338533878326\n",
            "Grad stats for output_head.2.bias: mean=-0.004622285254299641, std=0.19586816430091858\n",
            "Hungarian matching: row_ind=[ 3 12], col_ind=[0 1]\n",
            "conf_loss: 0.3060707449913025, smooth_l1_loss: 0.010802391916513443, ciou_loss: 1.0160562992095947, box_loss: 0.5134293437004089\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=4.278147280878386e-11, std=2.410789079476672e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=8.094967363092564e-09, std=1.2645739388972288e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-2.1989303433667118e-10, std=2.1034857411450503e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=3.854772501199477e-08, std=2.397020352873369e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.0539264733443474e-12, std=3.893335787097385e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.3313947722082276e-09, std=4.763071004276753e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.0838110964250802e-10, std=6.342970237938061e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=8.827125697052907e-10, std=1.749882727608565e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=5.321820761849949e-10, std=3.9305149357460323e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=1.4856796681783635e-08, std=4.661771413339011e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.1332347504833251e-08, std=4.587238890962908e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-4.485155358224802e-09, std=6.308364390861243e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-4.254467004388696e-12, std=1.2750592759402934e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-7.443129224071754e-09, std=1.8771191889754846e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.5339503278699596e-10, std=4.062677874117071e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.7581909261821238e-09, std=4.57450880730903e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=3.682096294532755e-12, std=8.173985577286658e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-8.158377085010216e-09, std=8.800478212833696e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=9.95201698827941e-10, std=4.211044881685666e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.9907405441065293e-09, std=6.326826564873045e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=9.37671273959495e-10, std=7.080520276758762e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-3.9644454830067843e-08, std=8.622037626082601e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-3.417636662561563e-08, std=4.738032657769509e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-4.171174339262507e-08, std=5.667479854309931e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=6.599402274654054e-11, std=1.7241525256395107e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-9.031938219550284e-08, std=1.9881597381754545e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-4.021520005892398e-09, std=6.1992413975531235e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.395505222490101e-08, std=5.080694791104179e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-5.452971407748919e-12, std=1.1411057130317204e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-4.005924125749516e-08, std=1.1622768170127529e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=5.3263393695601735e-09, std=8.712181625014637e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=2.6716620027400495e-08, std=1.1508076568134129e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-2.297856838140433e-08, std=1.2818757568311412e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.7057806189768598e-07, std=1.3285971363075078e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-5.036915808886988e-07, std=0.00013915292220190167\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=4.1359135138918646e-06, std=0.00013310804206412286\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=8.431300102529349e-11, std=3.87709733331576e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.423801959139382e-07, std=4.0444694604957476e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=9.56538048768607e-09, std=0.0001754627883201465\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-3.6917583656759234e-08, std=0.00013225525617599487\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.6000890329669346e-10, std=3.598100011004135e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.7198796058437438e-06, std=3.54940457327757e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.3914961982663954e-06, std=0.0003667323908302933\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=4.070508111908566e-06, std=0.0004484678211156279\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-3.397309001229587e-06, std=0.0005110689671710134\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=5.366353434510529e-06, std=0.000418285490013659\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0003079329617321491, std=0.006352595053613186\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.000682653218973428, std=0.006207836326211691\n",
            "Grad stats for input_proj.weight: mean=1.1027506019445354e-08, std=1.4755106576558319e-06\n",
            "Grad stats for input_proj.bias: mean=6.432034638237383e-08, std=5.1206370699219406e-06\n",
            "Grad stats for output_head.0.weight: mean=-1.8571972759673372e-07, std=0.013620373792946339\n",
            "Grad stats for output_head.0.bias: mean=0.0001861030759755522, std=0.014680806547403336\n",
            "Grad stats for output_head.2.weight: mean=4.70736158604268e-05, std=0.030341684818267822\n",
            "Grad stats for output_head.2.bias: mean=0.00020729511743411422, std=0.05648517236113548\n",
            "Hungarian matching: row_ind=[10 14 16 18], col_ind=[0 1 2 3]\n",
            "conf_loss: 0.4714118540287018, smooth_l1_loss: 0.012113455682992935, ciou_loss: 0.9905091524124146, box_loss: 0.5013113021850586\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-8.3215510870982e-11, std=1.42211638376466e-06\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.4422430183458346e-07, std=7.809283488313667e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=6.932021623384799e-11, std=1.2126185993110994e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.8587343220133334e-07, std=1.2182706086605322e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-5.43315392675936e-13, std=1.6557864057631377e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=4.303472245226203e-09, std=1.9376923887648445e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-2.1689094964472133e-09, std=3.325064312775794e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-8.299059217620197e-09, std=6.992477210587822e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=3.527656389223921e-09, std=1.844377038651146e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=3.014373106680068e-08, std=2.3821735339879524e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=5.49402443539293e-08, std=3.2691816613805713e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=9.246014087693766e-08, std=3.2058710530691314e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=7.298457845028583e-12, std=8.75845785230922e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-5.7046477763833536e-08, std=9.280717563342478e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-3.4430804873863963e-09, std=2.830713356161141e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=2.640404517251227e-08, std=2.432595692880568e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=1.889888245898419e-11, std=5.62450225061184e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-2.922373631975006e-08, std=5.7949608844865e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.87429116671467e-09, std=1.1079850992246065e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-4.566828692986746e-09, std=1.4976532156651956e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.818552502503735e-09, std=4.549615823634667e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-4.385879890378419e-07, std=4.842999715037877e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=2.1548852657815587e-07, std=1.1830529729195405e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.000888343900442e-09, std=1.3989012586534955e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=4.180880919246732e-10, std=4.1568896449462045e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-4.135496283197426e-07, std=4.249201083439402e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-7.066991436488479e-10, std=1.570152016938664e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=2.47875675540854e-08, std=1.176892237708671e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-9.957812352467954e-12, std=3.1000834042060887e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.3366936002512375e-07, std=3.149263875457109e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-5.6783058255405194e-08, std=1.0775730515888426e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.6385351386816183e-07, std=1.3703262084163725e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=2.478954002071987e-07, std=2.599523577373475e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-2.0127026800764725e-06, std=2.957087053800933e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.2305106287822127e-06, std=0.00013533308811020106\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-3.503381094560609e-06, std=0.00014780422498006374\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=2.1226753688097233e-10, std=4.502983210841194e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.5576853229504195e-06, std=4.529559737420641e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=1.1737459004734774e-08, std=0.0001440109481336549\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.0138396646652836e-06, std=0.00011204170732526109\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=8.225526926253224e-10, std=3.4795539249898866e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.6556678019696847e-06, std=3.379832924110815e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.5504381281061796e-06, std=0.00028369470965117216\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=4.609523784893099e-06, std=0.00035498326178640127\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-3.8664202293148264e-06, std=0.00034668666194193065\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=3.937745532311965e-06, std=0.00034257207880727947\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0015589697286486626, std=0.00420641852542758\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.00055070617236197, std=0.004910361487418413\n",
            "Grad stats for input_proj.weight: mean=-1.0890697410559369e-07, std=8.844910553307272e-06\n",
            "Grad stats for input_proj.bias: mean=-6.906678891027695e-07, std=3.490424569463357e-05\n",
            "Grad stats for output_head.0.weight: mean=1.6084723029052839e-06, std=0.008770284242928028\n",
            "Grad stats for output_head.0.bias: mean=-0.0011162306182086468, std=0.009589685127139091\n",
            "Grad stats for output_head.2.weight: mean=-0.0010766659397631884, std=0.022300560027360916\n",
            "Grad stats for output_head.2.bias: mean=-0.004944853484630585, std=0.04193105176091194\n",
            "Hungarian matching: row_ind=[10 12], col_ind=[0 1]\n",
            "conf_loss: 0.3046303689479828, smooth_l1_loss: 0.01333458349108696, ciou_loss: 1.03428053855896, box_loss: 0.5238075852394104\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.4465109665628972e-11, std=1.0756927082411494e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=7.291459103164755e-10, std=5.52638880435552e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=3.4247177316260036e-10, std=2.31179299703399e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.6367751598522773e-08, std=1.8015816749539226e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=6.437576166584691e-13, std=6.28823570991699e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=4.2639303199365486e-10, std=7.46859569744629e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-3.9672126694867416e-10, std=1.1766576335503487e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-6.771188054699451e-10, std=1.734828884991657e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.4268577430698315e-09, std=3.5933621234107704e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=1.6319640749884456e-08, std=4.117177923035342e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-2.111634955781483e-08, std=1.624713604542194e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-5.929905455559492e-10, std=1.5309570926547167e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-6.211775538389475e-11, std=4.7440971684409305e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-2.9139760826524252e-08, std=4.841670602218073e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-5.498938526748987e-10, std=1.3396062286119559e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-5.542646341893942e-09, std=1.0580160960671492e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=5.068723218926152e-11, std=2.3424901485213923e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-4.026423283676195e-08, std=2.3582802555210947e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.3279052302195282e-09, std=6.028166694704851e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.609488181093411e-09, std=6.796649927309772e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-2.853033720384701e-08, std=2.3215782221086556e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-4.660082808527477e-08, std=2.395498768237303e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=1.534112925583031e-08, std=7.2155953603214584e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-2.2097057694736577e-07, std=8.502424861944746e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.5302070721645578e-10, std=2.602095719339559e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.4632000500114373e-07, std=2.718851874305983e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-6.251471007523435e-10, std=8.010584679141175e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-3.886800215013864e-09, std=6.405936801456846e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-9.272138612459457e-12, std=1.929257905430859e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.0825130658531634e-07, std=1.977538431674475e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=3.0291045227670566e-09, std=7.0715595938963816e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=3.421000371872651e-09, std=6.021007720846683e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-4.045111268169421e-08, std=1.6849671737872995e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.3459669762360136e-07, std=1.623322350496892e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-2.045408109552227e-07, std=0.00012202807556604967\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.962659664262901e-06, std=0.00012137165322201326\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-4.64083393936221e-09, std=3.9976883272174746e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.616815436340403e-06, std=4.0230177546618506e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=2.0132648614890059e-07, std=0.0001884211815195158\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-2.018067789322231e-06, std=0.00011402213567635044\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.6742571773420423e-09, std=3.4755259548546746e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=6.195253376972687e-07, std=3.44324616889935e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.014311578728666e-06, std=0.00040532322600483894\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=2.737903741945047e-06, std=0.0004573653859551996\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.493514901085291e-06, std=0.0005123639712110162\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=7.254536740219919e-06, std=0.00044803140917792916\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0028672590851783752, std=0.008183038793504238\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0003907943028025329, std=0.007588914595544338\n",
            "Grad stats for input_proj.weight: mean=3.901533762729059e-09, std=5.692295985681994e-07\n",
            "Grad stats for input_proj.bias: mean=1.9230441239415086e-08, std=1.8514613202569308e-06\n",
            "Grad stats for output_head.0.weight: mean=2.4748878786340356e-06, std=0.01661870628595352\n",
            "Grad stats for output_head.0.bias: mean=-0.0017735008150339127, std=0.017795206978917122\n",
            "Grad stats for output_head.2.weight: mean=-0.0009973290143534541, std=0.03497720882296562\n",
            "Grad stats for output_head.2.bias: mean=-0.004386426415294409, std=0.06438560783863068\n",
            "Hungarian matching: row_ind=[3], col_ind=[0]\n",
            "conf_loss: 0.21699626743793488, smooth_l1_loss: 0.0011340121272951365, ciou_loss: 0.45742902159690857, box_loss: 0.22928151488304138\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=3.3376339886315165e-11, std=5.781216145805956e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-6.929766271923654e-08, std=3.2201890007854672e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-1.6267045488405074e-09, std=9.55554128267977e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.4839316975212569e-07, std=1.0024060429714154e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=4.9814874447662305e-12, std=1.9894058311820118e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=1.1174893899124072e-08, std=2.730190544752986e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.276197230699495e-09, std=3.321714245885232e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=6.146475328705492e-09, std=8.274342917502508e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-2.251663744345933e-09, std=1.3831377145834267e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.0546369821895496e-07, std=1.9433186935202684e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.1633736107796722e-07, std=3.939671387342969e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.6028167237891466e-08, std=3.683256863951101e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.1251074377716108e-10, std=1.0549472335696919e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=5.586398188484054e-08, std=1.1020987358278944e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.923232322871172e-09, std=2.8326921892585233e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=2.6134955533052562e-08, std=2.5461879431531997e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-9.579270709991761e-11, std=5.417430770648934e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=9.43181959200956e-08, std=5.584548148362956e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-3.773262147177547e-09, std=1.723670493447571e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-7.951349800805474e-09, std=1.9926167169614928e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=6.070459335205669e-08, std=5.147885076439707e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.6966049543043482e-07, std=5.312349912856007e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=2.2841391000838485e-08, std=2.0919693270116113e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=8.829803164189798e-07, std=2.4782162654446438e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.941546256047701e-10, std=7.597264357173117e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=7.59218607981893e-07, std=7.939188435557298e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=7.940023749597458e-09, std=2.6560455808066763e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=3.7492384308279725e-08, std=2.1286939954734407e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-6.084777126602603e-11, std=7.251384431583574e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.8946286672871793e-07, std=7.4455965659581125e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-4.292169819564151e-07, std=3.7692312616854906e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-4.981592951480707e-07, std=3.240002479287796e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.1772783636843087e-07, std=5.67765164305456e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=9.075512252820772e-08, std=5.168592178961262e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-8.2089190982515e-06, std=0.0005715592415072024\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=3.788270623772405e-05, std=0.0006486247293651104\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-2.3421401706968936e-08, std=0.00020750264229718596\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.0958819075312931e-05, std=0.00021147877851035446\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.1508866464282619e-06, std=0.0009811893105506897\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.1918687960132957e-05, std=0.0005921114352531731\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.909555180645839e-08, std=0.00021241071226540953\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.6582871467107907e-05, std=0.00021027315233368427\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-6.352170203172136e-06, std=0.002372007817029953\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-1.7058453522622585e-05, std=0.0026817384641617537\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.3445725673809648e-05, std=0.0022392584942281246\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.6111724107759073e-05, std=0.0023760951589792967\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.002484143478795886, std=0.039853207767009735\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0005068553145974874, std=0.04093215987086296\n",
            "Grad stats for input_proj.weight: mean=-6.838445365531243e-09, std=2.700918230402749e-06\n",
            "Grad stats for input_proj.bias: mean=-3.406192661259411e-08, std=1.0110801667906344e-05\n",
            "Grad stats for output_head.0.weight: mean=2.1418454707600176e-06, std=0.07130604237318039\n",
            "Grad stats for output_head.0.bias: mean=-0.0019646037835627794, std=0.07579731941223145\n",
            "Grad stats for output_head.2.weight: mean=-0.003047928214073181, std=0.19669941067695618\n",
            "Grad stats for output_head.2.bias: mean=-0.013179637491703033, std=0.3617071807384491\n",
            "No targets: conf_loss=0.15287034213542938, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=5.5730808856679914e-11, std=8.797178452368826e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.282265316149278e-08, std=3.552533485162712e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=9.082828933415499e-11, std=1.1437914082534917e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.635834401270131e-08, std=7.204288294815342e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=4.1628506197710635e-13, std=2.8977092725313014e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.037683716731408e-09, std=2.9035494009121976e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.4550661503752735e-10, std=3.766750467093516e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=8.451819244470471e-10, std=6.448370726275243e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-2.3181434549712776e-10, std=1.630569528288106e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-6.729818924355868e-09, std=1.6575526728956902e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.6197888303158834e-09, std=4.2276789713469043e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-6.244772698948964e-09, std=3.9659420281168423e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=2.193447333487253e-11, std=1.3210765814619663e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=8.442303744971014e-09, std=1.3045458047145075e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.8492534170633235e-09, std=3.622368751621252e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.8528222511804415e-08, std=2.687587823402282e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.5990875290583517e-11, std=7.205146346223046e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=1.2066891486028908e-08, std=7.054881479007236e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.2196381682372248e-09, std=2.0208604212257342e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.4161332934369284e-09, std=2.142512585123768e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=7.740045049331457e-09, std=6.128183258624631e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=3.3899243412349733e-09, std=6.397501124411065e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-5.597783570010506e-09, std=2.398027390881907e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=1.233567203939856e-08, std=2.4748846954025794e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.3398468018974725e-11, std=8.24361961804243e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=7.944561986050758e-08, std=8.216277365136193e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=2.735766280181906e-09, std=2.590255462564528e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=2.287940148448797e-08, std=1.9312881249788916e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=3.3428537715707307e-12, std=6.684281288471539e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-6.5423280126708505e-09, std=6.680169235551148e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-6.305502608938696e-08, std=2.545837105571991e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-7.065612095402685e-08, std=2.0461275198613293e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-5.4137103688844945e-09, std=5.8245200307283085e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-8.119251759808321e-08, std=4.957004875905113e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.1287686397263315e-07, std=4.668785913963802e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.7694873122309218e-07, std=4.024738518637605e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-4.05163319561197e-10, std=1.3062316611467395e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.856124782761981e-07, std=1.274841542908689e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=1.673227600917926e-08, std=6.531083636218682e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-5.450100388770807e-07, std=4.0860319131752476e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.436177399227745e-09, std=1.3630756257043686e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.9028558426725795e-06, std=1.2933219295518938e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.1465538136690157e-06, std=0.00013932741421740502\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.9195016395533457e-06, std=0.00014352472499012947\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-7.745627499389229e-07, std=0.00021844191360287368\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=6.212152584339492e-06, std=0.000135967115056701\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0018199568148702383, std=0.004525508265942335\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.000172149229911156, std=0.002797059016302228\n",
            "Grad stats for input_proj.weight: mean=-7.2644579240943585e-09, std=5.185727331991075e-07\n",
            "Grad stats for input_proj.bias: mean=-3.364492329183122e-08, std=1.2758799812218058e-06\n",
            "Grad stats for output_head.0.weight: mean=3.495886630844325e-06, std=0.0036945934407413006\n",
            "Grad stats for output_head.0.bias: mean=-0.0017906144494190812, std=0.003371770028024912\n",
            "Grad stats for output_head.2.weight: mean=0.0002871394099202007, std=0.0017987259197980165\n",
            "Grad stats for output_head.2.bias: mean=0.0013967211125418544, std=0.003126993775367737\n",
            "Hungarian matching: row_ind=[ 8 11 15], col_ind=[1 0 2]\n",
            "conf_loss: 0.40390118956565857, smooth_l1_loss: 0.007391418796032667, ciou_loss: 0.737185001373291, box_loss: 0.37228819727897644\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=5.383018249899285e-12, std=2.3063712717430462e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-2.1041692832568515e-09, std=1.0088092494697776e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-2.02543641580899e-11, std=7.739843255194501e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=7.846834293445681e-10, std=3.189176140949712e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-3.7428697294283886e-13, std=2.4649855490110895e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.0458059418461119e-10, std=2.631972328970278e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-7.970678006508081e-10, std=5.4572467433899874e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.526356152581343e-09, std=5.72180738345196e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=6.005461683500357e-10, std=1.3594869585631386e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-9.637613374025022e-09, std=1.3505025719950936e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.2927900406320987e-09, std=7.930428296276659e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=2.4719728486388703e-09, std=7.223126772260002e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=2.8802960017060286e-11, std=2.1766142310752912e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.2979211483354902e-08, std=2.2069667693358497e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.1412161216028949e-09, std=6.167974220261385e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.3010455823803113e-08, std=4.93888705932477e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-2.263511600375523e-11, std=1.1299545832343938e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=2.03334487025586e-08, std=1.1306450176107319e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.920192976318958e-10, std=3.6123631730333727e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-5.983471496051607e-10, std=4.048220318964013e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.1361379392837989e-08, std=1.0235924037260702e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=2.0446105253313362e-08, std=1.0883802588068647e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.5528058838754077e-08, std=3.978122549597174e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.401136498519918e-07, std=4.9308814595860895e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=8.572401816175912e-11, std=1.4051339576326427e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=1.209286182302094e-07, std=1.4326125210573082e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=7.78271580514911e-09, std=5.333236003934871e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=7.219810527203663e-08, std=4.199164322926663e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.0130785099704553e-15, std=1.4905637044648756e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.108782132774877e-08, std=1.5170110145845683e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.2351902967111528e-07, std=1.026014160743216e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.3860051240044413e-07, std=8.554369742341805e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.0045653198176296e-09, std=1.0886567906709388e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-5.975977046546177e-08, std=1.0529516657697968e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-6.554409992531873e-08, std=0.0001907936530187726\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=3.3387561870767968e-06, std=0.000167391961440444\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-6.128070939581676e-09, std=5.3766289056511596e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=3.225637328796438e-06, std=5.344627425074577e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.0494011348782806e-07, std=0.0002875591453630477\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=8.172296475095209e-07, std=0.0001587782462593168\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.4629097933038793e-10, std=6.166523962747306e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-9.96188873614301e-07, std=5.9912305005127564e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=4.419259312271606e-06, std=0.0007514769677072763\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.174100543721579e-05, std=0.0008180089062079787\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-6.465206752181984e-07, std=0.0007731901132501662\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.599891038495116e-05, std=0.0006942693144083023\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0027004501316696405, std=0.014740046113729477\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0017359430203214288, std=0.012672058306634426\n",
            "Grad stats for input_proj.weight: mean=-3.842553497612755e-10, std=1.2256062120741262e-07\n",
            "Grad stats for input_proj.bias: mean=-1.7225469939319282e-09, std=3.49516284359197e-07\n",
            "Grad stats for output_head.0.weight: mean=-2.582281013019383e-06, std=0.020804161205887794\n",
            "Grad stats for output_head.0.bias: mean=0.0038860593922436237, std=0.021600358188152313\n",
            "Grad stats for output_head.2.weight: mean=0.0021488997153937817, std=0.05753004178404808\n",
            "Grad stats for output_head.2.bias: mean=0.009259997867047787, std=0.10506709665060043\n",
            "Batch 100, Loss: 0.776189386844635\n",
            "Hungarian matching: row_ind=[ 1 10], col_ind=[1 0]\n",
            "conf_loss: 0.29407185316085815, smooth_l1_loss: 0.003771167481318116, ciou_loss: 0.5453882217407227, box_loss: 0.2745797038078308\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=6.895604313245096e-12, std=3.845792662104941e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=4.513516227433456e-09, std=1.9950533669543802e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=4.745828730001733e-11, std=6.838079968929378e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-4.509260076446253e-09, std=5.350663059289218e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=6.034341862998227e-13, std=2.06171275607403e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=1.4756590394071623e-10, std=2.4275918164562427e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.6005918812567188e-10, std=4.0421195279805033e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-5.214875198333857e-10, std=5.7080807636111786e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-3.463378472901013e-10, std=1.0483131518412847e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=7.110040556312924e-09, std=1.250769798843976e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-8.999659684150174e-09, std=6.016214797455177e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=3.1934650479570337e-09, std=5.2156798346914e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-1.2259786068280487e-11, std=1.5703713529546803e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-7.0459695855618065e-09, std=1.5922252316613594e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-5.908745714933161e-13, std=4.3591523990471615e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.189675691293246e-09, std=3.646600532647426e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=1.8457402273241996e-11, std=7.973018512075214e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-1.6255309986945576e-08, std=7.994606932015813e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.5790930785186674e-09, std=3.2684121720194526e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-3.3447937752839607e-09, std=3.674290098842903e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-7.2758226110636315e-09, std=7.949506652948912e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-2.0759676644388492e-08, std=8.123301427076512e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.978150976356119e-10, std=4.2060351006512064e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-5.039585460053786e-08, std=4.8473384595126845e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-8.898926040501465e-11, std=1.476882403039781e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-9.174896575814273e-08, std=1.5189085615929798e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-3.6170635375754046e-09, std=5.22424534210586e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-3.433567030697304e-08, std=4.223476935294457e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=7.405631663459644e-12, std=1.5454462527486612e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-8.509761073582922e-08, std=1.5734983662696322e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=4.646488527271231e-09, std=8.610546501586214e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=5.398362645792076e-09, std=7.353652563324431e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=2.422558509351802e-08, std=1.2105128007533494e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.941082470897527e-07, std=1.044507462211186e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=1.1513416211528238e-06, std=0.0001365038042422384\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-4.879912012256682e-06, std=0.00014838334755040705\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=6.190266077510387e-10, std=4.016407547169365e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-2.7815460157398775e-07, std=4.0372618968831375e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=3.3621212480738905e-08, std=0.00021019246196374297\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-5.70529664400965e-07, std=0.00013338972348719835\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=2.964455347864714e-10, std=4.3839241698151454e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.911934361942258e-07, std=4.2959771235473454e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=2.229421909305529e-07, std=0.0005050317849963903\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=6.04803062742576e-07, std=0.000569454045034945\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=1.8095142877427861e-06, std=0.0005359621136449277\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.251761568710208e-05, std=0.0005339408526197076\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0004748653736896813, std=0.007812305819243193\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0007731554214842618, std=0.008779418654739857\n",
            "Grad stats for input_proj.weight: mean=3.0732034694835875e-09, std=2.0771535957919696e-07\n",
            "Grad stats for input_proj.bias: mean=1.6192018392757745e-08, std=6.731010557814443e-07\n",
            "Grad stats for output_head.0.weight: mean=-5.752881406806409e-07, std=0.01631752774119377\n",
            "Grad stats for output_head.0.bias: mean=0.0006676685297861695, std=0.017112476751208305\n",
            "Grad stats for output_head.2.weight: mean=0.00014491869660560042, std=0.04761162027716637\n",
            "Grad stats for output_head.2.bias: mean=0.0006192791624926031, std=0.0869889110326767\n",
            "No targets: conf_loss=0.1334708333015442, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=3.2447747266850513e-10, std=2.740507170528872e-06\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=3.556601484433486e-07, std=1.598139715497382e-05\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-6.738732238886769e-09, std=1.7874675677376217e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=8.649728897580644e-07, std=2.2458170860772952e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=1.2610607003082919e-11, std=1.8790026956594374e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.7104291316627496e-08, std=2.2086766193751828e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.5339667314151484e-09, std=1.395788444824575e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-9.110785015309375e-09, std=4.978747938366723e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.107079228290786e-08, std=3.712043280756916e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-5.865297225682298e-08, std=4.187145350442734e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.834258966937341e-09, std=5.047604076935386e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-2.8696833354047158e-08, std=9.088061005968484e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=3.558165914685496e-11, std=1.5664114982882893e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=2.7028329796507933e-08, std=2.593885994883749e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.4342599330419148e-10, std=4.084732552200876e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.3707239787663639e-09, std=6.537219974234176e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-5.4873328103610675e-12, std=9.250427979168308e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=1.0717362997070268e-08, std=1.0785667825530254e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.9754859970078087e-09, std=2.1778225800517248e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-6.178916045485039e-09, std=3.6482049381447723e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.5290711747061323e-09, std=5.949532351223752e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.370201243224074e-08, std=1.093433070309402e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-9.89669146633787e-09, std=1.934603233166854e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-4.692367383540841e-09, std=3.2208658922172617e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-4.968321934417652e-11, std=6.902955647092313e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=8.825548292179519e-08, std=9.362325954498374e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.0375819092800498e-09, std=2.372096105318633e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-6.347132597284144e-09, std=2.5600395474612014e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-6.7346128673762e-13, std=5.603389467978559e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-3.1617268803074694e-08, std=5.860601959284395e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=9.835898318044656e-09, std=2.379335910518421e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.986277808896375e-08, std=3.2445680062664906e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-5.5266426102207333e-08, std=4.247670858603669e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.5475597453805676e-07, std=6.5667495618981775e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.8081435655403766e-06, std=3.223676685593091e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=8.942391787059023e-07, std=4.0695413190405816e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-5.066051467217392e-10, std=1.159343355539022e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=7.032708708720747e-07, std=1.1995124623354059e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.8640769755838846e-09, std=4.4277683628024533e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.3718988611799432e-07, std=3.3474676456535235e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-3.779767610012641e-10, std=8.18442458694335e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=3.913718273906852e-07, std=8.12481994216796e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.7392957829542866e-07, std=8.854137558955699e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=4.354831162345363e-07, std=0.000107575673609972\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-7.001016228969092e-07, std=0.00010534418834140524\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=2.4169071366486605e-07, std=0.000106722982309293\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017228680662810802, std=0.004174654837697744\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=6.01359861320816e-05, std=0.0023922778200358152\n",
            "Grad stats for input_proj.weight: mean=2.3486114741899655e-07, std=1.8536284187575802e-05\n",
            "Grad stats for input_proj.bias: mean=1.4489504565062816e-06, std=7.335880218306556e-05\n",
            "Grad stats for output_head.0.weight: mean=1.4428187569137663e-06, std=0.0031106495298445225\n",
            "Grad stats for output_head.0.bias: mean=-0.001535051385872066, std=0.0029463768005371094\n",
            "Grad stats for output_head.2.weight: mean=0.000280717940768227, std=0.0016229227185249329\n",
            "Grad stats for output_head.2.bias: mean=0.0012310279998928308, std=0.002796898363158107\n",
            "Hungarian matching: row_ind=[0], col_ind=[0]\n",
            "conf_loss: 0.22665219008922577, smooth_l1_loss: 0.06127648800611496, ciou_loss: 1.2176628112792969, box_loss: 0.6394696235656738\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-8.429264231057942e-13, std=1.3908748819346783e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.1115193210287089e-09, std=7.572911897568702e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-1.796680339227752e-11, std=3.3946772504123146e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.1611418493373549e-09, std=2.2918221986856224e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-8.622547120751278e-13, std=1.040766761661871e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.9127242284765487e-10, std=1.1930188392739183e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-3.1086924701106966e-11, std=2.1364197522188988e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.9649448734782027e-11, std=2.7845382888358472e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.8757918268951244e-10, std=5.762150934174315e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.8946551822173205e-09, std=6.201974400710242e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=7.248047495522769e-09, std=3.067735860895482e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.289448713417187e-10, std=2.847619384738209e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.755807273137407e-12, std=8.732777700970473e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=4.6208725734686595e-09, std=8.854769362187653e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.4134294562827563e-10, std=2.4675873078194854e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=2.4768231909888527e-09, std=2.003456245347479e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-9.780010135074235e-12, std=4.743860770872743e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=8.808680007632574e-09, std=4.741033521327154e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.41804992695549e-10, std=1.5959010113419936e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-5.503503208714733e-10, std=1.7695499821002159e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=4.068635206522231e-09, std=4.4848860625279485e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.3509079188622763e-08, std=4.5626512701346655e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-3.858805897039019e-08, std=1.8907747971752542e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=6.2811125189909944e-09, std=2.151432454411406e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.578777907018658e-11, std=5.861141403329384e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=2.6398140562378103e-08, std=6.075495093682548e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-5.460159435699552e-09, std=2.1496705358003965e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-5.464044861014372e-08, std=1.7725013776725973e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=3.7414515929867775e-14, std=6.335473585750151e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=2.6886270987347416e-10, std=6.460383588091645e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-4.2331368632630983e-08, std=3.636286010078038e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-4.8441592070957995e-08, std=3.049165115953656e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=3.82102882667823e-09, std=4.521222308540018e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.744829513152581e-08, std=4.3517325138964225e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=2.0351535567897372e-07, std=6.392307113856077e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-6.867035153845791e-07, std=6.231560837477446e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=1.911684366362465e-09, std=2.0969193428754807e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.0185050314248656e-06, std=2.1195934095885605e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=8.82742341445919e-08, std=0.0001048013218678534\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-7.656335583305918e-07, std=6.146345549495891e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=1.9775558968149198e-10, std=2.2309952328214422e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=6.570346045009501e-07, std=2.2006212020642124e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.27505745695089e-06, std=0.0002578527492005378\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-3.458524588495493e-06, std=0.0002967217587865889\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=3.3034848456736654e-07, std=0.00023671284725423902\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-5.5282625908148475e-06, std=0.0002614052500575781\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.001660723821260035, std=0.006364361383020878\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-9.998329915106297e-05, std=0.004667769186198711\n",
            "Grad stats for input_proj.weight: mean=-1.1782915754210421e-09, std=7.333067486570144e-08\n",
            "Grad stats for input_proj.bias: mean=-6.363630511430074e-09, std=2.570688764080842e-07\n",
            "Grad stats for output_head.0.weight: mean=1.0973235475830734e-06, std=0.008831251412630081\n",
            "Grad stats for output_head.0.bias: mean=-0.0013622671831399202, std=0.009368871338665485\n",
            "Grad stats for output_head.2.weight: mean=6.116474833106622e-05, std=0.019190127030014992\n",
            "Grad stats for output_head.2.bias: mean=0.00027124007465317845, std=0.03567221388220787\n",
            "No targets: conf_loss=0.13302595913410187, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.9583612075740886e-12, std=2.2786148079489976e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=4.5267226078671285e-10, std=1.22765882792919e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=6.145434855442389e-11, std=4.097482886322723e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-3.315248742197241e-09, std=3.762056905998179e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=1.4113666832460403e-13, std=1.0965638175264303e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=3.9341502278134044e-11, std=1.3283806055142122e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.124850143585654e-10, std=1.8889053876591788e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=3.688558347647586e-10, std=3.418984206859932e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.0946255013521977e-10, std=6.336379954063887e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-4.5784442903595846e-09, std=7.74924657775955e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.2913368979970983e-09, std=2.668178353815165e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=5.977041084292978e-11, std=2.4418571342721407e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.0482698042935112e-11, std=7.152057435177994e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=5.0718882427247536e-09, std=7.44838501987033e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=8.927129868663286e-11, std=2.0223637875460554e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=8.958526698243929e-10, std=1.673787153322337e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.1324358117903444e-11, std=3.640736423449198e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=8.236718862519865e-09, std=3.653735802799929e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=2.6441171474544944e-10, std=1.0841482378509681e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=5.114593193411565e-10, std=1.2413617866968707e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.552647953597443e-09, std=3.687525236273359e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.1394062582326114e-08, std=3.722853421095351e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-8.931593242778035e-10, std=1.449279466214648e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=3.6089122801286067e-08, std=1.5037434195619426e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.5747922891006247e-11, std=4.3522564396880625e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.6429917688328715e-08, std=4.5166962081566453e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-2.0435577674504657e-09, std=1.4113797988102306e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-2.1745240275095057e-08, std=1.135525735662668e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.109883018823865e-12, std=3.7655826190530206e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-8.651580563068251e-10, std=3.884480577198701e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=8.821883668019836e-09, std=1.4306626781035447e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.0184989740480432e-08, std=1.2304219580983045e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.570800792360387e-09, std=3.118102313237614e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-2.2883764216885538e-08, std=2.8704923806799343e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-2.1416371964733116e-07, std=2.707369640120305e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=2.4658709207869833e-07, std=2.5270081096095964e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-4.935201691758095e-10, std=7.834085408831015e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.256018802881954e-07, std=8.119995982269756e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.8788962325165812e-09, std=3.78369222744368e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.8906575860455632e-08, std=2.359012796659954e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.2500738222342989e-09, std=7.347648079303326e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=7.675594133615959e-07, std=7.2626321525604e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=6.368547929014312e-07, std=8.925911242840812e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.6827125364216045e-06, std=9.979848255170509e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.0390294846729375e-06, std=0.00010531690350035205\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.3583141935669119e-06, std=9.2842907179147e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.001720498432405293, std=0.004094179719686508\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.924584183958359e-05, std=0.002384188584983349\n",
            "Grad stats for input_proj.weight: mean=-1.1221340523448475e-09, std=1.2287260631183017e-07\n",
            "Grad stats for input_proj.bias: mean=-6.69480382242682e-09, std=4.332975436227571e-07\n",
            "Grad stats for output_head.0.weight: mean=1.577434886712581e-06, std=0.003068353747949004\n",
            "Grad stats for output_head.0.bias: mean=-0.0015293480828404427, std=0.002935894764959812\n",
            "Grad stats for output_head.2.weight: mean=0.0002799274225253612, std=0.001616535591892898\n",
            "Grad stats for output_head.2.bias: mean=0.001227141940034926, std=0.0027897958643734455\n",
            "Hungarian matching: row_ind=[ 0  1  3 14], col_ind=[3 0 2 1]\n",
            "conf_loss: 0.47559747099876404, smooth_l1_loss: 0.03269527107477188, ciou_loss: 1.1110551357269287, box_loss: 0.5718752145767212\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-5.61116327013611e-11, std=1.3503323259556055e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=1.5440305034530866e-08, std=7.735791882623744e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=4.3951363382088715e-11, std=2.041322204604512e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-4.996472569018806e-09, std=2.1658668174495688e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-4.911487883063614e-13, std=4.536273223720855e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.9702524056697257e-09, std=6.217720738277421e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-7.552561354096099e-10, std=8.171723209215997e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-2.6450237555764033e-09, std=1.8287431657881825e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=9.403500200733106e-10, std=3.1591807214681467e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=1.594670706595025e-08, std=4.368418444755662e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-2.9416831637263385e-08, std=1.0093467608385254e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=3.4875160537239935e-09, std=9.794996458367677e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-4.7605180214516096e-11, std=2.7590797913035203e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-2.1025167384891574e-08, std=2.9197724416007986e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-4.5754783295492985e-10, std=7.757348043924139e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-5.68840352599409e-09, std=6.908374530212313e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.147093614013329e-11, std=1.4349845400829508e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-2.2545714628563474e-08, std=1.4764434297376283e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=3.0532492090173946e-09, std=4.573336411795026e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=6.278882747068337e-09, std=5.188950353840482e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.6645053335651028e-08, std=1.3820164213029784e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-2.0547297197026637e-08, std=1.4251367019824102e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=6.479112357737904e-09, std=5.5430941756640095e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-2.1549801942910563e-07, std=6.616678547288757e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.1713148506675708e-10, std=1.872237248790043e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-2.268948975370222e-07, std=1.9403814803808928e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-8.940624240949546e-09, std=6.770010713808006e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-8.392120776079537e-08, std=5.467060418595793e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.72973857459624e-11, std=1.9494295884214807e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-5.009361814245494e-08, std=2.0031093299621716e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.5107825390714424e-07, std=1.0333154023101088e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.755431924266304e-07, std=8.886516297934577e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=6.085707582315081e-08, std=1.489927035436267e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=5.138428491591185e-07, std=1.4262699551181868e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=1.7248748918063939e-06, std=0.00016320364375133067\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-5.158465683052782e-06, std=0.0001811768306652084\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=8.025381248444319e-09, std=5.845102350576781e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-3.651512088254094e-06, std=5.86859168834053e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.9347849544715245e-08, std=0.00029626389732584357\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=3.894174369634129e-07, std=0.0001809978421078995\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=2.5514879098409438e-09, std=6.011560617480427e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-3.673910669022007e-06, std=5.91672578593716e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=2.447735596433631e-06, std=0.0007072656298987567\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=6.3382904045283794e-06, std=0.0007960115326568484\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=8.47979390528053e-06, std=0.0007818706217221916\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=2.3260294256033376e-05, std=0.0007179029635153711\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0033412796910852194, std=0.012236509472131729\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-7.976859342306852e-05, std=0.012417097575962543\n",
            "Grad stats for input_proj.weight: mean=1.2051230235954336e-08, std=6.714075198033242e-07\n",
            "Grad stats for input_proj.bias: mean=7.154851999757739e-08, std=2.6179366159340134e-06\n",
            "Grad stats for output_head.0.weight: mean=-2.2830499801784754e-07, std=0.019826389849185944\n",
            "Grad stats for output_head.0.bias: mean=0.0021600055042654276, std=0.021544907242059708\n",
            "Grad stats for output_head.2.weight: mean=0.002438105409964919, std=0.046953413635492325\n",
            "Grad stats for output_head.2.bias: mean=0.010784310288727283, std=0.08815746009349823\n",
            "Hungarian matching: row_ind=[17], col_ind=[0]\n",
            "conf_loss: 0.20621350407600403, smooth_l1_loss: 0.0018233980517834425, ciou_loss: 0.46160900592803955, box_loss: 0.23171620070934296\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=7.687275295487073e-12, std=3.6027671512783854e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.5982583034812592e-09, std=1.8646271371380863e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=3.960738681474396e-11, std=9.532129752187757e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-3.6608041042995865e-09, std=5.423718789643317e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=6.62834370723786e-13, std=3.014154259517454e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=2.3821189465422776e-10, std=3.336920784136055e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=7.425648984593636e-10, std=6.824504339419946e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.4060159703177533e-09, std=7.444279503943108e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=5.507198030940685e-10, std=1.6508691658145835e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-9.358362973443946e-09, std=1.7545332298141147e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-2.4472583959322947e-09, std=1.0233610510113067e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.3358345540837036e-09, std=9.458987051402801e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=4.170404646619552e-11, std=2.8880285185550747e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.8599459750134884e-08, std=2.938051864020963e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-4.5810599758056014e-10, std=8.068560077845177e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-8.038888665851118e-09, std=6.376479859682149e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.3980289148562974e-11, std=1.5453021262601396e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=1.3580038427107866e-08, std=1.5657845153782546e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.121227732880925e-08, std=4.885407633992145e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.2472047334076706e-08, std=5.519782462215517e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.6940063574111264e-08, std=1.4304957858257694e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=2.151373834635706e-08, std=1.4825828884568182e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-2.945588306602076e-08, std=5.410572612163378e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.580788418526936e-07, std=6.704523912048899e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.4164432127206084e-10, std=1.931965471158037e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=1.3797072995203052e-07, std=2.021092996074003e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-8.71193250873148e-09, std=6.413787104975199e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-9.327375494194712e-08, std=5.538999175769277e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=6.118661133314163e-12, std=1.7043232674041064e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-1.7533076857034757e-07, std=1.7484260297351284e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=9.287909819022389e-08, std=1.0535844921832904e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.1060619442559982e-07, std=9.080546988116112e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=3.4261887549291714e-08, std=1.1450397323642392e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-5.820559749736276e-07, std=1.3040128578722943e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-6.174485633891891e-07, std=0.0001837767194956541\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=8.697738849150483e-07, std=0.00018547827494330704\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=2.578768087957428e-09, std=5.3662552090827376e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.5153314052440692e-06, std=5.427010910352692e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.2627754131244728e-07, std=0.0002925986482296139\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.4983634173404425e-06, std=0.00018184383225161582\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.2866117060639226e-09, std=6.25753091298975e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.3076765981168137e-06, std=6.057973223505542e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=6.062826287234202e-06, std=0.0007270395872183144\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.6014784705475904e-05, std=0.0008067523594945669\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.1475458450149745e-06, std=0.0006214305758476257\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.8629212718224153e-05, std=0.0007115470361895859\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0019876740407198668, std=0.010296355001628399\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.001258418313227594, std=0.011716607958078384\n",
            "Grad stats for input_proj.weight: mean=-3.500638001696643e-09, std=1.7380105532538437e-07\n",
            "Grad stats for input_proj.bias: mean=-1.7746662805961932e-08, std=6.223435207175498e-07\n",
            "Grad stats for output_head.0.weight: mean=8.482966222800314e-07, std=0.02280237339437008\n",
            "Grad stats for output_head.0.bias: mean=-0.001386548625305295, std=0.02495681121945381\n",
            "Grad stats for output_head.2.weight: mean=-0.000498388078995049, std=0.06918732076883316\n",
            "Grad stats for output_head.2.bias: mean=-0.002197256777435541, std=0.1272255778312683\n",
            "Hungarian matching: row_ind=[11 15], col_ind=[1 0]\n",
            "conf_loss: 0.31694135069847107, smooth_l1_loss: 0.004717708565294743, ciou_loss: 0.6971297264099121, box_loss: 0.35092371702194214\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-5.1368426873255046e-11, std=1.243969194320016e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-3.6103677825138902e-09, std=6.088791906222468e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.05670738825836e-09, std=3.2455142218168476e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-4.428343558515735e-08, std=1.7577723383510602e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-1.6127793545095415e-12, std=1.0946246931098358e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-6.154243781253399e-10, std=1.1639134100960291e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=8.586655275699684e-10, std=2.3696046014265448e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.7472565616571956e-09, std=2.579862155016599e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=3.3534466314932843e-09, std=5.428982490229828e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.842813001142531e-08, std=5.927411734774068e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.5049879443249665e-08, std=3.4479444366297685e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=7.4306427677584e-09, std=3.037389888049802e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.4080825394557905e-10, std=9.640388043408166e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=5.0124086214964336e-08, std=9.525388122710865e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.6343246755923246e-09, std=2.695745706660091e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.8380394095629526e-08, std=2.1466541966219665e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.1486389617232362e-10, std=5.040066639594443e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=9.01092533922565e-08, std=5.016603950025456e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=3.1963534041778985e-08, std=1.4341241012516548e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=6.350416725808827e-08, std=1.558427925374417e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=4.656013175008411e-08, std=4.8134934331756085e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=4.823066035442025e-08, std=4.831687419937225e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.2009849115202087e-07, std=1.7899019439937547e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=5.486476766236592e-07, std=1.95422562683234e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.2213519084980362e-10, std=6.209650564414915e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.5355281486081367e-07, std=6.3075212892726995e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=2.2354193163209857e-08, std=1.9390061424928717e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.6872851915650244e-07, std=1.5732790416222997e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-7.853939720803282e-12, std=4.752114364237059e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=3.0381883675545396e-08, std=4.808091034647077e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.847103246494953e-07, std=1.510360471002059e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-3.282568172835454e-07, std=1.2672445336647797e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=1.2678924576903228e-08, std=4.272674777894281e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.0272711392644851e-07, std=3.709455268108286e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-2.2132162484922446e-06, std=0.00024208315880969167\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.235072522831615e-05, std=0.00025476302835159004\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-1.290755391458731e-09, std=8.002018148545176e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=5.851081255059398e-07, std=7.934625318739563e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-7.802428285685892e-07, std=0.0003680239024106413\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=7.008284683251986e-06, std=0.00022327610349748284\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-4.867075631409534e-10, std=7.544126856373623e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=2.0123518424952636e-06, std=7.250066846609116e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.1276413715677336e-05, std=0.0007891221903264523\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.9830491257598624e-05, std=0.0008675293647684157\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-8.610659278929234e-07, std=0.0009326551808044314\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-9.460245564696379e-06, std=0.0009071807726286352\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0002368855639360845, std=0.012474139221012592\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.002220161957666278, std=0.013530885800719261\n",
            "Grad stats for input_proj.weight: mean=-1.6205912167777115e-09, std=6.762186899322842e-07\n",
            "Grad stats for input_proj.bias: mean=-7.466988805049368e-09, std=2.055821823887527e-06\n",
            "Grad stats for output_head.0.weight: mean=9.400719136465341e-08, std=0.02428378164768219\n",
            "Grad stats for output_head.0.bias: mean=-0.0009209892014041543, std=0.025822224095463753\n",
            "Grad stats for output_head.2.weight: mean=0.0013076968025416136, std=0.08011335879564285\n",
            "Grad stats for output_head.2.bias: mean=0.005782117135822773, std=0.14964143931865692\n",
            "No targets: conf_loss=0.13643009960651398, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=7.558268247387367e-13, std=6.327140589235114e-09\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-8.433336251556511e-10, std=2.9630328413077223e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=3.200372605816071e-11, std=2.5099200939848743e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-7.434797222316547e-10, std=9.431413872107441e-08\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-3.781582252199156e-13, std=8.047289945523062e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.462696352927395e-10, std=8.400331985569665e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.0364086672209893e-10, std=1.8817509328528104e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.911346636518374e-10, std=1.8912585275643323e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.3028328416098134e-10, std=4.7092562738271226e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.6602287039878547e-09, std=4.2460172267055896e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-3.3994318471286533e-10, std=2.733242752128717e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.2920553515982647e-09, std=2.3809596427781798e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.3538985037253592e-11, std=7.557672176972119e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=5.986974027649694e-09, std=7.506736920959156e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=3.220799182912515e-10, std=2.1566945918038982e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.328737285812622e-09, std=1.745836186728411e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.3656908937065282e-11, std=4.1256456029259425e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=8.497952563857325e-09, std=4.062222913603364e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.2765035695139204e-09, std=1.1836449687052664e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.5194262232020037e-09, std=1.291018634219654e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=4.218755123019946e-09, std=3.859765911329305e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.3598928205738048e-08, std=3.8899932519598224e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-2.7899957899535366e-09, std=1.564559397593257e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=1.9410679286124832e-08, std=1.6055554397098604e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=4.7165531896764534e-11, std=5.117362888995558e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=5.032130090398823e-08, std=5.170544454813353e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=2.1151613793790602e-09, std=1.5589603208354674e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=2.5276541748553427e-08, std=1.2587271385200438e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-9.45042655242645e-14, std=4.206466144296428e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-3.921407643048269e-09, std=4.2694480839600146e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.9625294217794362e-08, std=1.668538629928662e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-3.4763825595973685e-08, std=1.40008091875643e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.687010056793952e-09, std=3.3994135719694896e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.7211274183637215e-08, std=3.0223150133679155e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-4.309305268179742e-08, std=3.1844316254137084e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.1636336694209604e-07, std=2.67050872935215e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-8.674808787967336e-11, std=8.004175469977781e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=9.797309985515312e-08, std=7.9403689596802e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=7.376046795570801e-08, std=4.099713987670839e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-6.566771162397345e-07, std=2.604465225886088e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-5.254534585219517e-10, std=8.51443110150285e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=7.417731922032544e-07, std=8.229637387557887e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-2.0943687673025124e-07, std=9.849393973127007e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-5.436384071799694e-07, std=0.00010668041068129241\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.046712554853002e-06, std=0.00010841160110430792\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=2.007882358157076e-06, std=9.777012746781111e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017353766597807407, std=0.004302941262722015\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=6.0454993217717856e-05, std=0.0024477457627654076\n",
            "Grad stats for input_proj.weight: mean=-3.506421542009974e-10, std=3.2366642699344084e-08\n",
            "Grad stats for input_proj.bias: mean=-1.346931011170227e-09, std=9.746621287831658e-08\n",
            "Grad stats for output_head.0.weight: mean=7.551680027972907e-07, std=0.003186766756698489\n",
            "Grad stats for output_head.0.bias: mean=-0.0015710011357441545, std=0.0030124301556497812\n",
            "Grad stats for output_head.2.weight: mean=0.0002799995127134025, std=0.001638780697248876\n",
            "Grad stats for output_head.2.bias: mean=0.0012561765033751726, std=0.00285215862095356\n",
            "Hungarian matching: row_ind=[ 2  7  8 10], col_ind=[3 0 1 2]\n",
            "conf_loss: 0.4662740230560303, smooth_l1_loss: 0.022614438086748123, ciou_loss: 1.0383265018463135, box_loss: 0.5304704904556274\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=2.6482316339837553e-11, std=7.115948363889402e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=5.632685429191042e-09, std=3.81455805609221e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=2.749223626530295e-10, std=1.2214866274007363e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.941990035447816e-08, std=1.188724354506121e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-1.0456045751450205e-12, std=2.2381954067896004e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-9.302368875196976e-10, std=2.8484487657465252e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=4.0441111570643784e-10, std=3.475516763273845e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.0362640462678883e-09, std=8.860392597398459e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.502842295053597e-10, std=2.019017841803361e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=8.365940828980456e-09, std=2.2855846282254788e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-1.5919983553658312e-08, std=3.442906404416135e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=2.593944614659449e-09, std=3.4654487990337657e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-1.1233398759802338e-11, std=9.921361510123461e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-5.954273074593175e-09, std=1.0517869952764158e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.899421592232997e-10, std=2.716836604577111e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.319714725336098e-09, std=2.440082482735306e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=3.504925516484292e-12, std=4.840170930719978e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-3.229711165175786e-09, std=5.046715045864403e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-9.190552763271853e-10, std=1.5539407627329638e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.8649102262457973e-09, std=1.7885234626646707e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-5.994365892547648e-09, std=4.518968523825606e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-7.703620852339554e-09, std=4.86557439671742e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=3.176264584681121e-09, std=1.7275392565352377e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-2.5747429077682682e-08, std=2.192004785683821e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-2.6825430765597957e-11, std=6.453374794546107e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-4.0955857372182436e-08, std=6.728513994858076e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-6.12680739475735e-10, std=2.1938296868029283e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-6.739504954111908e-09, std=1.7466593362769345e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-6.504796701278792e-12, std=6.021164722369576e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=4.412144605225876e-08, std=6.196375466060999e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=2.3415248406877254e-08, std=3.0467060696537374e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=2.6912303496828827e-08, std=2.614613322293735e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.9947822949006877e-08, std=4.957119017490186e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=5.6518061342103465e-08, std=4.43190629084711e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.437696705077542e-07, std=6.194036541273817e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-9.955513178283582e-07, std=5.324154335539788e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-1.2610298361082073e-09, std=1.3504862181434873e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=8.134105087265198e-07, std=1.3910504094383214e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-9.719705040822646e-09, std=8.554106170777231e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.3002136256545782e-08, std=5.311334825819358e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-4.25464108388951e-11, std=1.9510760466801003e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-2.485836887444748e-07, std=1.935527689056471e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.8723292782851786e-07, std=0.00022175139747560024\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-5.08707671542652e-07, std=0.0002492420026101172\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.3391236279858276e-06, std=0.00023654552933294326\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=8.108463589451276e-07, std=0.0002069277106784284\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.00017380058125127107, std=0.004433154594153166\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0003268346772529185, std=0.0037268507294356823\n",
            "Grad stats for input_proj.weight: mean=-6.281935416296847e-09, std=4.4677668142867333e-07\n",
            "Grad stats for input_proj.bias: mean=-3.483359378719797e-08, std=1.5484565665246919e-06\n",
            "Grad stats for output_head.0.weight: mean=-6.417285476345569e-07, std=0.007387592922896147\n",
            "Grad stats for output_head.0.bias: mean=0.0007105006370693445, std=0.007922687567770481\n",
            "Grad stats for output_head.2.weight: mean=-0.0006984655628912151, std=0.016705283895134926\n",
            "Grad stats for output_head.2.bias: mean=-0.003053860040381551, std=0.030603596940636635\n",
            "Hungarian matching: row_ind=[7], col_ind=[0]\n",
            "conf_loss: 0.21031148731708527, smooth_l1_loss: 0.006498055532574654, ciou_loss: 0.8088308572769165, box_loss: 0.4076644480228424\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-1.8733029016893e-11, std=1.4669124936972366e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=7.665964751879528e-09, std=8.646868536743568e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=3.392786052103247e-10, std=2.57686224358622e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.7347783654031446e-08, std=2.7530772968020756e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.352389116833109e-12, std=6.495684345964037e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=5.627904808847006e-10, std=8.109932991828828e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.833316831678644e-10, std=1.138339484896278e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.00720329246451e-09, std=2.43189703041935e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.3385919039876626e-09, std=3.89538286071911e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.4116847185950974e-08, std=5.21377671702794e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=4.836975620037265e-08, std=1.572854444020777e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=5.9328186807761085e-09, std=1.4438716107179062e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=5.26385601773427e-11, std=4.260055561644549e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=2.834585188793426e-08, std=4.444313503881858e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-9.121515764931587e-10, std=1.1844648497572052e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.1330014260124699e-08, std=9.909524578688433e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-6.704348187724918e-11, std=2.1413890749499842e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=5.147907344849045e-08, std=2.1600423849577055e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=4.2892924767556906e-09, std=7.074824566188909e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=9.113869658960994e-09, std=8.121728001242445e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.778461466983572e-08, std=2.0864954421995208e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=5.522291957049674e-08, std=2.1469804778462276e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-6.046280986993224e-08, std=8.71973952598637e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=3.344541141814261e-07, std=1.009537936624838e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.3522516439934407e-10, std=3.0306350708997343e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=1.6189578389003145e-07, std=3.185551804563147e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-6.204127767084344e-10, std=9.772660632734187e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-5.1848232374140935e-09, std=8.028442607610486e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-2.106848029370667e-11, std=2.779266651486978e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.2319777908942342e-07, std=2.852173793144175e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.6285781612168648e-09, std=1.3100684554956388e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-2.334509474621882e-09, std=1.1162145710841287e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-8.603424817010819e-08, std=2.106726424244698e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.85398420171623e-07, std=1.9496494132908992e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.1912507034139708e-06, std=0.0002145593025488779\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=3.4239749311382184e-06, std=0.00022517191246151924\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=7.678981894798653e-09, std=6.291017052717507e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-2.95102449854312e-06, std=6.433404632844031e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=2.5924572355506825e-07, std=0.00036375995841808617\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-3.837411441054428e-06, std=0.00022214285854715854\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-5.0424802111592726e-09, std=7.478056068066508e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=2.9592642931675073e-06, std=7.38389790058136e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-4.244052433932666e-06, std=0.0008654926205053926\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-1.1132195140817203e-05, std=0.0009712057653814554\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-4.021019776700996e-06, std=0.0008114507654681802\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.7245663912035525e-05, std=0.0008677960722707212\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0033151060342788696, std=0.017745083197951317\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.002643205691128969, std=0.015453867614269257\n",
            "Grad stats for input_proj.weight: mean=3.9651912864258065e-09, std=8.159710205291049e-07\n",
            "Grad stats for input_proj.bias: mean=3.0287665708783607e-08, std=3.400272589715314e-06\n",
            "Grad stats for output_head.0.weight: mean=2.313099685125053e-06, std=0.029611965641379356\n",
            "Grad stats for output_head.0.bias: mean=-0.004070481285452843, std=0.03160994127392769\n",
            "Grad stats for output_head.2.weight: mean=-0.00174518465064466, std=0.07775038480758667\n",
            "Grad stats for output_head.2.bias: mean=-0.007632095366716385, std=0.1438201367855072\n",
            "Batch 110, Loss: 0.6179759502410889\n",
            "Hungarian matching: row_ind=[ 7 10], col_ind=[1 0]\n",
            "conf_loss: 0.2896863520145416, smooth_l1_loss: 0.004084241576492786, ciou_loss: 0.7297336459159851, box_loss: 0.3669089376926422\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-6.815031872164923e-11, std=8.504071757897691e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=1.472773636379543e-08, std=4.02882761818546e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-3.7848207901092223e-10, std=1.2634899348995532e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=2.5499671707507332e-08, std=8.633653010292619e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-1.1258008414394283e-13, std=3.5111991536496134e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-9.90535764522349e-10, std=3.912336765665714e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=9.298070646757139e-10, std=6.695715626392484e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.4702966339162913e-09, std=8.753988822718384e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.1428524793188899e-10, std=1.943847678376187e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=1.196422694249577e-08, std=2.1424249041501753e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=4.003275932973338e-09, std=9.385940415995719e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=3.3176164038195566e-09, std=8.527205181962927e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-3.323078964778681e-11, std=2.678975192793587e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-1.1209835726333495e-08, std=2.713886715355329e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=7.912854260716529e-10, std=7.346742449954036e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=7.539535218370474e-09, std=5.845884061272955e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=1.9114432259215164e-11, std=1.367179862654666e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-1.8606330698389684e-08, std=1.37634543762033e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.245080343854511e-09, std=4.348217714778002e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-4.626248717443104e-09, std=4.817727017325524e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.2587371145400539e-08, std=1.2234172572789248e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-4.959098021117825e-08, std=1.3024539384787204e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-9.031104752921237e-08, std=5.265728304948425e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-2.481149152799844e-08, std=6.431268502637977e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-6.544439296041205e-11, std=2.0601353298843605e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-6.409344877056355e-08, std=2.132588178938022e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=5.649747336633482e-10, std=6.2999633883009665e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-4.4996539827479864e-10, std=5.06678316014586e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-5.044603623716171e-12, std=1.6064341252786107e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.758148471253662e-08, std=1.6432865095339366e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.9311141841171775e-07, std=8.475478352920618e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-2.2050998893519136e-07, std=7.254755473695695e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=1.1201990446352283e-08, std=1.4023533367435448e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=7.361268217209727e-08, std=1.2459699973987881e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=3.937379915441852e-07, std=0.00018256875046063215\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.742905508057447e-06, std=0.00014493656635750085\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-9.495764174971555e-09, std=3.7884237826801836e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=3.2235573144134833e-06, std=3.8409092667279765e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=1.302980336959081e-07, std=0.0002125302271451801\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.7348565961583517e-06, std=0.00015189462283160537\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.1848265419066593e-09, std=4.527893179329112e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.865265744527278e-06, std=4.4584714487427846e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.1028686230929452e-06, std=0.0005430300952866673\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-3.0648516258224845e-06, std=0.0005941576091572642\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.1462969925778452e-06, std=0.0006268009310588241\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-2.1106130589032546e-05, std=0.0005072761559858918\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0013375460403040051, std=0.009187071584165096\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0004788976802956313, std=0.009489909745752811\n",
            "Grad stats for input_proj.weight: mean=5.5388862385541415e-09, std=4.5922948288534826e-07\n",
            "Grad stats for input_proj.bias: mean=3.20718243074225e-08, std=1.5227180938381935e-06\n",
            "Grad stats for output_head.0.weight: mean=-4.609628376783803e-07, std=0.018039530143141747\n",
            "Grad stats for output_head.0.bias: mean=0.0004200229304842651, std=0.01903333142399788\n",
            "Grad stats for output_head.2.weight: mean=-0.0005325908423401415, std=0.04824215546250343\n",
            "Grad stats for output_head.2.bias: mean=-0.0022818297147750854, std=0.08820954710245132\n",
            "Hungarian matching: row_ind=[0], col_ind=[0]\n",
            "conf_loss: 0.2250002920627594, smooth_l1_loss: 0.016821177676320076, ciou_loss: 0.6548946499824524, box_loss: 0.33585792779922485\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=2.6222343740833765e-11, std=4.321643487514848e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-7.086325748417721e-09, std=2.4874293558241334e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=7.77885048042215e-11, std=7.054253359228824e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-8.120504269015782e-09, std=6.346513714561297e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.4803856885080577e-13, std=1.738897204006662e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=5.30651356189793e-11, std=2.28739835961278e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.0355636487213715e-10, std=2.8844095112390278e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.728690606801365e-10, std=5.46322738159688e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-3.908251500206461e-11, std=9.476569573507732e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-5.785673273805969e-09, std=1.2962651396719593e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-2.0147332691067277e-09, std=3.8329403651005123e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=1.524025350363445e-11, std=3.7093411719979485e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.6253323339987524e-11, std=1.087318963755024e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=6.934854468454432e-09, std=1.1306578073799756e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-2.6219398180371556e-11, std=3.0888460855749145e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=4.411688792060886e-10, std=2.572037658410409e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.1681072775715506e-11, std=5.882836617843168e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=8.83460771206046e-09, std=5.987817530694883e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.9876003065633085e-09, std=2.4841111212481337e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-4.017075116991009e-09, std=2.807886403388693e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=6.005663522046234e-09, std=5.320765694705187e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.0553970142268554e-08, std=5.789825650026614e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-4.190390257008403e-09, std=3.3774476833059452e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-1.0002064954051093e-08, std=3.492879159239237e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.8148297101228117e-11, std=1.089991997105244e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=3.156989691888157e-08, std=1.1344418453518301e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-6.570699095931332e-09, std=3.6019339404447237e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-6.547822550828641e-08, std=2.8924869184265845e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-5.692155080616601e-12, std=9.126767395173374e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.2758544443158826e-08, std=9.36646017635212e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-4.642738815618941e-08, std=6.726096671627602e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-5.2516568871396885e-08, std=5.74750038140337e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.1105697694802075e-08, std=8.732916285225656e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-6.343771019601263e-08, std=7.342104254348669e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=6.313534868240822e-07, std=0.00011998144327662885\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.1111419553344604e-06, std=0.00011769588309107348\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=3.8078291630938566e-09, std=3.763967106351629e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.2887770708402968e-06, std=3.868512430926785e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-5.0473438761855505e-09, std=0.00019853301637340337\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-6.267168828344438e-08, std=0.00012034006795147434\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=1.865959831093278e-09, std=4.236889799358323e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.994442982322653e-06, std=4.1501381929265335e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=3.933583229809301e-06, std=0.0004834860737901181\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.0247787940897979e-05, std=0.0005313141155056655\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=1.7558686522534117e-06, std=0.0005469099851325154\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=8.737436473893467e-06, std=0.00047596223885193467\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0052061304450035095, std=0.012161359190940857\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.000536817591637373, std=0.009891597554087639\n",
            "Grad stats for input_proj.weight: mean=-3.18556780953827e-09, std=2.1060351684809575e-07\n",
            "Grad stats for input_proj.bias: mean=-1.9112778915086892e-08, std=8.768031420913758e-07\n",
            "Grad stats for output_head.0.weight: mean=-1.9679791876114905e-06, std=0.016195200383663177\n",
            "Grad stats for output_head.0.bias: mean=0.0029937042854726315, std=0.017117518931627274\n",
            "Grad stats for output_head.2.weight: mean=0.0031312948558479548, std=0.04460691660642624\n",
            "Grad stats for output_head.2.bias: mean=0.013638808391988277, std=0.08151587098836899\n",
            "Hungarian matching: row_ind=[0 7], col_ind=[1 0]\n",
            "conf_loss: 0.30175384879112244, smooth_l1_loss: 0.030109521001577377, ciou_loss: 0.9550046324729919, box_loss: 0.4925570785999298\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-6.405942443166168e-10, std=3.701181867654668e-06\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=4.024999782359373e-07, std=2.129097811121028e-05\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=9.806972123271862e-09, std=2.5053816443687538e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-6.764355475752382e-07, std=2.989895801874809e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-2.6274149522720336e-11, std=2.853192313523323e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-3.0871628808881724e-08, std=2.871014714855846e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.6285206516641892e-09, std=1.483540046365306e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=9.401403211484194e-09, std=3.912902286629105e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.2374570701467746e-08, std=4.605108188115992e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-4.723668212136545e-08, std=5.096666427562013e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.3869559722934355e-07, std=6.509595209536201e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=4.48643433514917e-08, std=7.654294904568815e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-1.481773037603773e-11, std=2.4078423166429275e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-7.9467703528735e-09, std=2.4019831812438497e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-4.062673808480355e-11, std=2.458408800976031e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.6016150627962134e-09, std=2.6227959892821673e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=6.594211288124541e-12, std=3.68605270750777e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-4.902709793697113e-09, std=4.028727218496897e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=2.8885310809911857e-10, std=1.5267119124473538e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=6.829856680212743e-10, std=2.0869519801181013e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-4.496499173001212e-09, std=3.79370817427116e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-2.957658118418749e-09, std=4.2847497638831555e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.3416439514912781e-08, std=1.8116190858563641e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-3.602601950092321e-08, std=2.0632317045965465e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.4447332219447162e-11, std=6.931325060577365e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-3.125463265973849e-08, std=7.25418942693068e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-1.808713179229926e-09, std=2.0696470528491773e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-1.7443010591478014e-08, std=1.7079605640901718e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=3.4861002973229915e-12, std=5.720236231354647e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-1.1409757583180635e-08, std=5.893195975659182e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-5.672747960261404e-08, std=3.681080215756083e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-6.525394269374374e-08, std=3.1880231290415395e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.002665031701326e-11, std=4.539038855000399e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.2662480603230506e-07, std=4.241840542817954e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=6.599386779271299e-07, std=6.225799734238535e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.9831359168165363e-06, std=6.534465501317754e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-9.732895600578217e-10, std=1.9107767002424225e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=4.740414567550033e-07, std=1.9567934941733256e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-7.199314211447927e-08, std=9.873442468233407e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=9.168842893814144e-07, std=6.180470518302172e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.0573097952715216e-11, std=2.003012559725903e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.5241474216054485e-07, std=1.9711518689291552e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=9.296672374148329e-07, std=0.0002492327184882015\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=2.4632081476738676e-06, std=0.00027597282314673066\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=6.761474651284516e-07, std=0.0002392138703726232\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.0466396815900225e-06, std=0.00024560283054597676\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0003635472385212779, std=0.0036907517351210117\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-7.525239925598726e-05, std=0.0042849257588386536\n",
            "Grad stats for input_proj.weight: mean=3.1604116657035775e-07, std=2.2002595869707875e-05\n",
            "Grad stats for input_proj.bias: mean=2.1102400751260575e-06, std=9.435108222533017e-05\n",
            "Grad stats for output_head.0.weight: mean=-6.503046279249247e-08, std=0.00851191021502018\n",
            "Grad stats for output_head.0.bias: mean=6.65572879370302e-05, std=0.009181774221360683\n",
            "Grad stats for output_head.2.weight: mean=0.0007832918199710548, std=0.020543044432997704\n",
            "Grad stats for output_head.2.bias: mean=0.00341165903955698, std=0.03784891217947006\n",
            "Hungarian matching: row_ind=[10], col_ind=[0]\n",
            "conf_loss: 0.2159632444381714, smooth_l1_loss: 0.013717493042349815, ciou_loss: 0.958919882774353, box_loss: 0.4863186776638031\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=2.92861186690363e-11, std=1.6249236978183035e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.710919583786108e-08, std=8.784188594290754e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.8270801538378123e-11, std=1.5069782932641829e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-3.5108769225189462e-09, std=1.5141882840907783e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.0700108294136044e-13, std=3.044250362904677e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=2.352632977320468e-09, std=4.093178773700856e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=3.1240060538451075e-10, std=5.114647905202219e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.3636396456462307e-09, std=1.2154464457125869e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.7096679627570666e-09, std=2.0957656943210168e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.1506928743187927e-08, std=3.10401929937143e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.30218076321853e-08, std=6.393519242919865e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.173409979240205e-09, std=6.084593451305409e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=2.809252830360265e-11, std=1.8006655011504336e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.2128912096898148e-08, std=1.8761686249035847e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=5.072031683539535e-11, std=4.649203333428886e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=4.273057463421992e-10, std=4.11410582046301e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.3563483669543075e-11, std=8.552014207907632e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=1.3911314766801297e-08, std=8.706171428229936e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.4324034181001366e-09, std=2.6639500561032037e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-2.8942872543069598e-09, std=3.0058740208005474e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=8.690765440633186e-09, std=8.270415037259227e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.4881734955451975e-08, std=8.369922284146014e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-8.90181439672233e-09, std=3.4686247545323567e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=6.663059792799686e-08, std=3.801513457801775e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=7.988454342466866e-11, std=1.1351716011631652e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=1.0354357726782837e-07, std=1.1832885320472997e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-4.0189100936061095e-09, std=3.391121254026075e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-4.92606950786012e-08, std=2.7657415557769127e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-2.563615986161949e-12, std=8.500275612277619e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-3.9525616557511967e-08, std=8.701759952600696e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=2.622893546799787e-08, std=3.3348730994475773e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=2.995308889808257e-08, std=2.8352069421089254e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=1.8150061009691854e-08, std=7.4549006967572495e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-2.0531402356027684e-07, std=6.9206193984427955e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-2.492243993401644e-07, std=5.8883473684545606e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-9.377035894431174e-07, std=5.792831871076487e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-4.237528938855206e-10, std=1.5817526218597777e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.2225180512359657e-07, std=1.6363588656531647e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-8.954872754429744e-08, std=8.432687900494784e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.0487492545507848e-06, std=5.3232044592732564e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-4.093454464282331e-10, std=1.7140080672106706e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=5.886389544684789e-07, std=1.7011272575473413e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.666293769631011e-06, std=0.00019742910808417946\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=4.559510216495255e-06, std=0.00022248836467042565\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=8.842941952025285e-07, std=0.00021666151587851346\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-4.302659817767562e-06, std=0.00020807299006264657\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.002202665666118264, std=0.00644312147051096\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0004281618457753211, std=0.004124234430491924\n",
            "Grad stats for input_proj.weight: mean=-6.149567521873678e-09, std=9.471438033870072e-07\n",
            "Grad stats for input_proj.bias: mean=-3.4856327602028614e-08, std=3.4612201034178725e-06\n",
            "Grad stats for output_head.0.weight: mean=2.596840204205364e-06, std=0.006891842931509018\n",
            "Grad stats for output_head.0.bias: mean=-0.002077272394672036, std=0.007270880043506622\n",
            "Grad stats for output_head.2.weight: mean=-0.0004693551454693079, std=0.020065955817699432\n",
            "Grad stats for output_head.2.bias: mean=-0.002073290292173624, std=0.037236444652080536\n",
            "Hungarian matching: row_ind=[7], col_ind=[0]\n",
            "conf_loss: 0.21181614696979523, smooth_l1_loss: 0.007963445037603378, ciou_loss: 0.9184727668762207, box_loss: 0.463218092918396\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-9.795066979734202e-09, std=1.2032443919451907e-05\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=1.0828604217749671e-06, std=6.895630212966353e-05\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-6.493864113110703e-09, std=7.808783266227692e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.3125988971296465e-06, std=9.344528371002525e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=7.680900360185205e-11, std=7.288550136763661e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.0855692522682148e-07, std=7.972770958986075e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.597661641345894e-09, std=3.8161505244715954e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.3445489166485913e-08, std=1.0833666692633415e-06\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=4.395246833155397e-08, std=1.3266349014884327e-05\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.6108613465348753e-07, std=1.5215871826512739e-05\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.9262719774815196e-07, std=1.4458656778515433e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=1.3662231879152387e-07, std=1.8745756733551389e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-3.5296737754819674e-11, std=4.835088134313992e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-1.276806660399643e-08, std=5.346201987777022e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.5793065744063028e-09, std=4.492118250709609e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=2.1622412305077887e-08, std=6.041822189217783e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.0992339810899097e-12, std=7.298616822026815e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=2.3121748959908928e-09, std=8.142459506643718e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=4.3757009127176616e-10, std=2.344903577977675e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=3.4911358248734814e-09, std=3.4818449989870714e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.0203230260685814e-08, std=7.138823434615915e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-3.4880693888794667e-09, std=8.863658536029106e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=3.7039463052224164e-08, std=2.3431800855178153e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=8.195537759547733e-08, std=3.2509481115994276e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-6.036030703038264e-11, std=9.5373070507776e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-6.5640115565202e-08, std=1.0882018841584795e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.0247802606500045e-09, std=3.0043629521969706e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=2.5541311288179713e-08, std=2.8464501156122424e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.8683665725660603e-12, std=8.178093366950634e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=5.052696749885399e-08, std=8.459390414827794e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.3015754635480334e-08, std=4.856812665821053e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-5.950442982793902e-08, std=4.8828378567122854e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-5.253390966686311e-08, std=6.337616014207015e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=6.458648016405277e-08, std=6.930551535333507e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-2.87603825199767e-08, std=8.891915786080062e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.5601409586452064e-06, std=9.178288019029424e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=1.5773835571053496e-09, std=2.632633550092578e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=4.68686266685836e-07, std=2.6991307095158845e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-6.832331678197079e-08, std=0.00013639856479130685\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.1259431857979507e-06, std=8.809947757981718e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=4.745892567825649e-11, std=2.825957562890835e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.097639824365615e-06, std=2.8111760911997408e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-5.877383841834671e-07, std=0.00034346984466537833\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-1.5616515156580135e-06, std=0.00038937132922001183\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.2395788619178347e-06, std=0.0003323553246445954\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.216896180267213e-06, std=0.0003379405534360558\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.002424821490421891, std=0.006953877862542868\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0010981564410030842, std=0.006395385600626469\n",
            "Grad stats for input_proj.weight: mean=8.882177553459769e-07, std=6.650854629697278e-05\n",
            "Grad stats for input_proj.bias: mean=5.680426511389669e-06, std=0.00030728758429177105\n",
            "Grad stats for output_head.0.weight: mean=1.0916010069195181e-06, std=0.011227636598050594\n",
            "Grad stats for output_head.0.bias: mean=-0.0015713453758507967, std=0.012150616385042667\n",
            "Grad stats for output_head.2.weight: mean=-0.0004277538391761482, std=0.02803785353899002\n",
            "Grad stats for output_head.2.bias: mean=-0.0019175816560164094, std=0.052993714809417725\n",
            "Hungarian matching: row_ind=[15 16], col_ind=[0 1]\n",
            "conf_loss: 0.31084075570106506, smooth_l1_loss: 0.010740619152784348, ciou_loss: 0.888480544090271, box_loss: 0.4496105909347534\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-4.348838997247917e-11, std=4.407682396845303e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=6.5987482145146714e-09, std=2.690686642381479e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=8.489832448166368e-11, std=4.581094259492602e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.2893185186158007e-08, std=5.425664539870922e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=4.2671768896163087e-13, std=8.893954017707983e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-9.297550507270103e-10, std=1.0940427230821115e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.62117319568722e-10, std=3.0541770001946134e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=7.942551061290715e-10, std=8.212695945530868e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=5.787432755255395e-10, std=8.667105788617846e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=1.6813179737340533e-09, std=1.0223899948869075e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-7.2450698773707245e-09, std=2.648108079483791e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-7.662602996560963e-09, std=2.720957468227425e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-4.922109161226151e-12, std=7.137133906098825e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-1.7934415064146947e-09, std=7.499845366965019e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-2.16029069632917e-11, std=2.4781346041891084e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-2.2022272894162143e-09, std=2.1985961495829542e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.7118945150329523e-12, std=4.4220247019666203e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=2.3663919712646475e-09, std=4.5652942759488724e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=4.4901246609718726e-10, std=3.6837096217823273e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=7.586917760704637e-10, std=4.1773449765969417e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.6579537742700268e-09, std=4.6194509195629507e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=4.179978141394258e-09, std=4.381884366466693e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=5.0209237656417827e-08, std=5.3665921768697444e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-8.219387837016257e-09, std=5.0654962251428515e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-2.649732375788888e-13, std=1.6024484921217663e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=2.4021316491484868e-08, std=1.654756943025859e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-3.0797642214253074e-09, std=5.810414677398512e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-2.7359362775314366e-08, std=4.6733034650969785e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-2.0977219961082483e-11, std=1.7577618791619898e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=7.358865872220122e-08, std=1.8011855900113005e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.5407906062137045e-07, std=1.250184686796274e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.778813896180509e-07, std=1.058655197994085e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=5.8711862038762774e-09, std=1.236627849721117e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=1.6338867681042757e-07, std=1.1709898899425752e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=5.452766345115378e-07, std=0.0002097811666317284\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=2.855127604561858e-06, std=0.0002106073370669037\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=5.398916869125969e-10, std=6.676665361737832e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=4.39871037372086e-08, std=6.777828093618155e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=6.544269695041294e-07, std=0.0003631501167546958\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-6.779441264370689e-06, std=0.0002179988077841699\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.5027490363195284e-10, std=6.938901060493663e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=2.7507115873959265e-07, std=6.77122880006209e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-4.635535788111156e-06, std=0.0008325499948114157\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-1.215146403410472e-05, std=0.0009310775785706937\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-4.245968739269301e-06, std=0.0009182822541333735\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=3.1749921618029475e-05, std=0.0008710969123058021\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0012233412126079202, std=0.012442613020539284\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.00041140493704006076, std=0.014360340312123299\n",
            "Grad stats for input_proj.weight: mean=2.8589390854705243e-09, std=2.222053723244244e-07\n",
            "Grad stats for input_proj.bias: mean=1.790509784882488e-08, std=1.0239944003842538e-06\n",
            "Grad stats for output_head.0.weight: mean=1.4484203347819857e-07, std=0.028212783858180046\n",
            "Grad stats for output_head.0.bias: mean=-0.0002454869099892676, std=0.030437033623456955\n",
            "Grad stats for output_head.2.weight: mean=0.0009171786950901151, std=0.07109043002128601\n",
            "Grad stats for output_head.2.bias: mean=0.004009142983704805, std=0.13067615032196045\n",
            "Hungarian matching: row_ind=[19], col_ind=[0]\n",
            "conf_loss: 0.22305481135845184, smooth_l1_loss: 0.0028123692609369755, ciou_loss: 0.31198421120643616, box_loss: 0.1573982834815979\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.3767743022030654e-11, std=2.8212431502083746e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=1.965189344588225e-09, std=1.3644000773638254e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.8149326486138762e-10, std=7.809580893081147e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-7.555584602414456e-09, std=4.587372472997231e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=1.0233662875447358e-12, std=2.2295781221259858e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=4.96942764716124e-10, std=2.270765087075688e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-3.2040994857318594e-11, std=4.945933085309662e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-8.041634025346411e-11, std=5.625000554232429e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.016830508682176e-09, std=1.2401602589307004e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=4.210464421561255e-09, std=1.2549033101549867e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-1.0248008663893415e-08, std=7.200457616818312e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-7.113881039799708e-09, std=6.377585464178992e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-2.7366312341237098e-11, std=1.902442505752333e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-1.4268142223272662e-08, std=1.9003275042450696e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.8410584168293553e-09, std=6.170809001559974e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.468543864291405e-08, std=4.5177210949987057e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=4.048594792749327e-11, std=1.0677020867433384e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-2.0652359822292965e-08, std=1.0589018728524024e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=4.891043126065142e-09, std=4.4936368226444756e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=9.55590451212629e-09, std=4.959027819495532e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-9.431847303176255e-09, std=1.124821665143827e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-1.7884442371496334e-08, std=1.0518101589696016e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=3.1314186799136223e-09, std=5.606871582131134e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-2.0952533930085337e-07, std=6.161828878248343e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-5.944992415019001e-11, std=1.8737018763204105e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-2.442060065277474e-07, std=1.8985030010298942e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-8.32040569775927e-09, std=7.072617790981894e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-7.518264055761392e-08, std=5.592301022261381e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.2384093750483771e-11, std=2.1516655124287354e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-1.1354817530673245e-07, std=2.170002744605881e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.1593121485020674e-07, std=1.4251078027882613e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.3543086652134662e-07, std=1.190954299090663e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=3.213358468201477e-09, std=1.4251956599764526e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-6.757537107660028e-08, std=1.3791743185720406e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.2479358701966703e-07, std=0.00025013124104589224\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=8.369288480025716e-06, std=0.0002347521804040298\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=1.0497160474187694e-08, std=6.66547057335265e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-6.578411557711661e-06, std=6.597767787752673e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-4.2848085968216765e-08, std=0.0003553232236299664\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=5.021302058594301e-07, std=0.0002335753379156813\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=3.765521228160651e-09, std=7.212719356175512e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=3.479093948044465e-06, std=7.172760524554178e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=6.7229648266220465e-06, std=0.0008642937755212188\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.7593367374502122e-05, std=0.000928286521229893\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=4.65356424683705e-06, std=0.0008175888797268271\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=2.7484202291816473e-06, std=0.0008114509400911629\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.002292575780302286, std=0.018651368096470833\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.000840446911752224, std=0.01407137606292963\n",
            "Grad stats for input_proj.weight: mean=7.578350724735117e-10, std=1.6402367464252166e-07\n",
            "Grad stats for input_proj.bias: mean=4.3026062712669955e-09, std=5.240283940111112e-07\n",
            "Grad stats for output_head.0.weight: mean=6.4329360611736774e-06, std=0.029127908870577812\n",
            "Grad stats for output_head.0.bias: mean=-0.0049351779744029045, std=0.03070090524852276\n",
            "Grad stats for output_head.2.weight: mean=-0.0008222575997933745, std=0.060080353170633316\n",
            "Grad stats for output_head.2.bias: mean=-0.0036718242336064577, std=0.11368174850940704\n",
            "No targets: conf_loss=0.12816199660301208, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.8055603887012772e-11, std=3.766983880382213e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=2.6721798107587347e-09, std=1.9806923035048385e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-6.057415680160716e-11, std=6.657524664888115e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=3.3584246494910985e-09, std=6.387024882315018e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=5.653116863513219e-14, std=1.508730562704841e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=7.315708039357105e-10, std=1.6386437096116424e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=9.924950618300787e-12, std=2.0442282533394973e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=4.1286751795155396e-11, std=4.730738112357358e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.6409296144104246e-10, std=1.057439433793661e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-4.926334007393507e-09, std=1.1359193763382791e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.6956463727856317e-09, std=2.6230205207866675e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-2.1051160814522518e-10, std=2.375891341444003e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.0808538959683478e-11, std=6.920852513303544e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=5.144356496344926e-09, std=7.210432784177101e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.08294041736945e-11, std=1.9730437372800225e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.884537248475482e-10, std=1.6197577679122332e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-9.406558865165948e-12, std=3.450465158039151e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=7.785068589782895e-09, std=3.4796549641669117e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=3.361440570337493e-10, std=1.0174695574960424e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=7.061903284366622e-10, std=1.1834964652734925e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.656294822462769e-09, std=3.6000224667986913e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.410900420585676e-09, std=3.603892082537641e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.9087948999185755e-09, std=1.387946326758538e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=3.035957263364253e-08, std=1.4473583860308281e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.8061256443501215e-11, std=4.159516890922532e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.021950417154585e-08, std=4.3315139919286594e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-5.185744056390718e-10, std=1.3382154975261074e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-5.337306596686631e-09, std=1.092095203603094e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-5.850736561896497e-13, std=3.6556630789164046e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=5.788463930400667e-09, std=3.783400472912035e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-3.4339961985097034e-09, std=1.3610099358629668e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-3.892117739212608e-09, std=1.1701463336066809e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-7.239705723804946e-09, std=2.9973673463246087e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.147217952914616e-08, std=2.735214138738229e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.5016478250327054e-07, std=2.6470852390048094e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=7.553489922429435e-08, std=2.3747405066387728e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.767575973423476e-10, std=7.470821401511785e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.8019579783867812e-07, std=7.667387762921862e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=3.2013700579369697e-09, std=3.5662877053255215e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-2.541366939112777e-08, std=2.1989422748447396e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-7.241931498924714e-10, std=7.158152584452182e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=6.457445920204918e-07, std=7.0641422098560724e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=2.663500708877109e-07, std=8.636824350105599e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=7.074929726513801e-07, std=9.691106242826208e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.0168205335503444e-06, std=9.593559661880136e-05\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=8.894839993445203e-07, std=8.858145156409591e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.001696188235655427, std=0.004033925477415323\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.7061486586462706e-05, std=0.0023080636747181416\n",
            "Grad stats for input_proj.weight: mean=8.116008559655441e-11, std=1.9064317768879846e-07\n",
            "Grad stats for input_proj.bias: mean=7.960503367598903e-10, std=6.556105063282303e-07\n",
            "Grad stats for output_head.0.weight: mean=1.3622920960187912e-06, std=0.002981038298457861\n",
            "Grad stats for output_head.0.bias: mean=-0.0014773105503991246, std=0.0028358374256640673\n",
            "Grad stats for output_head.2.weight: mean=0.00027564537595026195, std=0.0015906179323792458\n",
            "Grad stats for output_head.2.bias: mean=0.0011853673495352268, std=0.002701320219784975\n",
            "No targets: conf_loss=0.12779052555561066, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=2.5427940308908603e-10, std=1.6337961028511927e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-2.867153092722674e-08, std=9.607847459847108e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-2.5644159018511914e-10, std=1.3598459247532446e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=2.2198470617240673e-08, std=1.2782523981513805e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-1.2151391004522338e-13, std=2.2633400931226788e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=9.78615410929251e-10, std=2.6296488542243424e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=5.067909980560614e-10, std=3.415873095491406e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.245763575103865e-09, std=8.333386602998871e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.300304641738137e-09, std=1.896725052574766e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-8.389685390852719e-09, std=2.3725451114842144e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.115458741513976e-08, std=2.3792011916157207e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-4.205464865236763e-09, std=2.6863625635087374e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.6603338495735365e-11, std=8.355338110277444e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=5.799666968897554e-09, std=8.724003919269308e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-9.522349575519229e-11, std=1.896866308470635e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-3.990004771026179e-09, std=1.8843151394776214e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.4807044479425713e-12, std=3.4705802676171515e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=5.967123684058606e-09, std=3.62929668540346e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.6058787632999838e-10, std=1.2066104204677686e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.973833874124864e-10, std=1.4281958726769517e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.581662966212207e-09, std=3.361125493483996e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.412317065165098e-09, std=3.33730099555396e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.0045688725313084e-09, std=1.6307766372847254e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.643301044713553e-08, std=1.6534735323148197e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.4522162078710608e-11, std=4.793189987140067e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.4724377090687994e-08, std=4.933468176204769e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=3.0252640392802732e-09, std=1.5375662769656628e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=3.3310186609014636e-08, std=1.262723458239634e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=2.8314850464283836e-13, std=4.087415277354012e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=4.294959943251797e-09, std=4.2098943708879233e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=5.495275789968446e-09, std=1.6065331465142663e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=6.1522253957946305e-09, std=1.3767494237981737e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-8.210101043459872e-09, std=3.52593247043842e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-5.892634646897932e-08, std=3.0831026833766373e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.835260145024222e-07, std=2.891190342779737e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.5490907401272125e-07, std=2.674226379895117e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-6.32630225982922e-10, std=7.73837928136345e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.2565448887235107e-07, std=7.89538535173051e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=3.877327614532078e-08, std=3.7218160287011415e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-3.3949413591471966e-07, std=2.5253284547943622e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=6.269029739769394e-11, std=7.293831913557369e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=5.941473091297667e-07, std=7.1238409873330966e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=5.285095880935842e-07, std=8.540381531929597e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.4083946098253364e-06, std=9.582581697031856e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.098548864320037e-06, std=0.00010484748054295778\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.6145986592164263e-06, std=8.94265467650257e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0016961554065346718, std=0.0041069998405873775\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.745718226535246e-05, std=0.0023059039376676083\n",
            "Grad stats for input_proj.weight: mean=-8.225638836734106e-09, std=7.887827564445615e-07\n",
            "Grad stats for input_proj.bias: mean=-7.796665357773236e-08, std=3.891025698976591e-06\n",
            "Grad stats for output_head.0.weight: mean=2.0388652046676725e-06, std=0.0030213305726647377\n",
            "Grad stats for output_head.0.bias: mean=-0.0014764852821826935, std=0.0028334155213087797\n",
            "Grad stats for output_head.2.weight: mean=0.0002752287546172738, std=0.0015893190866336226\n",
            "Grad stats for output_head.2.bias: mean=0.0011824469547718763, std=0.002690768800675869\n",
            "Hungarian matching: row_ind=[17], col_ind=[0]\n",
            "conf_loss: 0.2044866979122162, smooth_l1_loss: 0.01386764831840992, ciou_loss: 1.1152395009994507, box_loss: 0.5645535588264465\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-1.9054899880188714e-08, std=0.000465440476546064\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=5.820172737003304e-05, std=0.002797930734232068\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-8.450081736555148e-07, std=0.00029339836328290403\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=8.00758134573698e-05, std=0.0036551577504724264\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=7.37827576813288e-10, std=3.0993738619145006e-05\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-5.41385679753148e-06, std=3.307733641122468e-05\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=3.5956404076387116e-07, std=1.8435905076330528e-05\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.7253178157261573e-06, std=4.6230023144744337e-05\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.996586772496812e-06, std=0.0006403944571502507\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.783263309742324e-06, std=0.0006232364103198051\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.3729881175095215e-05, std=9.133532148553059e-05\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=6.845602911198512e-06, std=9.937889990396798e-05\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-1.0710774489552932e-09, std=2.3541890186606906e-05\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-3.9935684981173836e-07, std=2.448956001899205e-05\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.3798063136505334e-08, std=1.7187276171171106e-05\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-3.713257683557458e-07, std=2.6544483262114227e-05\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-3.925731961729184e-11, std=1.9039606513615581e-06\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-1.5871083292040566e-07, std=1.934505917233764e-06\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-8.462921030627513e-09, std=1.6384346963604912e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-2.510631702534738e-08, std=2.947294660771149e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=5.964261617918964e-08, std=2.9580767659354024e-05\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.1525837635417702e-06, std=2.8814598408644088e-05\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=1.4742568055226002e-06, std=1.1287684174021706e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-6.07735671565024e-07, std=1.2003375559288543e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-2.306859842038378e-10, std=5.189087460166775e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=8.809058016367999e-08, std=4.186811111139832e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-1.651878189790068e-09, std=4.117609933018684e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-1.6852979456416506e-08, std=5.1582910600700416e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-7.361999898591876e-12, std=1.1155880201840773e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-2.42100703928827e-08, std=1.248118906005402e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.4460499403744507e-08, std=8.865633390087169e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-5.255736823528423e-08, std=1.110535413317848e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=5.161517435681162e-09, std=8.360118954442441e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=9.765980735210178e-08, std=1.0492627552594058e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-4.229723344906233e-07, std=0.00013625402061734349\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.6744843378546648e-06, std=0.00017431705782655627\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=7.937198454044392e-09, std=5.564227103604935e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-4.686206921178382e-06, std=5.777223486802541e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-8.438451715164774e-08, std=0.0002689454995561391\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.151204742200207e-06, std=0.00018021042342297733\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=2.0127544075876358e-10, std=5.4490610637003556e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-5.236908009464969e-07, std=5.422657704912126e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-2.686555944819702e-06, std=0.0006564695504494011\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-7.342259777942672e-06, std=0.0007619124953635037\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=4.2225365177728236e-06, std=0.0006044672336429358\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-5.6212338677141815e-06, std=0.0006570115219801664\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-6.444752216339111e-07, std=0.010847222991287708\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.00042932661017403007, std=0.011265065521001816\n",
            "Grad stats for input_proj.weight: mean=3.726765135070309e-05, std=0.0027178190648555756\n",
            "Grad stats for input_proj.bias: mean=0.00025044125504791737, std=0.012543704360723495\n",
            "Grad stats for output_head.0.weight: mean=7.894832378951833e-07, std=0.02497055195271969\n",
            "Grad stats for output_head.0.bias: mean=-0.0008067677263170481, std=0.027000412344932556\n",
            "Grad stats for output_head.2.weight: mean=-0.00039483432192355394, std=0.05766258016228676\n",
            "Grad stats for output_head.2.bias: mean=-0.0017259500455111265, std=0.10686979442834854\n",
            "Batch 120, Loss: 0.7690402269363403\n",
            "Hungarian matching: row_ind=[7 8], col_ind=[1 0]\n",
            "conf_loss: 0.29889941215515137, smooth_l1_loss: 0.008098678663372993, ciou_loss: 0.7769902944564819, box_loss: 0.3925444781780243\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.1286020035194966e-10, std=7.392275591655562e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.3996772629809584e-08, std=3.673753781185951e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=6.53536780248487e-10, std=2.1252678550354176e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-3.3540498378670236e-08, std=1.078754621630651e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=1.567780627542703e-12, std=6.285291931362735e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=5.675184766573693e-10, std=7.021450443289723e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.723450354125134e-10, std=1.3837845358466438e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=4.804052711193663e-10, std=1.5160962618665508e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.6520456114221815e-09, std=3.5401777154220326e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.7285945119738244e-08, std=3.796873784267518e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.1912939018875477e-08, std=1.999261030505295e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.0891341162277968e-08, std=1.938700506798341e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=8.60287396875492e-11, std=5.660351121150597e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.430150385952402e-08, std=5.846841304446571e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=5.018474080742408e-09, std=1.6648247083139722e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=4.1445957776886644e-08, std=1.3524785344998236e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-5.4602322663299674e-11, std=3.0644656590084196e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=4.0693382885592655e-08, std=3.105904795575043e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.198575765888222e-10, std=8.09133837265108e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-4.071463166610556e-10, std=9.136576863966184e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.5081953342341876e-08, std=2.8250963168829912e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.319116773236601e-08, std=3.056021341762971e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=3.594043107568723e-08, std=9.570618203724734e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=1.2740636634589464e-07, std=1.1318812539684586e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.494857653800864e-10, std=3.3773544600990135e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=3.0532208938893746e-07, std=3.5230914363637567e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-4.272732390120382e-09, std=1.1023605111404322e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-2.248042108021764e-08, std=8.884154340194073e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.1919132347770756e-11, std=2.774256927295937e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-6.795213636223707e-08, std=2.866582690330688e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=5.882230258436039e-09, std=1.321364106843248e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=7.2406152185067185e-09, std=1.1324275874358136e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=8.228936820842137e-08, std=2.3544802388641983e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-5.264520837044984e-07, std=2.265680996060837e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=6.112350092735142e-08, std=0.00024238966580014676\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.1479551176307723e-06, std=0.0002331845898879692\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-4.009130805116001e-09, std=6.257457425817847e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.2898384511572658e-06, std=6.319839303614572e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=1.773207003452626e-08, std=0.0003348282480146736\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-4.904543402517447e-07, std=0.0002141507138730958\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=2.8573037269552515e-09, std=6.79579097777605e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.1595321893764776e-06, std=6.716520874761045e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-2.6209545467281714e-06, std=0.0008101873681880534\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-6.9669049480580725e-06, std=0.0009058290743269026\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=4.387455192045309e-06, std=0.0009084581979550421\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-6.673782081634272e-06, std=0.0008151846122927964\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.00331112346611917, std=0.012614545412361622\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0006259878864511847, std=0.01396834384649992\n",
            "Grad stats for input_proj.weight: mean=-4.352131544038684e-09, std=3.286384355760674e-07\n",
            "Grad stats for input_proj.bias: mean=-2.2581870595672626e-08, std=1.237460992342676e-06\n",
            "Grad stats for output_head.0.weight: mean=-2.564385795267299e-06, std=0.027044903486967087\n",
            "Grad stats for output_head.0.bias: mean=0.0026526390574872494, std=0.02886744774878025\n",
            "Grad stats for output_head.2.weight: mean=0.003773279255256057, std=0.0716051533818245\n",
            "Grad stats for output_head.2.bias: mean=0.016475649550557137, std=0.1322755515575409\n",
            "Hungarian matching: row_ind=[18], col_ind=[0]\n",
            "conf_loss: 0.21137170493602753, smooth_l1_loss: 0.012048724107444286, ciou_loss: 0.9134291410446167, box_loss: 0.46273893117904663\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-7.212197852823898e-12, std=4.800387998216138e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-6.857563406015288e-10, std=2.4084761207632255e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.679053840408784e-10, std=1.0087350688081642e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-9.858268867901643e-09, std=8.399401849601418e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-4.757680794470476e-13, std=2.8473078117485784e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.6725441304442654e-10, std=3.3004294408556234e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-2.0843804113268583e-11, std=5.129254887492607e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.4430345807170397e-10, std=8.062182388357542e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=6.253159101632377e-10, std=1.7507478844436264e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.095622792490758e-08, std=1.8470812790383206e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=6.315474365692353e-09, std=7.596523801112198e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=2.914646302087931e-11, std=6.671323831142217e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=2.6189087357075813e-11, std=1.9527568895227887e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.3475091265036099e-08, std=1.9907000137209252e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-2.1586374354676252e-10, std=5.656413577526109e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.7163612753279267e-09, std=4.642272699584282e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.5020651389363593e-11, std=9.978692361301e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=1.568685981112594e-08, std=1.0118954918425516e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-8.286462488404922e-11, std=3.292976202828868e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.9185719679626345e-10, std=3.7677747855013877e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.1478689998511982e-08, std=9.517389685242961e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.5214020265830186e-08, std=1.00267516245367e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-2.3993152353796177e-08, std=4.6708682930329815e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=7.294603676655242e-08, std=4.53825941804098e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.0241437038704948e-11, std=1.2405711231622263e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.116729357406257e-08, std=1.2824255009036278e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.2378276181834735e-09, std=4.536682808975456e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=5.388507418047084e-09, std=3.6142112094239565e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-9.549444568435206e-13, std=1.195112304230861e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-1.78296311048598e-09, std=1.2354939826764166e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=4.5587626118503977e-08, std=8.297713975480292e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=5.029106375786796e-08, std=7.172550340328598e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=9.067832706932677e-09, std=1.0542097697907593e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-2.0935388533871446e-07, std=9.071145541383885e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.135371803684393e-06, std=0.00013392657274380326\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.0398189260740764e-06, std=0.0001401790214003995\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=2.013550215451687e-09, std=3.972987178713083e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.8883520169765688e-06, std=4.0288046875502914e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.0897220903416382e-07, std=0.000225168711040169\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.1584672847675392e-06, std=0.000136113420012407\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-9.898570851873956e-11, std=5.029550811741501e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=3.289428150310414e-06, std=4.954425821779296e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=3.8591101656493265e-06, std=0.000571254116948694\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.047182649926981e-05, std=0.0006547219236381352\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-3.43724423146341e-07, std=0.00046931649558246136\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-8.119883204926737e-06, std=0.0005555253592319787\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.003511216724291444, std=0.01058875396847725\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0019309016643092036, std=0.010169276036322117\n",
            "Grad stats for input_proj.weight: mean=-2.2542037125816705e-09, std=2.686613811420102e-07\n",
            "Grad stats for input_proj.bias: mean=-1.1649138542679793e-08, std=8.420426524935465e-07\n",
            "Grad stats for output_head.0.weight: mean=2.0923762349411845e-06, std=0.01843217946588993\n",
            "Grad stats for output_head.0.bias: mean=-0.0038007304538041353, std=0.019770681858062744\n",
            "Grad stats for output_head.2.weight: mean=-0.002394141862168908, std=0.049932289868593216\n",
            "Grad stats for output_head.2.bias: mean=-0.010617149993777275, std=0.09278219938278198\n",
            "No targets: conf_loss=0.1321232169866562, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=2.7170510633056644e-11, std=3.866668052410205e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-5.5327937786842085e-09, std=2.1096325042435637e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-4.4228246065536325e-11, std=4.151865695689594e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=7.237050070330042e-09, std=3.951853386752191e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.8028360882226266e-13, std=9.522272748085925e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=3.7435882171976687e-10, std=1.2286512252046577e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-2.3987326014385246e-10, std=1.709047481313064e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-8.955153285583606e-10, std=3.406636750469261e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-2.3549795447053157e-10, std=5.880060172103185e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.539725845769226e-09, std=8.02341020289532e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.1136496997087306e-09, std=2.2051223425023636e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.9789290206517762e-09, std=2.0445357051812607e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.255309192657268e-12, std=6.354532899877086e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.586762886698125e-09, std=6.522718365431501e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=6.344953729087166e-11, std=1.6954759018972254e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=8.997921296938216e-10, std=1.4476846388333797e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-6.9447919637255495e-12, std=3.344135990346331e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=5.841963801600514e-09, std=3.33099414717708e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-4.79211725856743e-10, std=1.063818046986853e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-9.598088990259157e-10, std=1.1781276754163628e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.75636935498369e-09, std=3.0928450200917723e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=7.749264341327944e-09, std=3.069333729399659e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=2.677811750118053e-09, std=1.3933766922491486e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.9995010919492415e-08, std=1.4806281569690327e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.6057231025666816e-11, std=4.2695228330558166e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=3.954964711283537e-08, std=4.443349723715073e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-3.0042437426658353e-09, std=1.3455378393700812e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-3.5150907962133715e-08, std=1.12614930003474e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=4.0024233927127284e-13, std=3.734384677045455e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=8.112951199734653e-09, std=3.833238224615343e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.0993919552504394e-08, std=1.4693715684188646e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.283788009232012e-08, std=1.2521380767793744e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.453866774336348e-09, std=3.099469040535041e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.286927352519342e-08, std=2.7534995297173737e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.689531927695498e-07, std=2.770247374428436e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.887726111566735e-07, std=2.538424996600952e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.2943248129413405e-10, std=8.363706911040936e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.9590471822539257e-07, std=8.41592100186972e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=4.38421423609725e-08, std=3.9257003663806245e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-5.508655362973514e-07, std=2.4632332497276366e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.0188268007027546e-09, std=8.146493200911209e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=9.286553108722728e-07, std=7.874044058553409e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=9.146789921032905e-07, std=9.32132315938361e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=2.436756403767504e-06, std=0.00010345003101974726\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-8.178728307939309e-07, std=0.0001114512124331668\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.230177531397203e-06, std=9.439764835406095e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017166613833978772, std=0.003872761270031333\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.8693614846561104e-05, std=0.0023873259779065847\n",
            "Grad stats for input_proj.weight: mean=-3.132743175982e-09, std=2.0224196362050861e-07\n",
            "Grad stats for input_proj.bias: mean=-1.8754247932406543e-08, std=8.279083090201311e-07\n",
            "Grad stats for output_head.0.weight: mean=2.2350868675857782e-06, std=0.003031476167961955\n",
            "Grad stats for output_head.0.bias: mean=-0.0015259194187819958, std=0.0029288174118846655\n",
            "Grad stats for output_head.2.weight: mean=0.00027800293173640966, std=0.0016175450291484594\n",
            "Grad stats for output_head.2.bias: mean=0.0012194161536172032, std=0.0027733491733670235\n",
            "Hungarian matching: row_ind=[2 7 8], col_ind=[1 2 0]\n",
            "conf_loss: 0.3830507695674896, smooth_l1_loss: 0.011771011166274548, ciou_loss: 0.9670783877372742, box_loss: 0.4894247055053711\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-6.925952172887051e-11, std=2.2872538352203264e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=3.1910641240529e-08, std=1.2545340268843574e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-5.106726846948462e-11, std=2.883250260765635e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.4164029948915413e-09, std=2.899889750551665e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-2.6097318750473164e-12, std=6.912741667974842e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.9513173299401387e-09, std=8.965874087607517e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.3237716478542438e-10, std=1.1706907798725297e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-4.2201486749604555e-10, std=2.4096792117234145e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=3.6207659093179245e-10, std=4.239598183630733e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=2.7967320903599102e-08, std=5.977505566079344e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-4.216362015085906e-08, std=1.5795050103406538e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=1.0587708487719283e-08, std=1.4911219068380888e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-4.560259461716676e-11, std=4.3528714854801365e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-1.996845355733967e-08, std=4.564600999401591e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.0336771438801406e-09, std=1.2257258958925377e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.2955518435830982e-08, std=1.0337201956645004e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.7243207689764404e-11, std=2.3033156537621835e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-2.7118511880530605e-08, std=2.3467683263334038e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=3.755937338922877e-09, std=6.479990588559303e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=7.425159154195171e-09, std=7.29398209387e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-2.7346331421540526e-08, std=2.1596799797407584e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-6.220942339041358e-08, std=2.2456406441051513e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=9.499387942923931e-09, std=7.64154719945509e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-1.6126045920827892e-07, std=9.116810360865202e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.2773455904113717e-10, std=2.774851282083546e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.9437210596606747e-07, std=2.8752924663422164e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-9.212852702944474e-11, std=8.636456186650321e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=5.579135375910482e-09, std=7.0275496000249404e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=6.317307787995219e-12, std=2.159561745429528e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-2.613786342919866e-08, std=2.22108837988344e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-9.903423858759197e-08, std=8.931377124099527e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.1267957233940251e-07, std=7.603436642966699e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.797008053472382e-08, std=1.9951312424382195e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.428123480058275e-07, std=1.782215440471191e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.3458929970511235e-07, std=0.0001692161022219807\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=2.6697948669607285e-06, std=0.0001558317308081314\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-4.012264298580703e-09, std=4.598025407176465e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.995796765186242e-06, std=4.671725764637813e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.047892735390633e-07, std=0.0002376260672463104\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=2.003812369366642e-06, std=0.00014533950889017433\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.2053664733002734e-09, std=5.316192255122587e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.3350841072679032e-06, std=5.190216688788496e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.6159870597221015e-07, std=0.0006099238526076078\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-4.929033821099438e-07, std=0.0006764560239389539\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.720424163271673e-06, std=0.0006825692835263908\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.1571561117307283e-05, std=0.0005854421760886908\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0040341694839298725, std=0.012378926388919353\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0009137213928624988, std=0.011270866729319096\n",
            "Grad stats for input_proj.weight: mean=1.4897826972060102e-08, std=1.2272726053197403e-06\n",
            "Grad stats for input_proj.bias: mean=8.477498170122999e-08, std=4.5263122956384905e-06\n",
            "Grad stats for output_head.0.weight: mean=2.711920387810096e-06, std=0.020920777693390846\n",
            "Grad stats for output_head.0.bias: mean=-0.002016657730564475, std=0.022425135597586632\n",
            "Grad stats for output_head.2.weight: mean=-0.00311443954706192, std=0.051461122930049896\n",
            "Grad stats for output_head.2.bias: mean=-0.013410150073468685, std=0.09330663830041885\n",
            "Hungarian matching: row_ind=[11 16 19], col_ind=[2 1 0]\n",
            "conf_loss: 0.4154135286808014, smooth_l1_loss: 0.008044098503887653, ciou_loss: 0.780897319316864, box_loss: 0.3944707214832306\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=7.582307177955716e-12, std=9.967750180805979e-09\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.6674728264831629e-09, std=5.0782269056526275e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-7.532811874266798e-11, std=2.432377499417271e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=4.7789736612458e-09, std=1.535622544679427e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=3.7966591676097394e-13, std=8.200575329908588e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=1.8082295383248237e-10, std=8.716539490194464e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-6.280548563858401e-12, std=1.971246454957054e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-6.0604854468238045e-12, std=2.1533301364229374e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=9.680664603273215e-11, std=4.0897631947700575e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.9428323394521385e-09, std=4.3222247114727e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.3650591768055165e-09, std=2.713152866817836e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-5.366890931668422e-09, std=2.588307097539655e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=8.337668229441153e-12, std=7.7388278896251e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.891512001530373e-09, std=7.765414977711771e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.8837555607341692e-11, std=2.270960806072253e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.7974334787804764e-10, std=1.9220389901875023e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-7.2510053517049755e-12, std=4.540738274272371e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=6.094804660961017e-09, std=4.5141426596728706e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.743086674999006e-09, std=1.970085463653959e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-3.566551054490219e-09, std=2.240213348159159e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.850942593113359e-09, std=4.208686448237131e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.5746213222200822e-09, std=4.172411536274012e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-7.831118864487507e-09, std=2.6500765670789406e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-5.24129148971042e-08, std=2.659435267560184e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-2.038536006665481e-12, std=7.429504762512806e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-6.717171263659338e-09, std=7.604128313687397e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-4.336211389954769e-09, std=2.6323871225031326e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-3.746571053397929e-08, std=2.159655650757486e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-1.7696955012524995e-12, std=8.212608690882917e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-8.402243167893175e-08, std=8.365734629478538e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.5563200506107933e-08, std=6.6279189923079684e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.8125895451248653e-08, std=5.620963293040404e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=2.097293361202901e-08, std=5.795426659460645e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.137358817184577e-08, std=5.773633347416762e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=1.0941976142930798e-06, std=0.00011170117795700207\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-8.29772307042731e-06, std=0.000116904397145845\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=8.160640163623611e-09, std=4.101508602616377e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-3.669601028377656e-06, std=4.125710256630555e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=6.21087679064658e-08, std=0.00020361726637929678\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-8.900460670702159e-07, std=0.00012067920761182904\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.0298518421668632e-10, std=3.755928628379479e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-4.5692098638028256e-07, std=3.770814146264456e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-9.909036862154608e-07, std=0.0004538419016171247\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.522284376027528e-06, std=0.0004982338869012892\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=2.6401721697766334e-06, std=0.0004670284688472748\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=6.2041763158049434e-06, std=0.0004530683218035847\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0012056318810209632, std=0.008446159772574902\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0015078389551490545, std=0.007917401380836964\n",
            "Grad stats for input_proj.weight: mean=-1.0853544729627629e-09, std=5.175529693701719e-08\n",
            "Grad stats for input_proj.bias: mean=-6.084289072560978e-09, std=1.763825281386744e-07\n",
            "Grad stats for output_head.0.weight: mean=1.986845745705068e-07, std=0.016307484358549118\n",
            "Grad stats for output_head.0.bias: mean=-0.000289316289126873, std=0.017302604392170906\n",
            "Grad stats for output_head.2.weight: mean=-0.0011044174898415804, std=0.043482426553964615\n",
            "Grad stats for output_head.2.bias: mean=-0.004694269970059395, std=0.07892991602420807\n",
            "Hungarian matching: row_ind=[10], col_ind=[0]\n",
            "conf_loss: 0.21435551345348358, smooth_l1_loss: 0.016988908872008324, ciou_loss: 1.0810250043869019, box_loss: 0.5490069389343262\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.4632488276600242e-10, std=7.824504422160317e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.4018763927481359e-08, std=4.525656720488769e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=4.038633316660878e-11, std=9.007687395978792e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-2.8002142826721865e-09, std=8.754024065638077e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-6.513886652292911e-15, std=2.189163694765739e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-3.076279231351009e-10, std=2.8824231890212104e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-2.76780154351286e-10, std=4.016758481384386e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-7.767975152006557e-10, std=7.833128989886973e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-3.220916866553125e-10, std=1.273947418667376e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-9.288902980131297e-09, std=1.78049390342494e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.3913805219090136e-08, std=5.382817107602023e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.1744056272486887e-09, std=5.06310868786386e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=2.4506166193538625e-11, std=1.5311454149014025e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.0341330458629727e-08, std=1.5968647915087786e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-2.0632592856451026e-10, std=4.089367564574786e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-2.7132107671690164e-09, std=3.488915183424979e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.3994250203097636e-11, std=7.674548641034562e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=1.3754382521824482e-08, std=7.761501308323204e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=8.018095631889821e-10, std=2.8302537202762323e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.594870346899313e-09, std=3.208409680155455e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=7.0276477970310225e-09, std=7.573504490210325e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.428692719684932e-08, std=7.588234325339727e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-2.8529143492050935e-09, std=3.964401457778877e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=4.948902798673771e-08, std=4.155673195782583e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=6.234893851209122e-11, std=1.154306005446415e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=6.784957662375746e-08, std=1.1983745480392827e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-2.427021916773242e-09, std=3.846851996058831e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-2.718975977700211e-08, std=3.1723682241135975e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-2.7576829708664263e-12, std=1.1868529554703855e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-4.666891584292898e-08, std=1.218290321958193e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=6.568233068549034e-09, std=6.557935648743296e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=7.894144005149428e-09, std=5.60511989533552e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=1.6912281353143044e-08, std=8.116255230561364e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.3272951327489864e-07, std=8.074594916251954e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=3.391646714590024e-07, std=0.00012614461593329906\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.3661401681019925e-06, std=0.00011408457066863775\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=3.739891951681784e-09, std=3.1035058782435954e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.2749874258588534e-06, std=3.1853782274993137e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-9.20031126838694e-08, std=0.00017327666864730418\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.1844879281852627e-06, std=0.00010665796435205266\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-3.252878855164454e-09, std=3.4718697861535475e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.7186314380523982e-06, std=3.412471414776519e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=2.6675458286717912e-08, std=0.0004410379915498197\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=9.954692359315231e-08, std=0.0004944342654198408\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.0773472897417378e-06, std=0.0004976585623808205\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=4.435541541170096e-06, std=0.00042842503171414137\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.004732461180537939, std=0.011631581000983715\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0015408900799229741, std=0.009136064909398556\n",
            "Grad stats for input_proj.weight: mean=-6.85367806951831e-09, std=4.047278707730584e-07\n",
            "Grad stats for input_proj.bias: mean=-4.557167798679984e-08, std=1.7896034023578977e-06\n",
            "Grad stats for output_head.0.weight: mean=3.1639356166124344e-06, std=0.016051148995757103\n",
            "Grad stats for output_head.0.bias: mean=-0.0037120147608220577, std=0.017041942104697227\n",
            "Grad stats for output_head.2.weight: mean=-0.002682896563783288, std=0.04513409361243248\n",
            "Grad stats for output_head.2.bias: mean=-0.01175939105451107, std=0.08347238600254059\n",
            "No targets: conf_loss=0.1343805491924286, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=7.065119322913205e-12, std=2.8164160781329883e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-2.3853450326072334e-09, std=1.4705943840453983e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-1.5248149964897095e-11, std=3.675217641330164e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.0397471772449762e-09, std=2.75189449894242e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=6.005048888702014e-14, std=9.874511874841119e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.0760668744946855e-10, std=1.1615631123618186e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=9.556414687361681e-11, std=1.9014645857851065e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.1656437754202784e-10, std=2.7880950881353783e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.9173870824396033e-10, std=5.4167081486866664e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.6774962247344547e-09, std=6.539734442867484e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=6.886775594239225e-10, std=2.5282483306909853e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-2.73122280347593e-09, std=2.3752431843604427e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.3201162385456655e-11, std=7.19675981031287e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=4.623216920407458e-09, std=7.38757677254398e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.899495977175647e-10, std=2.0088738494905556e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=2.3943806937154477e-09, std=1.7174167510347615e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-7.632644516419873e-12, std=3.8160838045087075e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=7.694415771197782e-09, std=3.814539795143901e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-4.989532120802664e-10, std=1.2069065746800334e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.0120045912387354e-09, std=1.3679637334007566e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.819156463829131e-09, std=3.5884750104742125e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=7.22512005779663e-09, std=3.5884505678041023e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-4.312006751661102e-09, std=1.6058608025559806e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.5829880456740284e-08, std=1.63947163400735e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.401382994705493e-11, std=4.946627996105235e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.804288167292725e-08, std=5.096308655083703e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=2.0196200267719178e-09, std=1.5964233170961961e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=2.1525586646475858e-08, std=1.2699457556664129e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-2.7985253003848243e-12, std=4.319423965171154e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=7.552792169462919e-09, std=4.421057155923336e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.7916822631368632e-08, std=1.6465952512589865e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-3.1923399035349576e-08, std=1.3945785894975415e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-8.94473117796224e-09, std=3.5150660551153123e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-5.089221843945779e-08, std=3.106883241343894e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-4.03324008857453e-07, std=2.9305851057870314e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-3.903915626324306e-07, std=2.7468066036817618e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-5.169535910454215e-10, std=8.847287972457707e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.129201988054774e-07, std=8.922346751205623e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=2.982270075335691e-08, std=4.223433279548772e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-2.8526309847620723e-07, std=2.6416852051625028e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.1221086282375836e-09, std=9.004840649140533e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.2250879990460817e-06, std=8.69159703142941e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=6.23043732161932e-08, std=0.00010120298247784376\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.43249167194881e-07, std=0.0001094187464332208\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.06359016172064e-06, std=0.00011212309618713334\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=2.3346672151092207e-06, std=9.997584129450843e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017282313201576471, std=0.0038782316260039806\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.00010642646520864218, std=0.00249222363345325\n",
            "Grad stats for input_proj.weight: mean=-2.2590083137430383e-09, std=1.5749031945233583e-07\n",
            "Grad stats for input_proj.bias: mean=-1.2842486185604685e-08, std=5.716588020732161e-07\n",
            "Grad stats for output_head.0.weight: mean=1.8746432033367455e-06, std=0.0030743868555873632\n",
            "Grad stats for output_head.0.bias: mean=-0.0016008982202038169, std=0.0030050519853830338\n",
            "Grad stats for output_head.2.weight: mean=0.00027851469349116087, std=0.0016167671419680119\n",
            "Grad stats for output_head.2.bias: mean=0.0012391103664413095, std=0.002809293335303664\n",
            "Hungarian matching: row_ind=[16], col_ind=[0]\n",
            "conf_loss: 0.21975430846214294, smooth_l1_loss: 0.008310928009450436, ciou_loss: 0.8115654587745667, box_loss: 0.40993818640708923\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=8.109028205860458e-12, std=1.0172562525667672e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=5.446316175827803e-10, std=5.747629643337859e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-6.217179548961838e-11, std=1.9063934075802536e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=9.633307485046316e-09, std=1.577224907123309e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.4495336314878102e-12, std=5.3494566998324444e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=1.1317844439417968e-09, std=6.63725430172235e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=7.795781242769806e-10, std=1.1340141981008856e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.044163505132701e-09, std=1.6796030877230805e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-2.5235413758650793e-10, std=2.9510039212254924e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=9.89980186716366e-09, std=3.5610267445918e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-6.500584959212574e-09, std=1.6902278048291919e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.6196468045091024e-09, std=1.5237189927574946e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-7.234168819536535e-11, std=4.721904360849294e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-3.131285453150667e-08, std=4.868613245889719e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-3.0657934524391806e-10, std=1.2943960427946877e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-6.3161538221834235e-09, std=1.1025175581380608e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=6.137512720272298e-11, std=2.458950518757774e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-5.420231730113301e-08, std=2.441331332647678e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=5.661742186191532e-09, std=9.400680482940516e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.1261629850878307e-08, std=1.0637693321768893e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-2.1223542034931597e-08, std=2.426927721899119e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-5.6975579809659394e-08, std=2.347075678699184e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=2.4620646854600636e-08, std=1.2354925274848938e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-5.898136237192375e-07, std=1.2982224689039867e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-2.950084621033966e-10, std=3.866454335366143e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-2.900675610817416e-07, std=4.034883204440121e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-2.431896906074371e-09, std=1.3351653251447715e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-2.5334060183013207e-08, std=1.0991582712449599e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-2.9515612176567174e-11, std=3.756614887606702e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-1.6162559290933132e-07, std=3.865372036671033e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.2670649596202566e-07, std=2.0254557966836728e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.4645550550085318e-07, std=1.746307134453673e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=6.790514817112125e-08, std=2.94501987809781e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.339962179576105e-07, std=2.6854537281906232e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=3.842559635813814e-06, std=0.0003887022321578115\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.5123922821658198e-05, std=0.00035646301694214344\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=2.9417843716572634e-09, std=0.00011343928781570867\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.3262475704323151e-06, std=0.00011437014472903684\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-4.094964083378727e-07, std=0.0005583318998105824\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=5.704699105990585e-06, std=0.00034645467530936003\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=8.018474773052731e-10, std=0.00011068735329899937\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-5.572025656874757e-06, std=0.00010926090908469632\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=7.539641728726565e-07, std=0.001310960971750319\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=2.0591232896549627e-06, std=0.0014604816678911448\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=2.0941277398378588e-05, std=0.0015210275305435061\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.3711720384890214e-05, std=0.0013482646318152547\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.009985674172639847, std=0.02521328628063202\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0005058972164988518, std=0.02514614351093769\n",
            "Grad stats for input_proj.weight: mean=7.502339194331853e-09, std=5.27860720467288e-07\n",
            "Grad stats for input_proj.bias: mean=4.3485268719223313e-08, std=2.023210072366055e-06\n",
            "Grad stats for output_head.0.weight: mean=-4.731089575216174e-06, std=0.04317106679081917\n",
            "Grad stats for output_head.0.bias: mean=0.006389163434505463, std=0.044965144246816635\n",
            "Grad stats for output_head.2.weight: mean=0.0031768367625772953, std=0.10155518352985382\n",
            "Grad stats for output_head.2.bias: mean=0.013439360074698925, std=0.18288442492485046\n",
            "Hungarian matching: row_ind=[11 15 16 19], col_ind=[1 0 3 2]\n",
            "conf_loss: 0.49750882387161255, smooth_l1_loss: 0.00971804466098547, ciou_loss: 0.823261559009552, box_loss: 0.4164898097515106\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.5620772036983865e-11, std=2.225748296780239e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.1770137087196986e-09, std=9.662152677947233e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.921339753963025e-10, std=6.34939567589754e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-6.2145302237581745e-09, std=3.1849802439865016e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=1.7017611278480338e-12, std=2.0088137375751103e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=5.668931435387492e-10, std=2.2135846933224457e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=6.704757304909492e-10, std=4.343027626418916e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.6084882314970628e-09, std=5.363951061099215e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-2.3561352868739505e-10, std=9.96964288901836e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=5.831560123681356e-09, std=1.0463935495863552e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.549434524074968e-09, std=6.264903049668646e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-2.7276580993884636e-09, std=5.432193006527086e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-2.356922122748184e-11, std=1.7262094331726985e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-9.782034737781942e-09, std=1.7224853365860326e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.5407820292144834e-10, std=4.935596962241107e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.334382547848236e-09, std=3.7762814031339076e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.5681901050234046e-11, std=9.860669791805776e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-2.0341078155183823e-08, std=9.691888891438794e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.143613064831129e-11, std=3.5636540474115463e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.205302524454055e-11, std=3.8952620684540307e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-7.966264092829078e-09, std=8.931050388127915e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-1.1593855653302398e-08, std=8.795892085800006e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=1.3101640661261627e-07, std=4.745436854136642e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-1.2345316235951032e-07, std=4.8187084757955745e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.0457709004318971e-10, std=1.3984440556669142e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.3340964244434872e-07, std=1.389962449138693e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.1222601514759845e-08, std=4.365249424154172e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.193266427890194e-07, std=3.8630596463917755e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.529631976637802e-11, std=1.2770698276654002e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-3.7750567116745515e-08, std=1.2942332432430703e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=3.662212577637547e-08, std=6.463009412982501e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=4.1800483074894146e-08, std=5.433884325611871e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=2.9250912803036044e-08, std=9.456306543143e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=1.4415147120416805e-07, std=8.962598258221988e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=1.6047172266553389e-06, std=0.0001304852485191077\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.2355894796201028e-06, std=0.0001014833032968454\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-2.967463427760997e-11, std=3.5398450563661754e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.4044928181865544e-07, std=3.563125937944278e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.2383187570085283e-07, std=0.00015857844846323133\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=2.383186938459403e-06, std=9.888606291497126e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.7639223415244487e-09, std=3.226811168133281e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-3.615773948695278e-06, std=3.101305992458947e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=2.3975792373676086e-06, std=0.0003709323354996741\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=6.348773240461014e-06, std=0.0004020903434138745\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=5.085437351226574e-06, std=0.00042631415999494493\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.739341314532794e-05, std=0.00038274555117823184\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0048076314851641655, std=0.01181967556476593\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0002461005060467869, std=0.008166083134710789\n",
            "Grad stats for input_proj.weight: mean=1.0918400628057157e-09, std=1.1502688579412279e-07\n",
            "Grad stats for input_proj.bias: mean=4.851117285653572e-09, std=3.5329915704096493e-07\n",
            "Grad stats for output_head.0.weight: mean=-1.7423590179532766e-06, std=0.012781495228409767\n",
            "Grad stats for output_head.0.bias: mean=0.004433551337569952, std=0.012986451387405396\n",
            "Grad stats for output_head.2.weight: mean=0.002047694521024823, std=0.029866596683859825\n",
            "Grad stats for output_head.2.bias: mean=0.009030666202306747, std=0.05605580657720566\n",
            "No targets: conf_loss=0.11872607469558716, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-4.9844768069962075e-12, std=2.90076371811665e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-5.407193026663037e-10, std=1.2307332042382768e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-5.08308239249855e-12, std=5.039090922309697e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=3.7187524171145014e-09, std=3.032113511380885e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=6.658250339963701e-13, std=1.3218262040481932e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=2.950143185298515e-10, std=1.3242245522349094e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.8225483061916634e-10, std=1.768263402368575e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.0003669004277072e-09, std=3.1503056163728616e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.5896450822339148e-10, std=6.258559892557969e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.8032620669193875e-09, std=7.205527907672149e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.058294785138969e-09, std=2.044724709548973e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-5.117908763452306e-09, std=1.927700736814586e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.734370427783023e-12, std=6.538706998071575e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=4.50198323065365e-09, std=6.464091484303935e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.5718815965802833e-11, std=1.7695349185942177e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=2.7442043082359646e-10, std=1.3847922275544988e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-7.386771749828824e-12, std=3.2876545930093926e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=5.9892535375638545e-09, std=3.207687626627376e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.791500919308021e-10, std=1.038388219853914e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-5.532931890428472e-10, std=1.1015099943278983e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.5904078881922032e-09, std=2.8943185270691174e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=4.908074835441312e-09, std=2.902022799844417e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-4.05862721208905e-09, std=1.419753061782103e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=3.377918744718045e-08, std=1.320335059062927e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.079788160609276e-11, std=4.515684679518017e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.345163162611243e-08, std=4.500855936839798e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.5686794085922884e-09, std=1.4867898698867066e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.5569597167086613e-08, std=1.0375638339610305e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=9.841988335423935e-13, std=3.850053360565653e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=4.8228487870005665e-09, std=3.848554115393199e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=6.160450283232421e-08, std=1.551221657791757e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=7.149270686568343e-08, std=1.275569957215339e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.0906939351684741e-08, std=3.0651194720121566e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-4.289374899713039e-08, std=2.627679577926756e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.175081246808986e-07, std=2.9486274797818623e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=5.950326453785237e-07, std=2.4253518859040923e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=2.3437340956888875e-10, std=8.361408617929555e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.4340612608521042e-07, std=8.150650501193013e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-5.940026248651975e-11, std=3.886960257659666e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=9.89746240520617e-09, std=2.452106127748266e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.0305224168737368e-10, std=7.530566563218599e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=2.9219913244560303e-07, std=7.212388936750358e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=5.364255457607214e-07, std=8.592054655309767e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.4101312899583718e-06, std=9.127430530497804e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-8.083213742793305e-07, std=9.793454228201881e-05\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.5769473975524306e-06, std=8.088655886240304e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.001642465009354055, std=0.0038933604955673218\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.351935396902263e-05, std=0.0021518429275602102\n",
            "Grad stats for input_proj.weight: mean=-1.189506715348898e-09, std=1.754155789512879e-07\n",
            "Grad stats for input_proj.bias: mean=-6.023067822269468e-09, std=4.621889218014985e-07\n",
            "Grad stats for output_head.0.weight: mean=1.2527143553597853e-06, std=0.0028747175820171833\n",
            "Grad stats for output_head.0.bias: mean=-0.0013714845990762115, std=0.0026346410159021616\n",
            "Grad stats for output_head.2.weight: mean=0.00026847110711969435, std=0.001544965780340135\n",
            "Grad stats for output_head.2.bias: mean=0.0011035733623430133, std=0.0025300239212810993\n",
            "Batch 130, Loss: 0.11872607469558716\n",
            "No targets: conf_loss=0.12885704636573792, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-2.0614324049844646e-12, std=1.022367701608573e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.8347150188002814e-10, std=5.408040948395865e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=2.0314010890087886e-11, std=2.1797074367668756e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.6577034189779738e-09, std=1.8296725556865567e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-6.727287455397801e-14, std=6.93275703511631e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.156567979749724e-11, std=7.950428759784245e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.6157561399943177e-10, std=1.3786015884420522e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-4.179318002783816e-10, std=1.9323570299434323e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=7.58923479615703e-11, std=3.5913814144805656e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.5915461171189804e-09, std=4.078376036886766e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=4.2033576619360247e-10, std=2.0704689518424857e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=1.2701777407642112e-09, std=1.7972806176658196e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=7.920220035373404e-12, std=5.298434757605719e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.3720635173040137e-09, std=5.354833021442573e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.2591781223546548e-10, std=1.4812484039339324e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=2.3823647499199296e-09, std=1.2654832914904546e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-7.384717837233268e-12, std=2.8220940251344473e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=5.807245351263646e-09, std=2.8259728779289617e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.5573708989080615e-09, std=9.127160893740438e-08\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-3.1297182623291064e-09, std=1.0174348830105373e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.434104473536536e-09, std=2.882232195133838e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=7.101682797383546e-09, std=2.706792372464406e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.1324310378313385e-09, std=1.272328177037707e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=1.4945442217140226e-08, std=1.3372296052693855e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=4.315540633181847e-11, std=4.144296212871268e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.0857315752873546e-08, std=4.2339337369412533e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-9.248907195669176e-12, std=1.2985569810552988e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.0954144258334964e-09, std=1.0306632702850038e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-1.7795105666795763e-12, std=3.454557599980035e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=6.225437942930512e-09, std=3.51452229097049e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=3.940441306582443e-09, std=1.368675157209509e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=4.556078181394696e-09, std=1.1529865560078179e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-5.626272781000807e-09, std=2.8483009373303503e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.8393851775044823e-08, std=2.5347721930302214e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.4468002973444527e-07, std=2.4530363589292392e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.3436541596311145e-10, std=2.4046246835496277e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-4.1847117437932013e-10, std=7.986354830791242e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.494171553735214e-07, std=8.110031558317132e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.3676525689731989e-08, std=3.7027297366876155e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.495432684350817e-07, std=2.2279908080236055e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-4.5574388707336766e-10, std=7.638705938006751e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=6.554200240316277e-07, std=7.441582511091838e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=2.3781810298828532e-08, std=8.882457041181624e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=6.176651368150488e-08, std=9.788796160137281e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-9.219756975653581e-07, std=0.00010098572965944186\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.2337478665358503e-06, std=9.176266030408442e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017027901485562325, std=0.003905122634023428\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.711881385650486e-05, std=0.002343461848795414\n",
            "Grad stats for input_proj.weight: mean=-4.1261119521074363e-10, std=5.549899384504897e-08\n",
            "Grad stats for input_proj.bias: mean=-2.31028707275982e-09, std=1.960299158554335e-07\n",
            "Grad stats for output_head.0.weight: mean=1.7603379092179239e-06, std=0.003040757728740573\n",
            "Grad stats for output_head.0.bias: mean=-0.00149455142673105, std=0.002868627430871129\n",
            "Grad stats for output_head.2.weight: mean=0.0002744616649579257, std=0.0016000954201444983\n",
            "Grad stats for output_head.2.bias: mean=0.001191636431030929, std=0.0027097181882709265\n",
            "Hungarian matching: row_ind=[15], col_ind=[0]\n",
            "conf_loss: 0.21787044405937195, smooth_l1_loss: 0.004602479748427868, ciou_loss: 0.8272908329963684, box_loss: 0.4159466624259949\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-1.0706650843683718e-11, std=2.686975797416835e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=5.461445962140488e-09, std=1.3304986623552395e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-5.826959748045368e-11, std=9.514955934264435e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=2.4067323689536124e-09, std=3.9607090229765163e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-1.1464973935504386e-12, std=2.8100778592943243e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-4.215333637702656e-10, std=2.995480841150311e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.764157513990284e-10, std=7.19346502364715e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=4.4843884161593905e-10, std=7.624093001368237e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.3239143115129082e-09, std=1.5642187634057336e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-9.034388348538869e-09, std=1.54743375446742e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=8.812556018256146e-09, std=1.071788801709772e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.464990072643559e-09, std=9.73834858086775e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.8875548693508826e-11, std=3.081112254221807e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.2363032375617422e-08, std=3.1187869353743736e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.4116977586908774e-09, std=8.835943958729331e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.520056613912857e-08, std=7.265098247444257e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-4.043387846763835e-11, std=1.6982254180675227e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=3.818913185682504e-08, std=1.6673449465542944e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.9680321816650803e-09, std=7.915436981420498e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=4.684436838431338e-09, std=8.765764505369589e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.1532506505318452e-08, std=1.5618541056028334e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=3.727470954117962e-08, std=1.578223418619018e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.6401628499806975e-08, std=1.0353866855439264e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-7.713759941907483e-08, std=1.1259244274697267e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.9951566787579367e-10, std=3.5746875255426858e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=2.638470562033035e-07, std=3.7106447052792646e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-2.1564227736803332e-08, std=1.1651989552774467e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-2.2674612409900874e-07, std=9.616639545129146e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-5.85518300511012e-11, std=3.7837253330508247e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=3.857965680253983e-07, std=3.838718839688227e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=6.618617653941783e-09, std=1.8327858924749307e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=4.424464350449853e-09, std=1.5595453078276478e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-7.98575570115645e-08, std=2.6284258638042957e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-6.386100039890152e-07, std=2.3358037651632912e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-5.709861397917848e-06, std=0.0002824091352522373\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-5.755389793193899e-06, std=0.0003043644828721881\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-9.108418907999294e-09, std=9.7051371994894e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=4.863742560701212e-06, std=9.648984269006178e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.6036292410935857e-07, std=0.000467308476800099\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=2.753620719886385e-06, std=0.00028339840355329216\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-4.462624048073849e-09, std=8.32864607218653e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=2.545022653066553e-06, std=8.222675387514755e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.0778938985822606e-07, std=0.0009992019040510058\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.1798769012093544e-07, std=0.0010812475811690092\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-9.720384696265683e-06, std=0.0009100385359488428\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.011578569887206e-05, std=0.0010534304892644286\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0013959193602204323, std=0.013293111696839333\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.001400756649672985, std=0.016561251133680344\n",
            "Grad stats for input_proj.weight: mean=-2.460278925031645e-10, std=1.1849353853676803e-07\n",
            "Grad stats for input_proj.bias: mean=-1.038722885482457e-09, std=4.831792352888442e-07\n",
            "Grad stats for output_head.0.weight: mean=-4.711284418590367e-06, std=0.03870055824518204\n",
            "Grad stats for output_head.0.bias: mean=0.0030699498020112514, std=0.042591214179992676\n",
            "Grad stats for output_head.2.weight: mean=0.004814254119992256, std=0.0892573669552803\n",
            "Grad stats for output_head.2.bias: mean=0.021752195432782173, std=0.16610628366470337\n",
            "No targets: conf_loss=0.1315765231847763, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=9.26418230323689e-12, std=2.2500648810819257e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-3.381878244113068e-08, std=1.255485699402925e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=5.258655733086925e-10, std=1.4360990974182641e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-6.496166804481618e-08, std=1.592781813997135e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=1.5058024271930037e-12, std=1.815353556366972e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=2.3411648175653e-09, std=2.3252548331242906e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.8556189917973143e-10, std=2.437862711701655e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.0000681394117805e-09, std=6.862552481834427e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.3524275033205413e-09, std=2.3227444501117134e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.4446116242415883e-09, std=3.1428353963747213e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.9703355391698096e-08, std=2.0995618399410887e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.984094831821494e-09, std=2.487243193627364e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.4029037480323137e-11, std=7.470083573934971e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=5.200363251134377e-09, std=8.074085400266995e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-3.1462350086330915e-11, std=1.8232941556561855e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-8.250364835760138e-10, std=1.6370483990613138e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-4.7651049772667875e-12, std=3.1079604667638705e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=5.746924713889712e-09, std=3.271523851822167e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.0980998332854597e-09, std=1.0399914174286096e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.29808483354077e-09, std=1.245220886403331e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.3664306897662755e-09, std=3.0031921482986945e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=7.959456205242077e-09, std=3.095074418979493e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=2.2209505345927028e-09, std=1.4249128525989363e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.845498947579017e-08, std=1.4882642744851182e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.935622231414747e-11, std=4.2278790601812943e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.053059043940266e-08, std=4.429106184034026e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-1.7346232783488347e-10, std=1.3579084452430834e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-2.0502488595752766e-09, std=1.1217177871003514e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-1.6045775819151231e-12, std=3.779564679007308e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.1619302853205227e-08, std=3.881589236698346e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=9.610879203592049e-09, std=1.4257998373068403e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.0689994667245628e-08, std=1.2203806818433804e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.394827778422041e-09, std=3.1174320156424074e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-4.213875115510746e-08, std=2.7860999125550734e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.608293468460033e-07, std=2.6718864319263957e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=6.852283718217222e-08, std=2.526087519072462e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-5.203991126911944e-10, std=7.994122825039085e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.2820330514150555e-07, std=8.10358687886037e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.4057134123390824e-08, std=3.7896399589953944e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=2.6192736868324573e-07, std=2.3269531084224582e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.689493072693949e-10, std=7.6097744567960035e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=9.030808314491878e-07, std=7.478166025975952e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-3.493859708214586e-07, std=8.903343405108899e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-9.422537914360873e-07, std=9.954847337212414e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-9.90355147223454e-07, std=0.00010429803660372272\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.1861832263093675e-06, std=9.418830450158566e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017145732417702675, std=0.003967969678342342\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.824966501677409e-05, std=0.002392006805166602\n",
            "Grad stats for input_proj.weight: mean=-1.7359345960699102e-08, std=1.3842262660546112e-06\n",
            "Grad stats for input_proj.bias: mean=-1.0291210372770365e-07, std=5.406106538430322e-06\n",
            "Grad stats for output_head.0.weight: mean=1.2367090675979853e-06, std=0.003034492488950491\n",
            "Grad stats for output_head.0.bias: mean=-0.0015252534067258239, std=0.0029275210108608007\n",
            "Grad stats for output_head.2.weight: mean=0.0002771289146039635, std=0.0016033685533329844\n",
            "Grad stats for output_head.2.bias: mean=0.0012148625683039427, std=0.00276136863976717\n",
            "Hungarian matching: row_ind=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19], col_ind=[13  3  6  8  9 10 11  2  5  4  7  0 12 14 15 16 18 17  1]\n",
            "conf_loss: 2.26712965965271, smooth_l1_loss: 0.0566566102206707, ciou_loss: 1.270923137664795, box_loss: 0.6637898683547974\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-5.743407083258489e-09, std=6.491108251793776e-06\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=9.469970336795086e-07, std=3.964298593928106e-05\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.8071958374221708e-09, std=5.135788342158776e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-6.515347195090726e-07, std=6.154674338176847e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-7.552181102710165e-12, std=1.0645430847944226e-06\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-7.36132292900038e-08, std=1.1639867807389237e-06\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-7.644995747568828e-09, std=1.1231028338443139e-06\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-3.771059198243165e-08, std=3.2026350709202234e-06\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=6.927338347395562e-08, std=1.309450453845784e-05\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.130739401058236e-08, std=1.2511766726674978e-05\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-3.308067562102224e-07, std=8.049051757552661e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=6.586569725186564e-07, std=9.407291145180352e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-4.2621151052912865e-10, std=2.3656389203097206e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-2.2958754186674923e-07, std=2.9804118639731314e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.9821984054146924e-09, std=5.060953299107496e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-4.0756411578968255e-09, std=6.277817192312796e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=6.586153844523324e-11, std=9.999016583606135e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-9.6359379142541e-08, std=1.1044751317967894e-06\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=9.175039394904161e-09, std=2.019232852035202e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.2944306010685978e-08, std=3.204464292139164e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-2.8016216901960433e-08, std=8.853861800162122e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-8.13580300018657e-07, std=1.0961643056361936e-05\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.1443404446254135e-07, std=1.92570860235719e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.2238577912503388e-07, std=2.7719332138076425e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.04088349051068e-09, std=6.599569587706355e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-9.507102163297532e-07, std=8.234140295826364e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=9.90708581838362e-09, std=2.291929558850825e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=4.429530235938728e-07, std=2.1943067622487433e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=7.555733816388965e-12, std=5.150508513906971e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.4664365721728245e-07, std=5.285617589834146e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.1497775176394498e-07, std=2.1171237676753663e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=4.517479510468547e-07, std=2.7622432753560133e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=4.5389623437586124e-07, std=3.968143937527202e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-2.25262692765682e-06, std=5.660159877152182e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=1.1599562640185468e-05, std=0.0002630033704917878\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-6.2254084696178325e-06, std=0.00035773031413555145\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=8.359393177670427e-10, std=0.00010615175415296108\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-5.920817329752026e-06, std=0.0001080634247045964\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=4.7510006595530285e-08, std=0.00037620458169840276\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.2460677680792287e-06, std=0.00029663200257346034\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=1.4917631574462575e-09, std=7.262443250510842e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-4.656480086850934e-06, std=7.200537947937846e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=2.274690587000805e-06, std=0.0007766471244394779\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=5.722613423131406e-06, std=0.0009439709247089922\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=4.361085302662104e-06, std=0.0008150706416927278\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-2.2810418158769608e-06, std=0.00088367989519611\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.014194156043231487, std=0.033825647085905075\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.00022264683502726257, std=0.020010799169540405\n",
            "Grad stats for input_proj.weight: mean=2.629221569350193e-07, std=4.123364851693623e-05\n",
            "Grad stats for input_proj.bias: mean=1.5658183656341862e-06, std=0.00016825069906190038\n",
            "Grad stats for output_head.0.weight: mean=-1.7213140381500125e-05, std=0.02563077211380005\n",
            "Grad stats for output_head.0.bias: mean=0.012925409711897373, std=0.024748023599386215\n",
            "Grad stats for output_head.2.weight: mean=-0.002851567231118679, std=0.01257440634071827\n",
            "Grad stats for output_head.2.bias: mean=-0.012584400363266468, std=0.020336009562015533\n",
            "Hungarian matching: row_ind=[1], col_ind=[0]\n",
            "conf_loss: 0.20805445313453674, smooth_l1_loss: 0.01161228772252798, ciou_loss: 1.0425341129302979, box_loss: 0.5270732045173645\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=5.065205199716871e-12, std=1.652319525646817e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-7.992667083733807e-10, std=9.424853431028168e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.0038046782678833e-11, std=3.277675730828378e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-4.400084741007504e-10, std=2.530724145799468e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-5.357528656824151e-13, std=9.35983290872855e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.9609859009127604e-10, std=1.1605585825691378e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.8663834366883236e-11, std=2.0990654547858867e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-8.49047498974187e-11, std=3.027227890584072e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=7.286776737558398e-11, std=5.027296623438815e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.806527981708996e-09, std=6.214041547991656e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.585737928801791e-09, std=3.110653494786675e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-2.9844375859511274e-09, std=2.716580809192237e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.328847590250877e-12, std=8.034111687038603e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.963431804976381e-09, std=8.21569372533304e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-2.2579951797219167e-11, std=2.437847967939888e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-2.8198954282743216e-10, std=1.9366429171441268e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-3.538343229525509e-12, std=4.5548055993549497e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=3.296236172900535e-09, std=4.6229427397292966e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.2721806941229374e-09, std=2.3625089795586973e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.47235920625144e-09, std=2.6368022076894704e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=4.054847124734806e-09, std=4.6936440867284546e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.133600459814261e-09, std=4.537553195405053e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-9.379384380281408e-09, std=2.985058245030814e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=5.397016167307811e-08, std=3.34276683133794e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=7.97624188919599e-11, std=9.254811175196664e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=5.8258553536916224e-08, std=9.601578767615138e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-1.7260253226680788e-09, std=3.5701709748536814e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-2.4967278022813844e-08, std=2.8302160899329465e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-3.128952652531325e-11, std=1.1196525520063005e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-9.558893054872897e-08, std=1.144882958215021e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.9259150718653473e-08, std=8.590248398832045e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=2.1985187004247564e-08, std=7.340230240515666e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=5.367715516513272e-08, std=6.929720711923437e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=4.146627929912938e-08, std=7.3185478868253995e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-2.3634572698938427e-07, std=0.00014092729543335736\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-3.6605106288334355e-06, std=0.00015003394219093025\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=1.7803666318982891e-09, std=4.4448617700254545e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.0234497267447296e-06, std=4.502567389863543e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.7637547955473565e-07, std=0.00023887245333753526\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=2.3901875465526246e-06, std=0.00014364537491928786\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.8201795626282546e-09, std=4.5896285882918164e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.370406721434847e-06, std=4.573438491206616e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.2292586006878992e-06, std=0.00056693353690207\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-3.1631734600523487e-06, std=0.0006239968934096396\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=1.410244294675067e-06, std=0.0004918062477372587\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-9.559480531606823e-07, std=0.0005687985685653985\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.002838787389919162, std=0.012634593062102795\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0005684993229806423, std=0.010471117682754993\n",
            "Grad stats for input_proj.weight: mean=-1.0276866024838682e-09, std=9.06447041870706e-08\n",
            "Grad stats for input_proj.bias: mean=-5.725625307206883e-09, std=3.4135831583625986e-07\n",
            "Grad stats for output_head.0.weight: mean=2.126194885931909e-06, std=0.020226633176207542\n",
            "Grad stats for output_head.0.bias: mean=-0.0029313694685697556, std=0.021189747378230095\n",
            "Grad stats for output_head.2.weight: mean=-0.0014584596501663327, std=0.049094781279563904\n",
            "Grad stats for output_head.2.bias: mean=-0.006135604809969664, std=0.0882239043712616\n",
            "Hungarian matching: row_ind=[16], col_ind=[0]\n",
            "conf_loss: 0.22261682152748108, smooth_l1_loss: 0.00835849717259407, ciou_loss: 0.9125416874885559, box_loss: 0.46045008301734924\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-2.993021455677258e-11, std=1.932161524109688e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-9.422944202697181e-09, std=1.0827602636709344e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=3.3083122352728367e-10, std=4.245122227075626e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-2.284439659661075e-08, std=3.489435812298325e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-1.9355003710863627e-13, std=1.2086339040706662e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.159130652046315e-10, std=1.4734230546764593e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-8.767742643023269e-10, std=2.2937298638225911e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-2.427765544155136e-09, std=3.3800293408603466e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.9917615051999746e-09, std=6.31592058653041e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-4.440994061383208e-08, std=7.897419322944188e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.364186795806745e-08, std=3.402978109079413e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.999410415010061e-09, std=3.14545809487754e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.3974273127548287e-10, std=9.227145483237109e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=6.567318422412427e-08, std=9.601615147403209e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.0868533850683093e-10, std=2.633342091939994e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=5.410996095633891e-10, std=2.170392463085591e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-9.900613662239266e-11, std=4.913916882287594e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=8.737694656701933e-08, std=4.96046993703203e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.0737061240106982e-10, std=1.4090558124735253e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.4667556058611808e-10, std=1.6096239505714038e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=5.2463377642197884e-08, std=4.764261120726587e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.3199280601838836e-07, std=4.86443423142191e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=5.274046088743489e-08, std=1.741276355460286e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=9.969318170988117e-07, std=2.033253258559853e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.8958938852751146e-10, std=6.251535978663014e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=5.507810669769242e-07, std=6.494382887467509e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=3.268783910215234e-09, std=1.9761453586397693e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=2.7570536076382268e-08, std=1.5957564755808562e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-7.281775182832462e-11, std=5.3004523579147644e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=3.010886189258599e-07, std=5.443314421427203e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-7.466068296935191e-08, std=1.808043452911079e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-8.462239975415287e-08, std=1.5554771380266175e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-2.7735495677916333e-08, std=4.382611587061547e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.0476513757093926e-07, std=4.010609336546622e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-4.069932401762344e-06, std=0.0002750642306637019\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.104597595258383e-05, std=0.0003165392845403403\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-8.575028687118902e-09, std=8.900176180759445e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=3.0273506581579568e-06, std=9.198294719681144e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-5.698005978160836e-08, std=0.0003953691048081964\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=6.050486263120547e-07, std=0.00024629628751426935\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.5874981329488946e-09, std=8.632608660263941e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=2.692931957426481e-06, std=8.451096073258668e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=8.959434012467682e-07, std=0.0008300552144646645\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=2.316948666702956e-06, std=0.0009271574672311544\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-7.752016244921833e-06, std=0.0009067870560102165\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.3359756849240512e-05, std=0.0009891308145597577\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0011604485334828496, std=0.013871212489902973\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0011398887727409601, std=0.014205954037606716\n",
            "Grad stats for input_proj.weight: mean=-1.6538116653919133e-08, std=9.44420378345967e-07\n",
            "Grad stats for input_proj.bias: mean=-9.981476267739708e-08, std=3.7106235595274484e-06\n",
            "Grad stats for output_head.0.weight: mean=5.182055247132666e-07, std=0.025968704372644424\n",
            "Grad stats for output_head.0.bias: mean=-0.0003990807163063437, std=0.02824021875858307\n",
            "Grad stats for output_head.2.weight: mean=0.003422862384468317, std=0.06089072301983833\n",
            "Grad stats for output_head.2.bias: mean=0.01484011486172676, std=0.11178531497716904\n",
            "No targets: conf_loss=0.12388481944799423, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.011222008906465e-11, std=8.984326171912471e-09\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.3000107657035187e-09, std=4.096487771221291e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=5.13323758499773e-12, std=2.605152538137645e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.3426768585844684e-09, std=1.3100350315653486e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=5.051612340239986e-14, std=8.696514619543905e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=2.8890959069549638e-11, std=9.070894257945383e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.7863825002573108e-11, std=1.8288822900558444e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-2.6428415011992e-11, std=1.978147778913808e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=8.745149049360634e-11, std=4.721686863717878e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.612838472832891e-09, std=4.6266745101775086e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-2.1339534583830755e-09, std=2.5805243808463274e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-6.770999760874474e-09, std=2.2908123753495602e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.1980361147578833e-11, std=7.558366377224957e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=5.0335060564066225e-09, std=7.431599158280733e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=4.785719043276515e-10, std=2.0799750188871258e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.4920086822154417e-09, std=1.6350328735370567e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-6.092154558601237e-12, std=3.959995353852719e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=7.4505437375194106e-09, std=3.931063830009407e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-5.12396070018184e-10, std=1.2366999158075487e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.057446241681248e-09, std=1.376230613914231e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.359829747751064e-09, std=3.6292539107307675e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.702043530206538e-09, std=3.525620400068874e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-4.18334877849702e-09, std=1.7045385902747512e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=1.0181879339654643e-08, std=1.59466571858502e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.17890887224781e-11, std=4.487576745759725e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.021968891265715e-08, std=4.572146679038269e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=2.8407548535724914e-10, std=1.3753474377153907e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=5.0689266117842635e-09, std=1.2655175396503182e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=3.5736968939659164e-12, std=4.0696221503822017e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.85857906842557e-08, std=4.1205800016541616e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.5581965434895437e-09, std=1.5683035599067807e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-3.0785578530867497e-09, std=1.2830500963900704e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.0649539916585127e-08, std=3.0770352168474346e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-4.7547416670568055e-08, std=2.8261347324587405e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-7.192669500000193e-07, std=3.047280915779993e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-5.171167458684067e-07, std=2.6199470084975474e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-9.233396269792138e-10, std=8.506675840180833e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=3.707553162257682e-07, std=8.374419849133119e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=3.514097102197411e-08, std=3.7483470805455e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-5.492138370755129e-07, std=2.5369592549395747e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.5560353006094374e-10, std=7.945913239382207e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=3.0012077445462637e-07, std=7.687833203817718e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=2.00025124286185e-06, std=8.853829785948619e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=5.3985704653314315e-06, std=9.78669777396135e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.276026523555629e-06, std=0.00010924797970801592\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=7.056282811390702e-07, std=9.211674478137866e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0016718665137887, std=0.004082337021827698\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.445687202154659e-05, std=0.002248047851026058\n",
            "Grad stats for input_proj.weight: mean=-5.33095678711959e-10, std=5.104446998416279e-08\n",
            "Grad stats for input_proj.bias: mean=-2.9568956172454364e-09, std=1.6012799619602447e-07\n",
            "Grad stats for output_head.0.weight: mean=2.1653140720445663e-06, std=0.002978402888402343\n",
            "Grad stats for output_head.0.bias: mean=-0.0014338437467813492, std=0.0027542850002646446\n",
            "Grad stats for output_head.2.weight: mean=0.000272090983344242, std=0.0015656830510124564\n",
            "Grad stats for output_head.2.bias: mean=0.0011484244605526328, std=0.002623537788167596\n",
            "Hungarian matching: row_ind=[11 17 18], col_ind=[1 0 2]\n",
            "conf_loss: 0.3849009871482849, smooth_l1_loss: 0.008529589511454105, ciou_loss: 0.9361830353736877, box_loss: 0.47235631942749023\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=4.565947619994404e-11, std=1.532507951651496e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-2.0172899795056765e-08, std=9.180666893371381e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-7.907378918314834e-11, std=2.302176511648213e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=5.970164806967659e-09, std=2.317753114766674e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=3.1488353591235807e-13, std=6.433479171619183e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=8.27867330244203e-10, std=8.746239643642184e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.4885721261469484e-10, std=1.204684139111123e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=6.886944348138968e-10, std=2.1529437788103678e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.7109558214656317e-10, std=3.3808464650064707e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.5598833275353172e-08, std=4.807133677786624e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.4880620230760542e-08, std=1.6702001630619634e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=2.540438970299874e-09, std=1.6006694067982608e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=5.960343330002615e-11, std=4.7647617407164944e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.4633536927231034e-08, std=4.983091344001878e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=3.9736661183731314e-10, std=1.3444285968944314e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=6.022355503176868e-09, std=1.1262388852628646e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-6.592271173389008e-11, std=2.505749137071689e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=4.822714316787824e-08, std=2.52183269822126e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-5.782871070891815e-09, std=7.508824637625366e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.1755441953198442e-08, std=8.478148174617672e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.4079795934994763e-08, std=2.339028242204222e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=5.6117478663963993e-08, std=2.432886958558811e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-4.098126282769954e-08, std=1.0109291906701401e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=3.910936356987804e-07, std=1.0825055142049678e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.5681560217029045e-10, std=3.334734401505557e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=2.3866570586505986e-07, std=3.508654572215164e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-4.532598740780713e-09, std=9.969490747607779e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-5.197625441155651e-08, std=8.208530744013842e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-4.3154813056389685e-11, std=2.700247705433867e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.2076392863491492e-07, std=2.7808521281258436e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=3.0239924342367885e-08, std=9.394561857334338e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=3.461175879237999e-08, std=8.051485565374605e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.3646996421812219e-08, std=2.1496576664503664e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.1071402872839826e-07, std=2.042220330622513e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.963641125257709e-06, std=0.00016150338342413306\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=5.174983925826382e-07, std=0.00016253335343208164\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=5.0927511097143e-09, std=4.9388461775379255e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-2.581797843959066e-06, std=5.127944677951746e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=9.09520707637057e-08, std=0.00022873093257658184\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.5087507563293912e-06, std=0.0001428366085747257\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-9.96650317830472e-10, std=4.636790617951192e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.250739956049074e-08, std=4.593204357661307e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=2.4584387574577704e-06, std=0.0005046296864748001\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=6.179151569085661e-06, std=0.0005728674586862326\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.915936420322396e-06, std=0.0004889940028078854\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.3702345313504338e-05, std=0.0005613136454485357\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0015486429911106825, std=0.009018661454319954\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0006146971136331558, std=0.008605560287833214\n",
            "Grad stats for input_proj.weight: mean=-1.1761713381019945e-08, std=7.422795533784665e-07\n",
            "Grad stats for input_proj.bias: mean=-7.408382884932507e-08, std=3.3232897749257972e-06\n",
            "Grad stats for output_head.0.weight: mean=1.013337168842554e-06, std=0.015604987740516663\n",
            "Grad stats for output_head.0.bias: mean=-0.0009004342718981206, std=0.01738215610384941\n",
            "Grad stats for output_head.2.weight: mean=6.689785550406668e-06, std=0.04376336187124252\n",
            "Grad stats for output_head.2.bias: mean=3.0215382139431313e-05, std=0.08237173408269882\n",
            "Hungarian matching: row_ind=[ 0  1  2 12 16], col_ind=[0 3 4 1 2]\n",
            "conf_loss: 0.5745630860328674, smooth_l1_loss: 0.042071156203746796, ciou_loss: 1.2110435962677002, box_loss: 0.6265573501586914\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.3379443386529744e-11, std=5.724032092757625e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=5.391622703854182e-09, std=3.079562134189473e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-2.5995061658790064e-10, std=7.556047876278171e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.909868707627993e-08, std=7.242016977215826e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-5.111614256869679e-13, std=1.9885812108100254e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-3.5592376268489545e-10, std=2.5607205245137266e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.0152666901630525e-10, std=3.572447937472134e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.9103696402567039e-10, std=7.193671791583256e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.9469648115943983e-10, std=1.1655854592618198e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=8.772090609454608e-09, std=1.5886898552253115e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-1.0458812482738722e-08, std=4.882519419879827e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-2.66858002362369e-09, std=4.578013204081799e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-1.9811319251772375e-11, std=1.3556447697737894e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-9.145213475392211e-09, std=1.4123794755960262e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.9539657392098064e-10, std=3.78830520730844e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=2.507826390996115e-09, std=3.1612239581590984e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=1.6134538149970012e-11, std=7.160773662917563e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-1.5048133406025954e-08, std=7.1765171583138e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-3.4463715214982926e-10, std=2.413268305190286e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-7.164315807273169e-10, std=2.7253560119788744e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-6.136573915682675e-09, std=6.774491794203641e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-1.9468366474484355e-08, std=6.980919806665042e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=1.131226667894225e-09, std=3.187987886121846e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-1.463833569914641e-07, std=3.4995989608432865e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-6.560500059871188e-11, std=1.075334807865147e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-8.52307593390833e-08, std=1.1180914043507073e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=8.29761120924033e-11, std=3.353236024850048e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.8273205171226437e-09, std=2.747251073742518e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=3.232969447708456e-12, std=1.0026958534581354e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-8.14409801819238e-08, std=1.0259950613544788e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=2.4420703681471423e-08, std=4.02404339183704e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=2.773784046894434e-08, std=3.432792937019258e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=1.6300845118166762e-08, std=7.541719696746441e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=4.5708119955634174e-08, std=6.864222541480558e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=9.13572080207814e-07, std=6.402272993000224e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.214427695435006e-06, std=7.01530443620868e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=1.3133079346250298e-10, std=1.8900622308137827e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-4.562321009871084e-08, std=1.9317703845445067e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=3.426608330414638e-08, std=9.564619540469721e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-2.210867933172267e-07, std=6.016779661877081e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=5.427454041750934e-10, std=2.0354435037006624e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-8.149676773427927e-07, std=2.0229486835887656e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.519629933000033e-08, std=0.00021901568106841296\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-1.164862624136731e-07, std=0.0002462908159941435\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=1.8392761376162525e-06, std=0.00023389745911117643\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.5902160157565959e-06, std=0.0002354816533625126\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.000197435641894117, std=0.003486160421743989\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0004393527051433921, std=0.003799429861828685\n",
            "Grad stats for input_proj.weight: mean=3.6177689732852514e-09, std=3.190389463725296e-07\n",
            "Grad stats for input_proj.bias: mean=2.0775129172534434e-08, std=1.1442041341069853e-06\n",
            "Grad stats for output_head.0.weight: mean=-6.610644049942493e-07, std=0.007319651078432798\n",
            "Grad stats for output_head.0.bias: mean=0.0005127760814502835, std=0.007944962941110134\n",
            "Grad stats for output_head.2.weight: mean=-0.0013064783997833729, std=0.016392821446061134\n",
            "Grad stats for output_head.2.bias: mean=-0.00566626014187932, std=0.029709938913583755\n",
            "No targets: conf_loss=0.131135493516922, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-3.540707007101962e-12, std=3.9256359940509356e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.7765736659569598e-09, std=2.2131341381737002e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-7.45291606207843e-11, std=7.027755799526858e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.305172503407448e-08, std=7.409407771774568e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-3.608745247074552e-14, std=1.562899498708248e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=5.494724675259022e-10, std=1.8969450010786204e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-9.762642083632755e-11, std=2.272589227914068e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-6.659965912092503e-10, std=5.946752068552996e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.6017409620872058e-10, std=1.1618236328558851e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-6.40119868222655e-09, std=1.3594043934972433e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=8.44687697565405e-09, std=2.0304931069858867e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-2.452212211068172e-09, std=2.0829592983773182e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=7.995645812108876e-12, std=6.175647371264859e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.3207439020799256e-09, std=6.665022311835855e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.4030810367715585e-11, std=1.582416899736927e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.1898178542988376e-10, std=1.4468153608504508e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-6.920325423820373e-12, std=3.043077967390673e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=5.648957746018368e-09, std=3.127726699858613e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-3.0927996275131875e-10, std=1.0017581075771886e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-7.068718943514796e-10, std=1.1652218034896578e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.7578010985962464e-09, std=2.7980621553069795e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=6.830274568159211e-09, std=2.9250313104967063e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.414591110915353e-09, std=1.3883976635042927e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.4695220091075498e-08, std=1.4178561968947179e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.0469551401114394e-11, std=4.1689577301440295e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.083265636722899e-08, std=4.3366097202124365e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-4.3864481491517893e-10, std=1.3096114344079979e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-5.331291852428421e-09, std=1.0915530310739996e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-2.971761725589772e-12, std=3.6646400758399977e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.2746575350774947e-08, std=3.7454401535796933e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.1078246764384403e-08, std=1.449940668862837e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.2770832391595377e-08, std=1.233048010362836e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.549072395500843e-09, std=2.9177881515352055e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.653039470918884e-08, std=2.661847247509286e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=5.5323766900983173e-08, std=2.7238491384196095e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.1169574893065146e-07, std=2.5036983060999773e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.8367944932282683e-10, std=8.069475370575674e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.4552267063882027e-07, std=8.312503268825822e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.112152763800168e-08, std=3.804584048339166e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=3.106617896264652e-07, std=2.3505406716139987e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-7.007621150023624e-10, std=7.601897777931299e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=9.028550493894727e-07, std=7.456156254193047e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-2.012970554687854e-07, std=8.96803685463965e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-5.295946721162181e-07, std=0.00010026795644080266\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-9.397413123224396e-07, std=0.0001053066152962856\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.4645269175161957e-06, std=9.362107084598392e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017149418126791716, std=0.003966687712818384\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.74249352212064e-05, std=0.0023852332960814238\n",
            "Grad stats for input_proj.weight: mean=-5.627655008666466e-10, std=2.2390619847101334e-07\n",
            "Grad stats for input_proj.bias: mean=-3.621190458602541e-09, std=8.048153290474147e-07\n",
            "Grad stats for output_head.0.weight: mean=1.5863079170230776e-06, std=0.003025137120857835\n",
            "Grad stats for output_head.0.bias: mean=-0.0015231729485094547, std=0.0029232786037027836\n",
            "Grad stats for output_head.2.weight: mean=0.000276161270448938, std=0.0015981030883267522\n",
            "Grad stats for output_head.2.bias: mean=0.001211289200000465, std=0.0027501664590090513\n",
            "Batch 140, Loss: 0.131135493516922\n",
            "Hungarian matching: row_ind=[ 1 17], col_ind=[0 1]\n",
            "conf_loss: 0.2839675843715668, smooth_l1_loss: 0.0011933145578950644, ciou_loss: 0.3660832643508911, box_loss: 0.1836382895708084\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-1.6073994349094511e-12, std=5.849006612379526e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-4.1131822392515005e-09, std=2.9253763500491914e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.92540122734286e-10, std=1.26729531757519e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-8.216852975806432e-09, std=8.297482736452366e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-2.13129644141552e-13, std=3.578171359208682e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.7508969274437902e-10, std=4.221913130209032e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-7.137112012500779e-10, std=7.245213851092558e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.7651020645104154e-09, std=9.979765991374734e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=6.560483267747941e-10, std=1.9158424890974857e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.2706586005606368e-08, std=2.2819479283953115e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.5723957125810557e-09, std=1.0231966598439612e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-9.122775423975327e-09, std=9.624330914448365e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=3.742267606909877e-11, std=2.8913478899994516e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.5050225954382768e-08, std=2.958468883207388e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.3646612728734908e-09, std=8.532241508873994e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.4961770489207993e-08, std=6.880810587972519e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-2.1760371282653068e-11, std=1.6384215939524438e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=2.4668748821454756e-08, std=1.6586132289830857e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=2.145325694868916e-09, std=6.693083491882135e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=4.357390892550939e-09, std=7.577444307571568e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.4392135483376478e-08, std=1.4265115169109777e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.077167599561335e-08, std=1.4802365058130817e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-7.861160611355444e-10, std=8.951024938141927e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=7.312910099699366e-08, std=9.214575584337581e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.0555526591682352e-10, std=2.577553232185892e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=1.583406827876388e-07, std=2.6620739390637027e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.511745573168355e-08, std=9.6547310022288e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.931701660851104e-07, std=7.786181413393933e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-9.617462382038866e-11, std=3.020405983988894e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=2.020052534135175e-07, std=3.069644208153477e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.3051527503193938e-07, std=1.9144605175824836e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.5071464076754637e-07, std=1.6269976185867563e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.2801558568753535e-07, std=2.107901127601508e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-6.279112767515471e-07, std=1.9827348296530545e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.85514158551814e-06, std=0.0003055344568565488\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.9935758902865928e-06, std=0.0003275186172686517\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=2.794574127662486e-09, std=9.151276026386768e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-4.3726404896915483e-07, std=9.262264939025044e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-4.0464175299348426e-07, std=0.0005193916731514037\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=5.491821866598912e-06, std=0.0003182998625561595\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-4.378506446300889e-09, std=0.00010628892050590366\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=3.904918230546173e-06, std=0.00010345535702072084\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.3953014786238782e-05, std=0.0011869852896779776\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-3.8588259485550225e-05, std=0.0013224371941760182\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-9.613468137104064e-06, std=0.0011811793083325028\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-5.005170896765776e-05, std=0.0012595071457326412\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0022264725994318724, std=0.016032453626394272\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.000928653113078326, std=0.02117389813065529\n",
            "Grad stats for input_proj.weight: mean=-6.67768551565473e-09, std=3.2644487646393827e-07\n",
            "Grad stats for input_proj.bias: mean=-3.4674087601160863e-08, std=1.0898289701799513e-06\n",
            "Grad stats for output_head.0.weight: mean=1.5039695426821709e-06, std=0.037413738667964935\n",
            "Grad stats for output_head.0.bias: mean=-0.002108383923768997, std=0.039810631424188614\n",
            "Grad stats for output_head.2.weight: mean=-0.003437876934185624, std=0.09909322112798691\n",
            "Grad stats for output_head.2.bias: mean=-0.01469921600073576, std=0.18132272362709045\n",
            "Hungarian matching: row_ind=[10], col_ind=[0]\n",
            "conf_loss: 0.21181142330169678, smooth_l1_loss: 0.006756539456546307, ciou_loss: 0.799252986907959, box_loss: 0.4030047655105591\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-3.905749682009407e-11, std=1.260674054037736e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=8.26401169717883e-09, std=6.690816007903777e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-1.4935358505496765e-10, std=2.0711050296995381e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.2724541420539026e-08, std=2.202221594416187e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-7.859962680711874e-13, std=3.878103527199528e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=5.01894803495162e-10, std=4.9576211580415475e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=6.035918431734899e-10, std=6.63916992493796e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=4.066261549695582e-09, std=1.78084917479282e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.0715002218830705e-09, std=3.24111908867053e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.5328501135059014e-08, std=3.9872080037639535e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.3747265487372715e-08, std=6.464516104642826e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.3492609696186264e-08, std=6.95335074851755e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=3.2381153314275934e-11, std=1.9221791092149942e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.5402813247078484e-08, std=2.1281020678998175e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.962061346727495e-10, std=4.996654183742066e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=5.342756459469911e-09, std=4.991592277292511e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-9.424572233740491e-12, std=8.998015488259625e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=1.1117807119376266e-08, std=9.561757252640746e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.525852333372768e-09, std=2.9600388984363235e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=4.256449859241229e-09, std=4.022944892767555e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.1110454778417989e-08, std=8.389617960347096e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=3.1123050803216756e-08, std=9.773287956704735e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-2.4861599001724244e-08, std=3.365145630596089e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.050149916499322e-08, std=4.5382184907794e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=8.189234707023374e-11, std=1.0488187172086327e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=1.6504066024936037e-07, std=1.3074164826321066e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.7370127558535842e-09, std=3.5202192520955577e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=9.915982701613757e-09, std=3.7188858641457045e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=4.194894431819307e-12, std=1.0188790611209697e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.4784416357827013e-08, std=1.0527492122491822e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-4.827145794195076e-09, std=6.381260391208343e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=8.233907777821514e-09, std=6.658244728896534e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=3.666649206479633e-08, std=7.534523319918662e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-2.3651435299143486e-07, std=9.082551514438819e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-9.219452294928487e-07, std=0.000122191893751733\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-3.7290424188540783e-06, std=0.000123105215607211\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-5.900138599912452e-09, std=3.184454908478074e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=3.506467692204751e-06, std=3.3064392482629046e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.3570002010965254e-08, std=0.00016212105401791632\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.9810572666756343e-06, std=0.00011298531899228692\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.969726686785634e-10, std=3.241349259042181e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.514780194611376e-07, std=3.216416371287778e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-6.901907454448519e-07, std=0.0003546790103428066\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-1.7309193935943767e-06, std=0.00040176667971536517\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=1.7188408492074814e-06, std=0.00038578108069486916\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.890135172288865e-05, std=0.0003789007314480841\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.00025999435456469655, std=0.005374992731958628\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0003585517406463623, std=0.0060479771345853806\n",
            "Grad stats for input_proj.weight: mean=1.3739925863731628e-09, std=7.25213908481237e-07\n",
            "Grad stats for input_proj.bias: mean=6.808441810335353e-09, std=2.382074399065459e-06\n",
            "Grad stats for output_head.0.weight: mean=-1.2314740160945803e-07, std=0.011756565421819687\n",
            "Grad stats for output_head.0.bias: mean=0.0001541951933177188, std=0.012791913002729416\n",
            "Grad stats for output_head.2.weight: mean=0.0015971792163327336, std=0.028617750853300095\n",
            "Grad stats for output_head.2.bias: mean=0.006874370388686657, std=0.052240971475839615\n",
            "Hungarian matching: row_ind=[12 16], col_ind=[1 0]\n",
            "conf_loss: 0.31194716691970825, smooth_l1_loss: 0.006505169905722141, ciou_loss: 0.9973383545875549, box_loss: 0.5019217729568481\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-6.307517008696806e-12, std=5.6489298572159896e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.7779328009837059e-09, std=3.191041741956724e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=4.689050189798927e-11, std=7.132974388923685e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-8.035335952172318e-09, std=6.837841510787257e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-2.390019605835736e-13, std=1.845365460440007e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.4171602780166381e-10, std=2.4596360503892356e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.0679067352636906e-10, std=3.75196549384782e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.78118630955737e-10, std=7.14997341333401e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-2.8537672225326105e-10, std=1.0266288796856315e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-9.758420738137374e-09, std=1.4706289164223563e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.3050545533133118e-08, std=5.216490421844355e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-2.207787730412747e-09, std=4.7661043822699867e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=2.4127736267254285e-11, std=1.4332844955333712e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.0090256630235217e-08, std=1.4923314495263185e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.93208013424362e-10, std=4.1657838778519363e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.9229495207848686e-09, std=3.4882492627730244e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.3658907338509607e-11, std=7.80423121682361e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=1.5130444452893244e-08, std=7.883276254005978e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=5.023647053903346e-10, std=3.6024547966917453e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.0441207898281846e-09, std=4.0762677144812187e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=5.859792651108364e-09, std=7.723936050751945e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.517790515492834e-08, std=7.432418556163611e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.3372414287005085e-10, std=5.002559191780165e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=1.2722165365630644e-07, std=5.069606231700163e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=7.859505407603606e-11, std=1.412634560438164e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=1.1237736430302903e-07, std=1.4648270507677807e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=4.4898444961916084e-09, std=5.172687906451756e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=5.038676675894749e-08, std=4.274612820154289e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.7880918967705384e-11, std=1.4954631524233264e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-7.234000776179528e-08, std=1.5428597635036567e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.1588053894229233e-07, std=1.0979390935972333e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.3284109456890292e-07, std=9.367453458253294e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-2.9271433277244796e-08, std=1.145640908362111e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=8.461108080837221e-08, std=1.0662338354450185e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.069544618483633e-08, std=0.00021333769836928695\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=3.4324687021580758e-06, std=0.0001919576752698049\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=1.2836570695284877e-09, std=6.455790571635589e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-7.249662417052605e-07, std=6.609064439544454e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.669352454631735e-07, std=0.00033701438223943114\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=2.091613623633748e-06, std=0.0002076314704027027\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-4.146045284869615e-09, std=7.280329737113789e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=4.678865934693022e-06, std=7.233492215164006e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=5.2586246965802275e-06, std=0.0009065424674190581\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.4100080079515465e-05, std=0.0010211162734776735\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-8.63882087287493e-06, std=0.0008637472055852413\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=3.5534912967705168e-06, std=0.0008294792496599257\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.006615909282118082, std=0.018043911084532738\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.00041801398037932813, std=0.016750745475292206\n",
            "Grad stats for input_proj.weight: mean=-3.742585352739525e-09, std=3.279091913555021e-07\n",
            "Grad stats for input_proj.bias: mean=-2.122395059700466e-08, std=1.2597568002092885e-06\n",
            "Grad stats for output_head.0.weight: mean=3.975015715695918e-06, std=0.028978968039155006\n",
            "Grad stats for output_head.0.bias: mean=-0.004770602099597454, std=0.03111187182366848\n",
            "Grad stats for output_head.2.weight: mean=-0.0031357172410935163, std=0.06683790683746338\n",
            "Grad stats for output_head.2.bias: mean=-0.013611232861876488, std=0.1236422210931778\n",
            "Hungarian matching: row_ind=[8], col_ind=[0]\n",
            "conf_loss: 0.2202467918395996, smooth_l1_loss: 0.03872116282582283, ciou_loss: 1.0734996795654297, box_loss: 0.5561104416847229\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=6.5854821595934254e-12, std=9.11053774643733e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=2.0474125506098062e-08, std=5.304112278281536e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=2.2714509440024955e-10, std=7.869894602663408e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-2.8043261934840302e-08, std=9.385105386172654e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=9.723923055648953e-13, std=1.616398392911833e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.3028750018028177e-09, std=1.963978668584332e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=4.182656998530376e-11, std=2.6378463857668066e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=1.858859732806195e-10, std=8.274233920246843e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=3.1641078646060805e-10, std=1.7608316227324394e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-9.484391050307295e-10, std=1.677120735621429e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-2.9808213675153183e-09, std=1.928309387722038e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.3140272748255484e-09, std=2.299968713259659e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-4.178694282958029e-12, std=5.900455946061811e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-2.376966845574202e-09, std=6.483787728939205e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=3.13740596002976e-11, std=1.9738853040962567e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.430069840324677e-09, std=1.764643400292698e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-4.705097422785798e-12, std=3.7603573588285144e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=6.372206762250698e-09, std=3.953928739974799e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.384543590887688e-09, std=2.1025297769483586e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.6706512556984308e-09, std=2.479685008438537e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-3.954404803607758e-09, std=3.2014736461860593e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=6.4611502814670985e-09, std=3.589798325265292e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-3.860812114453438e-09, std=2.7485803002491593e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=1.0061853572551627e-09, std=3.0527060062013334e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.084027312359126e-11, std=8.308338124152215e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.1976198699414908e-08, std=8.642809348202718e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-1.349721723276076e-10, std=3.2245168313238537e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=6.522355988636264e-10, std=2.6309307941119187e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-3.4638958368304884e-12, std=1.1492685416669701e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=9.013464108420521e-08, std=1.1799247658927925e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.1968768198755697e-08, std=5.693214916391298e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.3836455536875292e-08, std=4.864894435741007e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-3.923220504020719e-08, std=7.178219220804749e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.0430042013686034e-07, std=6.708394721499644e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.7017100617522374e-08, std=0.00010734177340054885\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.478855665482115e-06, std=9.957060683518648e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-7.585564953949131e-10, std=2.711385786824394e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=5.021555580242421e-07, std=2.797161323542241e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-5.929212676392126e-10, std=0.00015566330694127828\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=7.281732905539684e-08, std=9.682138625066727e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=2.1890578238981107e-10, std=3.498101432342082e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-3.2558145335315203e-07, std=3.451807060628198e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.242467760675936e-06, std=0.0004169839958194643\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-3.407825715839863e-06, std=0.00046801636926829815\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.4436631065327674e-06, std=0.00036881229607388377\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=6.226728146430105e-06, std=0.00038601254345849156\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.001857639872469008, std=0.006663986016064882\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0002942636492662132, std=0.0072090052999556065\n",
            "Grad stats for input_proj.weight: mean=7.697672721462823e-09, std=4.836173843614233e-07\n",
            "Grad stats for input_proj.bias: mean=4.590403079873795e-08, std=2.054907781712245e-06\n",
            "Grad stats for output_head.0.weight: mean=1.6022058844100684e-06, std=0.012545768171548843\n",
            "Grad stats for output_head.0.bias: mean=-0.0014820881187915802, std=0.013649682514369488\n",
            "Grad stats for output_head.2.weight: mean=-0.00017468855367042124, std=0.028979875147342682\n",
            "Grad stats for output_head.2.bias: mean=-0.0007639005780220032, std=0.053623300045728683\n",
            "Hungarian matching: row_ind=[1], col_ind=[0]\n",
            "conf_loss: 0.21202489733695984, smooth_l1_loss: 0.0033484220039099455, ciou_loss: 0.5975604057312012, box_loss: 0.30045440793037415\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.3567803998359995e-11, std=1.7343747771292328e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-2.1665453875385765e-09, std=8.539091567172363e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=5.526280821843699e-11, std=5.753564025212654e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-2.043571756260576e-09, std=2.7068705321653397e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-6.503339533558972e-13, std=1.7698594589887762e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.579730318252871e-10, std=1.8797107870227592e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.1793243465119119e-11, std=4.3741042787814877e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=4.3915815428619e-11, std=4.506979323082305e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=8.060246914354252e-10, std=1.0148823292865927e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-6.075789649173657e-09, std=9.671472156469463e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.982211728090988e-09, std=5.810105676573585e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=3.3360931794845783e-09, std=5.761532975157024e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=2.7387517601007438e-11, std=1.7793306028579536e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.044590636212206e-08, std=1.829061488933803e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-4.650954066320878e-10, std=5.391716513258871e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-4.812847009816323e-09, std=4.141193699069845e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.7333356971960256e-11, std=1.1083713502557657e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=2.4058111947056204e-08, std=1.1010322964466468e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-7.262507040195487e-09, std=5.304889896251552e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.4515650903490496e-08, std=5.930688757871394e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=7.59902007985147e-09, std=9.214068086293992e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=2.925554909438688e-08, std=9.708224979476654e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-7.134261181818147e-09, std=7.00127930031158e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.1863243659936415e-07, std=7.269186880876077e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=6.492406612323975e-11, std=2.1406333416962298e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=1.3539526833028503e-07, std=2.2196197733137524e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-3.379811097659058e-09, std=8.328501280630007e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-3.97685084863042e-08, std=6.475227110058768e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-6.073475056211919e-11, std=2.479337808836135e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.4982930451878929e-07, std=2.5257588731619762e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-4.892912670584337e-07, std=1.973110920516774e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-5.587057216871472e-07, std=1.6585760022280738e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-5.845211603627831e-08, std=1.6628675439278595e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.7403922331359354e-07, std=1.63025706569897e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.948857743627741e-06, std=0.0003226100525353104\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.4199412362358999e-05, std=0.00034486965159885585\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-7.565499338113568e-09, std=9.307420259574428e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=4.226150394970318e-06, std=9.316806244896725e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=9.566674634697847e-07, std=0.0005311354761943221\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-9.63413458521245e-06, std=0.00034424461773596704\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=2.2593074078258724e-09, std=0.00010048293188447133\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-2.0408940599736525e-06, std=9.856108226813376e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-5.3341968850872945e-06, std=0.0012644864618778229\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-1.4412889868253842e-05, std=0.001407421426847577\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.68564690486528e-06, std=0.0010410193353891373\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.8795863070408814e-05, std=0.001311402185820043\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0004166536091361195, std=0.019241251051425934\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0013439868343994021, std=0.02203352004289627\n",
            "Grad stats for input_proj.weight: mean=-1.0096715685747881e-09, std=7.91881049622134e-08\n",
            "Grad stats for input_proj.bias: mean=-5.115849521786231e-09, std=2.7548321668291464e-07\n",
            "Grad stats for output_head.0.weight: mean=-1.9721373973879963e-06, std=0.04347839206457138\n",
            "Grad stats for output_head.0.bias: mean=0.001379175460897386, std=0.04643328860402107\n",
            "Grad stats for output_head.2.weight: mean=0.000657598371617496, std=0.09367416799068451\n",
            "Grad stats for output_head.2.bias: mean=0.0028704332653433084, std=0.17504139244556427\n",
            "Hungarian matching: row_ind=[ 7 10], col_ind=[0 1]\n",
            "conf_loss: 0.29046159982681274, smooth_l1_loss: 0.015053699724376202, ciou_loss: 1.0221524238586426, box_loss: 0.5186030864715576\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=9.147391177855013e-12, std=3.039005491700664e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=4.96091923096742e-09, std=1.6073177278030926e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-1.1479239087064386e-10, std=5.961217652838968e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=8.90228690764161e-09, std=4.868703626925708e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-3.5701823442035874e-13, std=1.8545319946383643e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.9753537694455758e-10, std=2.26701502015203e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.534448262896504e-10, std=3.500656831079141e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-3.999067743620799e-10, std=5.101739475321665e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.2412104677395064e-10, std=9.598159778079207e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=6.519478290556435e-09, std=1.1411169964503642e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-2.0624106866762304e-09, std=4.958935733156977e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-4.945466258732267e-10, std=4.69157555471611e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-2.0903667685701066e-11, std=1.400333502488138e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-8.730421718894377e-09, std=1.45593077149897e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=8.729451606015459e-10, std=3.896991529472871e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=8.695531406033297e-09, std=3.294279622423346e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=1.1362327745345624e-11, std=7.308829452767895e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-1.1114842379811307e-08, std=7.385540357063292e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.910716112580758e-09, std=2.397566731815459e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-5.870249175643494e-09, std=2.716444100769877e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-7.067246343694933e-09, std=6.861370707156311e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-2.0792040089645525e-08, std=7.133679673643201e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-4.442931356152258e-09, std=3.044872983082314e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-3.053740016412121e-08, std=3.4433753626217367e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-5.2907678238511835e-11, std=1.0868599247260136e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-5.9195084389784824e-08, std=1.1382417142158374e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-5.172310357792753e-10, std=3.062914402107708e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-6.530491702960717e-09, std=2.553759259171784e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=6.171833877299804e-13, std=7.527238494731137e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-3.834552675385794e-10, std=7.769408512103837e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.6442620598411395e-09, std=3.585496415325906e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.6801777746877633e-09, std=3.095442025369266e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.566586149692739e-08, std=6.89299713485525e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=1.1842796254768473e-07, std=6.2332424022315536e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=9.270468126487685e-08, std=7.526353874709457e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.0987969289999455e-06, std=6.311899778665975e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.0603217737734667e-09, std=1.8242766600451432e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.654645075177541e-06, std=1.8480375729268417e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-9.078056706357529e-08, std=0.00010442220809636638\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.2033451639581472e-06, std=6.496371497632936e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.7547296948805524e-10, std=2.1216896129772067e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=2.40280797925152e-07, std=2.1012796423747204e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.1067211289628176e-06, std=0.0002658111625351012\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=2.8827626010752283e-06, std=0.0002978474658448249\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.5467239791178145e-06, std=0.0003014844551216811\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-6.3553607105859555e-06, std=0.00025953655131161213\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0004827778902836144, std=0.005087373312562704\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.00047717796405777335, std=0.004534097388386726\n",
            "Grad stats for input_proj.weight: mean=3.1699107783111913e-09, std=1.5213937842872838e-07\n",
            "Grad stats for input_proj.bias: mean=1.7724556045095596e-08, std=5.615900136035634e-07\n",
            "Grad stats for output_head.0.weight: mean=-1.370972313452512e-06, std=0.008502798154950142\n",
            "Grad stats for output_head.0.bias: mean=0.0011503545101732016, std=0.00921644363552332\n",
            "Grad stats for output_head.2.weight: mean=0.0005497123929671943, std=0.022090276703238487\n",
            "Grad stats for output_head.2.bias: mean=0.0024032953660935163, std=0.04086998105049133\n",
            "No targets: conf_loss=0.12678909301757812, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=2.193188989793593e-12, std=1.305696351039387e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-8.769758252924476e-10, std=7.456198147792747e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=6.893050366607589e-12, std=2.3558310857652032e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-4.828957234082054e-10, std=1.9560465602808108e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-4.0052640024046404e-13, std=6.942682873045669e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.2133889165942833e-10, std=8.84384920851744e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=9.619897239909747e-11, std=1.3496246786814936e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.2254231790697077e-10, std=2.059971215828682e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=5.994515994700578e-11, std=3.637625312080672e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.411763011522794e-09, std=4.674219411526792e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.4846320556548562e-09, std=1.9270264317583496e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.8268413448652154e-09, std=1.8048442029794387e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=8.526447776990853e-12, std=5.387763479802743e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.6446705653503386e-09, std=5.5700148493542656e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=5.825526866454211e-11, std=1.5557210986116843e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=5.947883296997247e-10, std=1.2690954065419646e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-6.445094458129574e-12, std=2.968545764758801e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=5.410207393197197e-09, std=2.9978746596270867e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=9.073999329700655e-10, std=9.577560433626786e-08\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.821197193052626e-09, std=1.0768359715029874e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.8451250244643234e-09, std=2.8214890335220844e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.045684118940244e-09, std=2.8376632599247387e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-3.289098771119825e-09, std=1.292935962737829e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.2268105581702002e-08, std=1.3573795740740024e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.4361105147030493e-11, std=3.962877315188962e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.094040662039333e-08, std=4.143674630086025e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.0446212783676856e-09, std=1.2537914244603598e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.1666138277632854e-08, std=1.0501108818061766e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-2.8248514638562483e-12, std=3.513460740123264e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.5986680423907274e-08, std=3.6135830328021257e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=5.1652158106207935e-09, std=1.3655678685609018e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=6.1662701611453485e-09, std=1.1669338846331812e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-7.702205095938552e-09, std=2.750081648628111e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-4.197976011255378e-08, std=2.52206223194662e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-2.3110186475605587e-07, std=2.7502628654474393e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.5487916016354575e-07, std=2.3165197490016e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-2.302235485585058e-10, std=7.426061529258732e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.312788384666419e-07, std=7.591114353999728e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=4.9541881708137225e-09, std=3.5548131563700736e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.7560893184054294e-07, std=2.1894627934671007e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-9.126006617066196e-10, std=7.215262030513259e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=6.644109475928417e-07, std=7.060070402076235e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=3.339553984460508e-07, std=8.60125437611714e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=8.789288585830946e-07, std=9.456415136810392e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.0746393854788039e-06, std=9.719855734147131e-05\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.368879338770057e-06, std=8.601576701039448e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0016917113680392504, std=0.004112882073968649\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.561664147535339e-05, std=0.002308920258656144\n",
            "Grad stats for input_proj.weight: mean=-1.4905675582710387e-09, std=7.487080466717089e-08\n",
            "Grad stats for input_proj.bias: mean=-8.170644605343114e-09, std=2.7267367386230035e-07\n",
            "Grad stats for output_head.0.weight: mean=1.343007170362398e-06, std=0.002972775138914585\n",
            "Grad stats for output_head.0.bias: mean=-0.0014732354320585728, std=0.0028277134988456964\n",
            "Grad stats for output_head.2.weight: mean=0.0002733842993620783, std=0.0015687377890571952\n",
            "Grad stats for output_head.2.bias: mean=0.0011738631874322891, std=0.0026712585240602493\n",
            "No targets: conf_loss=0.1266191452741623, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.4382350562239243e-12, std=1.1132322619289425e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=4.563083522146627e-10, std=6.115480033486165e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=4.166577499686852e-11, std=2.6404002539948124e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.7632346693829959e-09, std=2.0513772369668004e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-3.281302096355687e-13, std=8.200293777349543e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.7479170888456963e-10, std=9.250462618126676e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.1256851006891111e-10, std=1.574177410645916e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.733945292376916e-10, std=2.142268584748308e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=3.046648489046788e-10, std=4.3939962779404595e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.8132738361108522e-09, std=4.888510218847841e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=6.002629504564538e-10, std=2.3168095708570036e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.8354739950154908e-10, std=2.1115404535976268e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.80658176191751e-12, std=6.16651547602487e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=4.2599972438495115e-09, std=6.393358376044489e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-2.7319275314185987e-11, std=1.770164317349554e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-2.5007973469826084e-10, std=1.452222306852491e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-7.887093755876151e-12, std=3.2835526297958495e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=6.8050098889216315e-09, std=3.28624061296523e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=5.853558748825094e-10, std=1.0158171193097587e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.1665430843521563e-09, std=1.1591693294121796e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.078058696814878e-09, std=3.263598387093225e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=6.488643400359706e-09, std=3.278911435700138e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-2.63739252659434e-10, std=1.399855136696715e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=3.517426705457183e-08, std=1.4751199159945827e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.8398172702281954e-11, std=4.4002013055433054e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.04980049495407e-08, std=4.576646688292385e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=9.986362847769215e-10, std=1.3864262200513622e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.2193484444367186e-08, std=1.1281939578111633e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-1.6015522241730196e-12, std=3.8610173191955255e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=2.0325931160414257e-08, std=3.9634932136323187e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-7.798178769391484e-10, std=1.439231255062623e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-8.321521249854413e-10, std=1.228286691912217e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.879631087031157e-09, std=3.061097913814592e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.9049300681881505e-08, std=2.774335825961316e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.351848363308818e-07, std=2.8379596187733114e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.3582452140781243e-07, std=2.497280547686387e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-2.947958821497565e-10, std=7.808083864802029e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.509315410430645e-07, std=7.93274102761643e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=6.954627540523006e-09, std=3.615250898292288e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-9.575762760505313e-08, std=2.288756331836339e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-8.936460460517992e-10, std=7.214542165456805e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=7.296077342289209e-07, std=7.1375075094692875e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-2.7384021450416185e-07, std=8.598323620390147e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-7.11402435626951e-07, std=9.614911687094718e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.141302277574141e-06, std=0.00010559886140981689\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.2945340586156817e-06, std=8.88780050445348e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0016889702528715134, std=0.00397515669465065\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.676774890162051e-05, std=0.002304410794749856\n",
            "Grad stats for input_proj.weight: mean=-2.596626802464641e-10, std=6.473573677112654e-08\n",
            "Grad stats for input_proj.bias: mean=-1.5604548764258652e-09, std=2.2852375991533336e-07\n",
            "Grad stats for output_head.0.weight: mean=1.3579083315562457e-06, std=0.0029778892640024424\n",
            "Grad stats for output_head.0.bias: mean=-0.0014700389001518488, std=0.0028220866806805134\n",
            "Grad stats for output_head.2.weight: mean=0.000273265439318493, std=0.0015740747330710292\n",
            "Grad stats for output_head.2.bias: mean=0.0011722225463017821, std=0.0026708415243774652\n",
            "Hungarian matching: row_ind=[ 0  3  7  8 16], col_ind=[3 4 1 2 0]\n",
            "conf_loss: 0.5743523836135864, smooth_l1_loss: 0.02950519323348999, ciou_loss: 1.0775693655014038, box_loss: 0.5535372495651245\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-8.047744692873948e-10, std=2.273785781881088e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=5.899144994714334e-08, std=1.2128689377277624e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=4.6337103598581564e-10, std=2.8854250899712497e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-5.762793264807442e-08, std=2.3870084078225773e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-1.9746218549165917e-12, std=7.464166174031561e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.3554989353181668e-09, std=8.702154019601949e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.7817365078064427e-10, std=1.224576777758557e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-3.6402258984935543e-10, std=1.9424638253440207e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.098554663376717e-09, std=4.0139786960935453e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=2.41669422251789e-08, std=4.959476314070344e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.162897144193266e-08, std=1.6119674910441972e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=1.3876658044864598e-08, std=1.4825531025053351e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-3.5837981887665293e-11, std=4.5173209173299256e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-1.4458912289683212e-08, std=4.390662411424273e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-2.1110739822916003e-09, std=1.2833469327233615e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-2.017750233562765e-08, std=1.135717297984229e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.3518076375239616e-11, std=2.538819785513624e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-3.337651222068416e-08, std=2.547602093727619e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.8694565895316373e-09, std=7.875832466197608e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=3.6467682207330654e-09, std=8.518474032825907e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-2.0648215581786644e-08, std=2.2092342533142073e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-3.3896725426529883e-08, std=2.2522469862451544e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.9280378182884306e-08, std=9.742974725668319e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-4.516311946645146e-07, std=1.1126280696771573e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-2.2601298610425147e-10, std=3.187586798958364e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-2.665351530595217e-07, std=3.2637947242619703e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-6.540757713224821e-09, std=9.134028005064465e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-7.339641427961396e-08, std=8.329936463269405e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=6.072120584121876e-11, std=2.7538872018340044e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-2.407327883702237e-07, std=2.817856966430554e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=3.977517337716563e-08, std=9.110835890169255e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=4.756112303994087e-08, std=7.75482567405561e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=2.619401584524894e-08, std=2.032491465797648e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=5.685670600996673e-08, std=1.973220605577808e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=3.977763299189974e-06, std=0.00014474036288447678\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-4.192694632365601e-06, std=0.0001541896490380168\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=1.4298121575606615e-09, std=4.5172764657763764e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-6.227227800081891e-07, std=4.5153501559980214e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.4398420944417012e-07, std=0.0001986679999390617\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.1457317441454506e-06, std=0.00012234914174769074\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=3.697351758091827e-09, std=4.1345094359712675e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.8743945702226483e-06, std=4.137875293963589e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.0058697625936475e-06, std=0.00040402280865237117\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.7881928872375283e-06, std=0.00044532507308758795\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=3.981130248575937e-06, std=0.0004259929701220244\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.4012612155056559e-06, std=0.00045672812848351896\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0002110578352585435, std=0.006539279595017433\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.00017039463273249567, std=0.0068408953957259655\n",
            "Grad stats for input_proj.weight: mean=1.4092817579580696e-08, std=1.1247736892983085e-06\n",
            "Grad stats for input_proj.bias: mean=9.765933839389618e-08, std=4.657439149013953e-06\n",
            "Grad stats for output_head.0.weight: mean=-9.58629243541509e-07, std=0.01286484394222498\n",
            "Grad stats for output_head.0.bias: mean=0.0011503066634759307, std=0.013581844046711922\n",
            "Grad stats for output_head.2.weight: mean=-0.0012828420149162412, std=0.030400922521948814\n",
            "Grad stats for output_head.2.bias: mean=-0.005531600210815668, std=0.05557449907064438\n",
            "Hungarian matching: row_ind=[ 0 16 17], col_ind=[1 0 2]\n",
            "conf_loss: 0.38731649518013, smooth_l1_loss: 0.016455164179205894, ciou_loss: 0.8609705567359924, box_loss: 0.43871286511421204\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-9.035551862268676e-09, std=1.9993183741462417e-05\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=2.8264896627661074e-06, std=0.00010378595470683649\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-8.52131532003142e-10, std=1.420368607796263e-05\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-4.797229848918505e-07, std=0.00015105468628462404\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=5.6452842400744885e-11, std=1.7649380197326536e-06\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-4.884767790258593e-08, std=1.971597157535143e-06\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=5.587091678194156e-09, std=2.1191410723986337e-06\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=6.043293865332089e-08, std=5.951987532171188e-06\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.7450646200577467e-08, std=2.400833909632638e-05\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-4.1144335227727424e-07, std=2.6721423637354746e-05\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-8.712364660823368e-07, std=1.5163958778430242e-05\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-2.8441087351893657e-07, std=1.4956593986426014e-05\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-1.5700567235210627e-10, std=4.192252163193189e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.419027052586898e-07, std=4.178282779321307e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.024494622470229e-08, std=1.2999138562008739e-05\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=7.685337521934343e-08, std=1.1723769603122491e-05\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.1340839378704004e-10, std=2.4910884803830413e-06\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=1.744259066072118e-07, std=2.55047666541941e-06\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=2.9266786771842135e-09, std=4.601993168762419e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.112368863687152e-08, std=6.393301646312466e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.9378660454094643e-08, std=1.8724464098340832e-05\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=2.042936102952808e-06, std=2.1149884560145438e-05\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-2.653657134032983e-07, std=4.625556175597012e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=3.707054929691367e-07, std=5.1568520575528964e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.4819363514106954e-09, std=1.59216233441839e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=9.949527566277538e-07, std=1.6038929970818572e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=4.9812860503095635e-09, std=5.731558849220164e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-1.19267383524857e-07, std=4.283023008611053e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-1.5864642932683637e-11, std=1.2734083611576352e-05\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-3.403647497179918e-07, std=1.264330330741359e-05\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-3.0927395755497855e-07, std=4.002038622274995e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-8.494535563841055e-07, std=4.7882404032861814e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-8.08081040304387e-07, std=9.772592602530494e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=7.130454832804389e-06, std=0.00011177936539752409\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=8.959334081737325e-06, std=0.00047396490117534995\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.3065324310446158e-05, std=0.0005341109354048967\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.2370431335415617e-10, std=0.00015763485862407833\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.8862934868811863e-06, std=0.00015690094733145088\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-7.750557529107027e-09, std=0.00045182977919466794\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=3.19937589665642e-06, std=0.000370879250112921\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=9.003429113363381e-10, std=9.990263788495213e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-4.978119250154123e-06, std=9.628463158151135e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.0568664947641082e-06, std=0.0008582681766711175\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=3.0571900424547493e-06, std=0.0010623512789607048\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=1.6384841728722677e-05, std=0.0011877083452418447\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.9155766494804993e-05, std=0.0010500499047338963\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.004964067600667477, std=0.011303243227303028\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.000971752218902111, std=0.015463047660887241\n",
            "Grad stats for input_proj.weight: mean=1.1775240409406251e-06, std=0.00013072653382550925\n",
            "Grad stats for input_proj.bias: mean=7.523775821027812e-06, std=0.0004570009477902204\n",
            "Grad stats for output_head.0.weight: mean=-2.2310850908979774e-06, std=0.027666479349136353\n",
            "Grad stats for output_head.0.bias: mean=0.0017785350792109966, std=0.029307901859283447\n",
            "Grad stats for output_head.2.weight: mean=0.001934329280629754, std=0.06455326080322266\n",
            "Grad stats for output_head.2.bias: mean=0.008497404865920544, std=0.1188616082072258\n",
            "Batch 150, Loss: 0.826029360294342\n",
            "No targets: conf_loss=0.12837031483650208, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=3.2073066424942454e-11, std=2.28346515029898e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-4.454550062149565e-09, std=1.2638446378332446e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=4.6360939393030876e-11, std=3.382028523901681e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-5.083148124640502e-09, std=3.49318440839852e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=5.540672087800402e-13, std=8.876388513101574e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=2.438698132323225e-10, std=1.1338491034962317e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-4.903565054004133e-11, std=1.624007062162036e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-2.1127966043366087e-10, std=3.335118847758167e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-2.2821122769300928e-10, std=5.084071119654254e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.204543963519768e-09, std=7.282411473852335e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.100572160657066e-09, std=2.024521847943106e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.5730332592056584e-09, std=1.9419164232203912e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=7.53843255180131e-12, std=5.657706836359466e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.4739711107789617e-09, std=5.8967255966990706e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.3956437394657684e-10, std=1.5445725409790612e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.9194184019966087e-09, std=1.3803715148696938e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-5.7238380701818414e-12, std=3.009519389252091e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=5.560078619737396e-09, std=3.0664292438586926e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.8205563445672368e-10, std=9.957697955087497e-08\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-4.099215411557111e-10, std=1.1373114006119067e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.630455853136482e-09, std=2.838307580077526e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=5.2608619682814606e-09, std=2.844245443611726e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-9.03228070114892e-09, std=1.3674311958311591e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=4.4494036899322964e-08, std=1.4335697642309242e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.444511342820533e-11, std=4.15476421267158e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.107041817746904e-08, std=4.3070298261227435e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-1.6920471967996065e-10, std=1.265344849343819e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-1.5111978335369258e-09, std=1.0638635785653605e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-1.630834356447508e-12, std=3.5859986269315414e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.7825170672836066e-08, std=3.694228780659614e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.2269163462974575e-08, std=1.3662341871167882e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.4256762881359464e-08, std=1.169360530184349e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-7.219163933314121e-09, std=2.8534443572425516e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-4.5801357373420615e-08, std=2.629648406582419e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.1754620977153536e-07, std=2.6769208488985896e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-4.200694547762396e-08, std=2.4611252229078673e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-5.453720253179029e-10, std=7.825099601177499e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.135527665814152e-07, std=8.001900823728647e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=3.392612057950828e-08, std=3.738003215403296e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-4.2844590097956825e-07, std=2.3567537937196903e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-8.643148419196223e-10, std=7.704671588726342e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=7.808112627571973e-07, std=7.545863809355069e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=6.633079010498477e-07, std=8.805237303022295e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.7288127764913952e-06, std=9.903943282552063e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.090037358153495e-06, std=0.00010661153646651655\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.5708244518464198e-06, std=9.118659363593906e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0016995779005810618, std=0.003962891176342964\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.737940955441445e-05, std=0.002339945873245597\n",
            "Grad stats for input_proj.weight: mean=-6.682275843772345e-10, std=1.0461333488365199e-07\n",
            "Grad stats for input_proj.bias: mean=-4.416281562669155e-09, std=4.2631924657143827e-07\n",
            "Grad stats for output_head.0.weight: mean=1.93142841453664e-06, std=0.002990190638229251\n",
            "Grad stats for output_head.0.bias: mean=-0.0014920320827513933, std=0.002863999456167221\n",
            "Grad stats for output_head.2.weight: mean=0.0002742665237747133, std=0.0015838483814150095\n",
            "Grad stats for output_head.2.bias: mean=0.0011874544434249401, std=0.0027009109035134315\n",
            "No targets: conf_loss=0.1274583488702774, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-3.7730929491885945e-12, std=2.6751719062190205e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-2.175373658985791e-09, std=1.5411404774567927e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.928063264600155e-11, std=3.532101189307468e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-2.0620278817773396e-09, std=3.775587060772523e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.5310504560283054e-13, std=9.03249031125597e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=6.34361035922737e-11, std=1.2442392005596048e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=5.503723778804703e-12, std=1.658003689897214e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-5.0670578843892145e-12, std=3.552008465135259e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-6.223377368996807e-11, std=5.317837192819752e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.7173364386688945e-09, std=7.754172770546575e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=4.271932141364232e-09, std=2.2226538476388669e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-6.759641735243349e-10, std=2.0639895126350893e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=8.364729915666391e-12, std=6.022203535849258e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=4.191352598326148e-09, std=6.314525080597377e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.6187159945779683e-10, std=1.6902002641927538e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.7581661682086747e-09, std=1.4345283716465929e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-6.3876404166052225e-12, std=3.224621636377378e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=6.071206648528005e-09, std=3.253521185797581e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-7.853787759026787e-11, std=1.0398718330861811e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.5682077858514276e-10, std=1.177632427129538e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.1565825509005663e-09, std=3.1285705404116015e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=5.942476288822718e-09, std=3.123979297470214e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=1.017702899730466e-08, std=1.4336883396026678e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.728747006131016e-08, std=1.485583311477967e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.530316754734141e-11, std=4.3342541289348446e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.338400572123646e-08, std=4.5316579644349986e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-1.3015140076788612e-09, std=1.3573337582784006e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-1.7447947087134708e-08, std=1.123119545809459e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-2.134736831749251e-12, std=3.8067855712142773e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=2.2165135504792488e-08, std=3.907074699327495e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=8.786267713389861e-09, std=1.4202432794263586e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.009006922458866e-08, std=1.2192081157991197e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-5.144705994553078e-09, std=3.0531784886989044e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-4.5005538851228266e-08, std=2.77288609140669e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-2.932224560936447e-07, std=2.8916789233335294e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=6.643966798947076e-08, std=2.497941932233516e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.2600264154858394e-10, std=7.927482329250779e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.9517968041782296e-07, std=8.138203156704549e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-3.6387683977068264e-09, std=3.645703327492811e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.0402649763818772e-07, std=2.3100055841496214e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.8176927457934653e-10, std=7.419559096888406e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=6.953687829991395e-07, std=7.267369255714584e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.2002910807495937e-06, std=8.540915587218478e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-3.1770912300999044e-06, std=9.611284622224048e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.1134736723761307e-06, std=0.00010203899728367105\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.494946673119557e-06, std=8.955848898040131e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0016953428275883198, std=0.004107483197003603\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.7412129535805434e-05, std=0.002325193490833044\n",
            "Grad stats for input_proj.weight: mean=-1.7661584417183462e-09, std=1.3545725607855275e-07\n",
            "Grad stats for input_proj.bias: mean=-1.090172929707478e-08, std=5.526238169295539e-07\n",
            "Grad stats for output_head.0.weight: mean=1.0398653103038669e-06, std=0.002990393666550517\n",
            "Grad stats for output_head.0.bias: mean=-0.001483157742768526, std=0.00284551247023046\n",
            "Grad stats for output_head.2.weight: mean=0.0002730615669861436, std=0.001569977030158043\n",
            "Grad stats for output_head.2.bias: mean=0.0011796947801485658, std=0.002682801801711321\n",
            "Hungarian matching: row_ind=[11 16 19], col_ind=[2 1 0]\n",
            "conf_loss: 0.4100192189216614, smooth_l1_loss: 0.006855672691017389, ciou_loss: 0.7456360459327698, box_loss: 0.3762458562850952\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=3.2360097674405397e-12, std=1.1788548803792764e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=3.9119003175658307e-11, std=5.848768935834414e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-1.268866123282919e-10, std=2.9663519640621416e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=6.269104790845859e-09, std=1.6905627830965386e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-1.5833254846109313e-14, std=9.700360514841577e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=1.5865433966588682e-11, std=1.0380253101516246e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.2524453135996936e-10, std=2.490725670156735e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=4.568677658411957e-10, std=2.7223302723200504e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.1716536902083305e-10, std=5.106594258563746e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.0398108474827268e-09, std=5.3285670986724654e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.771770286040919e-09, std=3.473972469691944e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.950265892171956e-09, std=3.2920328862928727e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.780213965082662e-12, std=9.837873449214385e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=4.4816279576309626e-09, std=1.0017937768225238e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-9.215302826381944e-11, std=3.237655903376435e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.1208467487477947e-09, std=2.53508062542096e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-7.857187123150311e-12, std=6.077853953456724e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=9.195052719235264e-09, std=6.114871808904354e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-7.051651484957233e-10, std=3.208178611657786e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.4232401923663929e-09, std=3.615722334870952e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=4.637353612224615e-09, std=5.981913773212e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=2.599714887807636e-09, std=5.701119221157569e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=3.4546872029750375e-09, std=4.2063511500600725e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=5.154189963718636e-08, std=4.260247351339785e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=5.672344191576251e-11, std=1.1759642575270846e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.8050427636781023e-08, std=1.2222858458699193e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=3.994877317836654e-09, std=4.588213869283209e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=3.6331584851723164e-08, std=3.888883384206565e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.834465912509131e-11, std=1.2783513057001983e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-8.848105892411695e-08, std=1.2990630011699977e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.86786657252469e-08, std=1.0676908459572587e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.7620251924199692e-08, std=9.087428225029726e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=2.8496501158770116e-08, std=9.971056897484232e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.0064992039815479e-07, std=9.293441507907119e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-5.733595571655314e-07, std=0.0001975192135432735\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=7.080029718053993e-08, std=0.00018535673734731972\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=1.0864992239234539e-09, std=5.5741849791957065e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-9.189248544316797e-07, std=5.8144018112216145e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=8.176463950348989e-08, std=0.0002918583631981164\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-3.706566076289164e-07, std=0.00018651840218808502\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-4.290505728477001e-10, std=6.157234747661278e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=2.6653847271518316e-06, std=6.068531365599483e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.5204821011138847e-06, std=0.0007574685732834041\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-4.321465894463472e-06, std=0.0008399423095397651\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-5.470107225846732e-06, std=0.0007388822268694639\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.3097636838210747e-05, std=0.0006981635233387351\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0057134805247187614, std=0.013546689413487911\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0016984870890155435, std=0.013701168820261955\n",
            "Grad stats for input_proj.weight: mean=-8.480360302876022e-10, std=5.399972380359941e-08\n",
            "Grad stats for input_proj.bias: mean=-4.673179176961639e-09, std=1.927345465446706e-07\n",
            "Grad stats for output_head.0.weight: mean=3.9746955735608935e-06, std=0.026797378435730934\n",
            "Grad stats for output_head.0.bias: mean=-0.003238607896491885, std=0.028469733893871307\n",
            "Grad stats for output_head.2.weight: mean=-0.001778509933501482, std=0.0601167194545269\n",
            "Grad stats for output_head.2.bias: mean=-0.007722413167357445, std=0.10994026809930801\n",
            "No targets: conf_loss=0.12703688442707062, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=4.342678994184723e-12, std=1.2900389201320195e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-2.0258470456724353e-09, std=6.909684913125602e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.2888808076372271e-11, std=2.447455749177152e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.4545400439658351e-09, std=1.9815803398159915e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-3.1304472902782265e-13, std=7.46917638849709e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-3.3128957910300016e-11, std=9.205492368380419e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.7778183092342914e-10, std=1.5508790696117103e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=4.768261896437309e-10, std=2.135921661761131e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.0156409047112902e-10, std=3.909762824605423e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.6411544062909798e-09, std=4.6439396328423754e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.5791812302268227e-09, std=2.2313201952783857e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-5.843654449222413e-10, std=2.1081909551412537e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.022366187494413e-12, std=6.308265199095331e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=4.241125672876933e-09, std=6.537190699873463e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=9.15539449808378e-11, std=1.7687030151591898e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=9.343453788446254e-10, std=1.454115334809103e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-7.907202670409674e-12, std=3.308720053496472e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=6.380563188912447e-09, std=3.331908260406635e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.076086775242402e-09, std=1.0411316253566838e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.1997765831116567e-09, std=1.1833486723844544e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.69926481166749e-09, std=3.1641974373997073e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.143528518189669e-09, std=3.2178553510675556e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=3.4941471938054747e-09, std=1.3578745665654424e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=3.018194405512986e-08, std=1.4761699276277795e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.053616734471909e-11, std=4.24181280322955e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=3.9626147696480984e-08, std=4.4388525566319004e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-1.8041294014281561e-09, std=1.3390905451160506e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-1.882459699231731e-08, std=1.131658336817054e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=4.11537470768053e-12, std=3.68076399581696e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.969442742222327e-08, std=3.7902981375737e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.412114958299071e-08, std=1.4167468407322303e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.6238697497783505e-08, std=1.2073375046384172e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.53584208976099e-09, std=3.048051439691335e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-6.847824352007592e-08, std=2.6677366804506164e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.962046548622311e-07, std=2.5906450900947675e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.5955997412220313e-07, std=2.431725079077296e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.303212425809221e-10, std=7.90236208558781e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.790802883760989e-07, std=8.152625923685264e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.6792562834998535e-08, std=3.766455120057799e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=2.3917067437650985e-07, std=2.2865151549922302e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-8.21454904098573e-10, std=7.715445462963544e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=7.883373314143682e-07, std=7.476358405256178e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-5.294523361953907e-07, std=8.615708065917715e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-1.3867804682377027e-06, std=9.744946873979643e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.0785979611682706e-06, std=0.00010891823330894113\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.5966090813890332e-06, std=9.069275256479159e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0016929570119827986, std=0.003947731573134661\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.751939897891134e-05, std=0.0023187361657619476\n",
            "Grad stats for input_proj.weight: mean=-1.618280731641164e-09, std=6.355337234253966e-08\n",
            "Grad stats for input_proj.bias: mean=-8.927393935209693e-09, std=2.3684971495185891e-07\n",
            "Grad stats for output_head.0.weight: mean=1.455504389014095e-06, std=0.0029633543454110622\n",
            "Grad stats for output_head.0.bias: mean=-0.0014783436199650168, std=0.0028368367347866297\n",
            "Grad stats for output_head.2.weight: mean=0.0002726398524828255, std=0.001574421883560717\n",
            "Grad stats for output_head.2.bias: mean=0.0011759925400838256, std=0.002676076255738735\n",
            "Hungarian matching: row_ind=[7], col_ind=[0]\n",
            "conf_loss: 0.20196719467639923, smooth_l1_loss: 0.004447408486157656, ciou_loss: 0.7342475652694702, box_loss: 0.369347482919693\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-2.1157797736037764e-12, std=3.603157239240318e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-4.757829685786419e-09, std=2.1174808750856755e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-3.035708143195315e-11, std=6.210679259766039e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.7830714682531834e-09, std=6.365178819578432e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=6.137312880127865e-13, std=1.452002340585068e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=1.6536996771954193e-10, std=1.8590982975297266e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-1.3304757295884428e-10, std=2.7983071859694064e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-5.411453507520037e-10, std=5.4815249228568064e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.997710968344336e-10, std=8.246735205830191e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-5.8102136435422835e-09, std=1.2015267714104994e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=7.429068915598691e-09, std=3.8595246110162407e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=4.319495872096013e-10, std=3.7123962215446227e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.1697864898962962e-11, std=1.0267810779396314e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=5.445199846576543e-09, std=1.0702402875040207e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=4.819663002031405e-10, std=3.139693944831379e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=5.406890046799617e-09, std=2.5851818463706877e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.0345918566301293e-11, std=5.976096417725785e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=8.763981540482746e-09, std=6.057369716927496e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-5.27731025545819e-10, std=2.655752382452192e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.057545606641952e-09, std=3.011456044532679e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=6.312411926501227e-09, std=5.591624017142749e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=2.1910071978936685e-08, std=5.773304678768909e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=1.902564505940063e-08, std=3.48092544300016e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=2.2154363676918365e-08, std=3.818882305495208e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=5.627527957519085e-11, std=9.943350960384123e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=5.9538539431969184e-08, std=1.0297516155333142e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-1.2524697945437424e-09, std=4.043773515149951e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-1.3304827461979585e-08, std=3.457982302279561e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-8.046341370970822e-14, std=1.259592409041943e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-1.2611923949634729e-08, std=1.2874392041339888e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=4.406749098961882e-08, std=8.758745025261305e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=5.105457034915162e-08, std=7.478914540115511e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=9.121677635448577e-09, std=8.58710063766921e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=3.9626684156246483e-07, std=8.233520929934457e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=1.3536100595956668e-07, std=0.00016558339120820165\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-3.5787129490927327e-06, std=0.00015303523105103523\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-1.0330166722027911e-09, std=3.911460589733906e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=7.385001481452491e-07, std=3.995529914391227e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.7643371563735855e-07, std=0.00022971902217250317\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=2.9305815587576944e-06, std=0.00014445435954257846\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=1.4944383508463943e-09, std=4.5420969399856403e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.6470027048853808e-06, std=4.5072240027366206e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-3.111867101779353e-07, std=0.0005530668422579765\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-9.333525667898357e-07, std=0.000619826780166477\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=2.8400281735230237e-06, std=0.0005794136668555439\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.6828860680107027e-05, std=0.0005762818618677557\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0016693698707967997, std=0.007817594334483147\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0006646965048275888, std=0.0098326550796628\n",
            "Grad stats for input_proj.weight: mean=-2.1180599496517516e-09, std=1.6322452722761227e-07\n",
            "Grad stats for input_proj.bias: mean=-1.366351831677548e-08, std=6.819341251684818e-07\n",
            "Grad stats for output_head.0.weight: mean=-1.2262662494322285e-06, std=0.017765436321496964\n",
            "Grad stats for output_head.0.bias: mean=0.0014054208295419812, std=0.018850188702344894\n",
            "Grad stats for output_head.2.weight: mean=0.0036305859684944153, std=0.049361806362867355\n",
            "Grad stats for output_head.2.bias: mean=0.015403145924210548, std=0.08849882334470749\n",
            "Hungarian matching: row_ind=[ 0  1  2  7 10 16], col_ind=[4 5 1 0 2 3]\n",
            "conf_loss: 0.6427478194236755, smooth_l1_loss: 0.03479747846722603, ciou_loss: 1.102586269378662, box_loss: 0.5686918497085571\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-3.7053529688968467e-10, std=1.8444242186888005e-06\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.799873103891514e-07, std=1.0072825716633815e-05\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-8.640443915908236e-10, std=1.3280056236908422e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.8635029164215666e-07, std=1.4872760402795393e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=1.7936152563180485e-11, std=1.65221209158517e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=1.2189515175009547e-08, std=1.9649158389256627e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.0406276951258064e-09, std=1.799211304387427e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=4.666051101054336e-09, std=5.744927307205216e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-7.280352321004102e-09, std=2.6514981072978117e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=7.807721402741663e-08, std=2.785501465041307e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-1.0449335263729154e-07, std=9.040701343110413e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=3.230723422120718e-08, std=1.407328909408534e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-8.824269787099936e-11, std=2.81980220506739e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-3.936024128847748e-08, std=4.3479732880769006e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-3.861175268404793e-12, std=5.291182674227457e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-4.611286463784836e-09, std=1.0098151506099384e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.0757173757601777e-11, std=1.2762440348978998e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-1.699623020101626e-08, std=1.5444111056694965e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=4.0790739674889664e-09, std=3.700005777318438e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.1728912951980419e-08, std=6.017726263962686e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.3750828031788842e-08, std=9.411426162841963e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-9.240238085794772e-08, std=1.7312131603830494e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-8.752884639307013e-08, std=4.074335265613627e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-7.356521791734849e-08, std=6.1263249335752334e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=1.0340468932501512e-11, std=1.2399269735396956e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.5985568779797177e-07, std=1.8342150269745616e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=3.797091974178102e-09, std=3.333786025905283e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=2.547729138768773e-09, std=4.762371645483654e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.3026468792531887e-11, std=1.0990645478159422e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-3.451378205454603e-08, std=1.148763431046973e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-4.3992656628688565e-08, std=4.582794190355344e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-8.789060501612767e-08, std=5.739132575399708e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=2.5077611098822672e-08, std=7.3065480137302075e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-2.1658998150542175e-07, std=1.1471855941636022e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=1.7130253127106698e-07, std=8.07854303275235e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.790090891518048e-06, std=9.856077667791396e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=2.9879032581447973e-09, std=3.081592876696959e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-4.180246833129786e-07, std=3.208359703421593e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.2416923428636437e-08, std=0.00012394499208312482\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=3.859167918562889e-07, std=8.738088217796758e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=5.895550714285491e-10, std=2.7423460778663866e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-6.395616765075829e-07, std=2.7525245968718082e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-9.038714097187039e-07, std=0.0002622109022922814\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.444966412440408e-06, std=0.00030197223532013595\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.2252015696722083e-07, std=0.00029824714874848723\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-8.454550879832823e-06, std=0.000293355988105759\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.00013015240256208926, std=0.003923028241842985\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.00018486198678147048, std=0.004503687843680382\n",
            "Grad stats for input_proj.weight: mean=-5.376117329092267e-08, std=1.1889091183547862e-05\n",
            "Grad stats for input_proj.bias: mean=-3.1429766522705904e-07, std=4.450491542229429e-05\n",
            "Grad stats for output_head.0.weight: mean=-6.841710273874924e-07, std=0.007994509302079678\n",
            "Grad stats for output_head.0.bias: mean=0.0007537897326983511, std=0.008679060265421867\n",
            "Grad stats for output_head.2.weight: mean=-0.0018130994867533445, std=0.01791529729962349\n",
            "Grad stats for output_head.2.bias: mean=-0.007968596182763577, std=0.032249365001916885\n",
            "Hungarian matching: row_ind=[11 16 19], col_ind=[2 1 0]\n",
            "conf_loss: 0.4112352430820465, smooth_l1_loss: 0.006197463721036911, ciou_loss: 0.7190544605255127, box_loss: 0.36262595653533936\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=4.402533025638089e-12, std=1.391032711239859e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-8.973358167629897e-10, std=7.012647529336391e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=5.839744660063317e-11, std=3.463290454419621e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-3.2717322184794284e-09, std=1.9497412040436757e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=1.9407739304533322e-13, std=1.097689938944768e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=1.121763654188257e-10, std=1.1962151269528931e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.2443382262083968e-11, std=2.584754454915128e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-3.4262592762956956e-11, std=2.804839205339249e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.8788592903717927e-10, std=5.877508613139071e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.719179770238611e-09, std=6.029737420476522e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.816879257101391e-09, std=3.789095330830605e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-6.770228822006175e-10, std=3.411510363093839e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=7.860091917610834e-12, std=1.0367018887791346e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=4.194909308807837e-09, std=1.0537073791283547e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=3.7178179979058257e-10, std=3.1065155781107023e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.1865887706317153e-09, std=2.4569558831899485e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.2289891326844327e-11, std=6.141447528307253e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=8.530508743831433e-09, std=6.135451258160174e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-3.307076557046429e-10, std=2.427869105758873e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-6.559917054005382e-10, std=2.716766687171912e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=4.79037609579791e-09, std=5.627966856991407e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=7.284888248193511e-09, std=5.695077334166854e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-6.092157889270311e-09, std=3.1579706956108566e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-1.457359246614942e-07, std=3.3474379961262457e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-2.3604080929412463e-12, std=9.151834206022613e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.7848655886609777e-09, std=9.433013588022732e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-2.6593114377249094e-09, std=3.4138859064114513e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-1.9525018046806508e-08, std=2.827879598044092e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=3.461897435386163e-12, std=9.866178061201936e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-4.382583895790049e-08, std=1.0078159675686038e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.6184315160548977e-08, std=7.978081157489214e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-3.014359606368089e-08, std=6.683207629976096e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=3.34613545760476e-08, std=7.299463504750747e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-4.9292935955236317e-08, std=6.845807547506411e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=3.732975528691895e-08, std=0.0001391805853927508\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-5.864450486114947e-06, std=0.00013507761468645185\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=6.884803838147491e-09, std=4.611407712218352e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-2.9404573069768958e-06, std=4.669156624004245e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=2.665360909759329e-08, std=0.00022225074644666165\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-5.783781489299145e-07, std=0.00013433769345283508\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=1.9722019573009675e-09, std=4.3072577682323754e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.2006673841824522e-06, std=4.316956255934201e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-9.682610198069597e-07, std=0.0005125851603224874\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.5497793103568256e-06, std=0.000578792009036988\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=2.8799140636692755e-06, std=0.0005218822043389082\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.0544971701165196e-05, std=0.0005144388996995986\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0008983216248452663, std=0.008784204721450806\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0015586658846586943, std=0.008473838679492474\n",
            "Grad stats for input_proj.weight: mean=-1.2310091834777381e-09, std=6.271378794053817e-08\n",
            "Grad stats for input_proj.bias: mean=-7.10969771944292e-09, std=2.2120519815871376e-07\n",
            "Grad stats for output_head.0.weight: mean=-1.575167516421061e-07, std=0.01798883080482483\n",
            "Grad stats for output_head.0.bias: mean=0.00016658335516694933, std=0.01938561163842678\n",
            "Grad stats for output_head.2.weight: mean=-0.0005653849802911282, std=0.048769548535346985\n",
            "Grad stats for output_head.2.bias: mean=-0.002488371916115284, std=0.08957410603761673\n",
            "Hungarian matching: row_ind=[ 0  1  2  3  4  6  7  8 10 14 17 19], col_ind=[ 8  1  6  0  9  7  4 10  5 11  2  3]\n",
            "conf_loss: 1.3281761407852173, smooth_l1_loss: 0.04507086053490639, ciou_loss: 1.0791094303131104, box_loss: 0.5620901584625244\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-8.196688328077073e-10, std=8.697578550709295e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.195785870322652e-07, std=4.835177151107928e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.028499063693289e-09, std=9.827144822338596e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-8.748156687943265e-08, std=1.0558371286606416e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-2.123923259489402e-11, std=1.7419652920125372e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=9.172552495329e-09, std=2.0866987426870764e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.1092973761783753e-11, std=2.3756498990223918e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.687379125314692e-10, std=7.33929596208327e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-3.0803022355030407e-09, std=2.021325826717657e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=6.069517155538051e-08, std=1.9070679400101653e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=4.071012682516084e-08, std=1.159574935627461e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=5.999361007980042e-08, std=1.8296706230103155e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-8.389505756767335e-11, std=3.838546263068565e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-3.697059014484694e-08, std=5.862440275450354e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.836342522487655e-09, std=8.449686674794066e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-3.8239500455006237e-10, std=1.3556021940530627e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.424693779090603e-11, std=2.1646381753726018e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-3.889758914965569e-08, std=2.3132410831294692e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=4.106829876171503e-10, std=6.266333798521373e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-7.21253279323264e-10, std=9.327382599622069e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.7513727357254538e-08, std=1.4218866226656246e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-1.1037572278382868e-07, std=2.5573926905053668e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-3.947295112993743e-08, std=7.053603439999279e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-1.608503481520529e-07, std=1.0454315997776575e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.1001836247581664e-10, std=2.352503543079365e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-3.018990639702679e-07, std=3.0515907383232843e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=3.426441352871734e-09, std=6.211046638782136e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-6.564093268934812e-09, std=7.868313332437538e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=3.2609470679290098e-12, std=1.980283514058101e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-2.5042652396223275e-08, std=2.057636265817564e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.4645530061206955e-08, std=7.71286340750521e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=2.8104601312861632e-08, std=9.126065378950443e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=5.159273541721632e-08, std=1.2896964108222164e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.537684823915697e-07, std=1.967085881915409e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=4.682942744693719e-07, std=0.00015481944137718529\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-3.258066499256529e-06, std=0.00016362997121177614\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=7.662777079531224e-10, std=4.837939559365623e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-2.103050292134867e-06, std=5.120033893035725e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-8.743090518237295e-08, std=0.00021428766194730997\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.2232360404595966e-06, std=0.00014624823234044015\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=3.6133798175796983e-09, std=4.218597314320505e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-3.850777829939034e-06, std=4.166684811934829e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=7.645299433534092e-07, std=0.00048123407759703696\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.9258186512161046e-06, std=0.0005444114212878048\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=4.820818503503688e-06, std=0.0004880705091636628\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-5.00135138281621e-06, std=0.0005048105376772583\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.008535027503967285, std=0.02087002992630005\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0003191159339621663, std=0.012056439183652401\n",
            "Grad stats for input_proj.weight: mean=-5.6576080709191956e-08, std=5.793204309156863e-06\n",
            "Grad stats for input_proj.bias: mean=-3.4855131048061594e-07, std=2.162409327866044e-05\n",
            "Grad stats for output_head.0.weight: mean=-7.896567694842815e-06, std=0.01575186289846897\n",
            "Grad stats for output_head.0.bias: mean=0.007604396902024746, std=0.015319489873945713\n",
            "Grad stats for output_head.2.weight: mean=-0.0008587589836679399, std=0.012821371667087078\n",
            "Grad stats for output_head.2.bias: mean=-0.0037129458505660295, std=0.02328014187514782\n",
            "Hungarian matching: row_ind=[15], col_ind=[0]\n",
            "conf_loss: 0.21274790167808533, smooth_l1_loss: 0.002949155867099762, ciou_loss: 0.7039192914962769, box_loss: 0.3534342348575592\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=2.0543081125090623e-12, std=5.8493153431982137e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=3.778034773915806e-09, std=3.4273040228072205e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=3.112625157619675e-10, std=1.1183557546701195e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.8806510126978537e-08, std=1.044399937200069e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.7441243721781916e-13, std=3.051139429999239e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-7.319828077001489e-11, std=3.828885652978897e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.1868050986407752e-10, std=6.770722649207528e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=3.248212809836559e-10, std=1.117252637072852e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-1.1277221378946933e-09, std=1.76990155864587e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=9.157926861291799e-09, std=2.2702178625877423e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-7.08763181478389e-09, std=1.0492396995687159e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=9.798102773572737e-09, std=8.963409072748618e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-1.1940244799835131e-11, std=2.682763238226471e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-8.148371755112294e-09, std=2.746302527611988e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=3.549193994256683e-10, std=8.532167043995287e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=5.806740865921256e-09, std=7.316183996408654e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.4329760428543068e-11, std=1.6477372355439002e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-2.5104110790152845e-08, std=1.664298139303355e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=6.959780751714106e-09, std=1.0439144944029977e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=1.4218755950423656e-08, std=1.1641201353995712e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.1198849847460224e-08, std=1.6104870610433863e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-4.8485837567113776e-08, std=1.5363656302724849e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-3.4091613088094164e-08, std=1.4687101611343678e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=6.303554300757241e-08, std=1.454218818253139e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-9.71347446920845e-11, std=4.984677161701256e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.3857560077212838e-07, std=5.154543487151386e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-2.619162131622943e-08, std=1.6683565263519995e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-2.734869894993608e-07, std=1.3215958460932598e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-8.307043941613301e-11, std=5.013946520193713e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-6.186608061398147e-07, std=5.113420684210723e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.8357376063704578e-07, std=2.846985444193706e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-2.0815900825255085e-07, std=2.41556281252997e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.56275460642064e-08, std=3.738403393072076e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=1.8354819530941313e-07, std=3.3068397897295654e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=5.1890283430111594e-06, std=0.0004390490357764065\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.2834228730062023e-06, std=0.0005156156839802861\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-2.3957700268084636e-09, std=0.0001603316777618602\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.5576470104861073e-06, std=0.0001637112582102418\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.741278990470164e-07, std=0.0007945735123939812\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=4.682715371018276e-06, std=0.000500311201903969\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.132003018573414e-09, std=0.00016796421550679952\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.8412395093037048e-06, std=0.00016459845937788486\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-1.0795379239425529e-05, std=0.0018216542666777968\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.873371704481542e-05, std=0.0020077822264283895\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=6.17638579569757e-06, std=0.0018139048479497433\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-4.312817327445373e-05, std=0.0018776621436700225\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.007095459382981062, std=0.03162279725074768\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0029950765892863274, std=0.032235193997621536\n",
            "Grad stats for input_proj.weight: mean=1.6853253237414378e-09, std=2.8587399469870434e-07\n",
            "Grad stats for input_proj.bias: mean=9.308732451529522e-09, std=1.200529823108809e-06\n",
            "Grad stats for output_head.0.weight: mean=3.7169666029512882e-06, std=0.06172772869467735\n",
            "Grad stats for output_head.0.bias: mean=-0.0076820761896669865, std=0.06578768044710159\n",
            "Grad stats for output_head.2.weight: mean=-0.0087498240172863, std=0.13935239613056183\n",
            "Grad stats for output_head.2.bias: mean=-0.037446994334459305, std=0.2530258297920227\n",
            "No targets: conf_loss=0.1203947439789772, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=3.844338476027831e-12, std=3.2130842431143947e-09\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-6.192404367055815e-10, std=1.5937716923986045e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=3.980558070659779e-12, std=1.3528268283380385e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=3.8884451214471483e-10, std=6.206827407595483e-08\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-3.6788568068615857e-13, std=4.673941678134952e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-8.731341344381249e-11, std=4.832200861670799e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.3888373784354258e-10, std=1.199915011795838e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.4619303817807747e-10, std=1.1494430296465907e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.219824324356523e-10, std=2.7043276062954646e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-1.4487083754843866e-09, std=2.4531379594350256e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.1314559834072497e-09, std=1.73447446627506e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.5507817252569112e-10, std=1.65890043035688e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.465335633340732e-12, std=5.35985940075534e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.5103582263218414e-09, std=5.2402608474722e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.4826673222501086e-10, std=1.4976927786847227e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.0107374937007307e-09, std=1.1973961022704316e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-5.796252366963017e-12, std=2.865853154787601e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=5.727538887612127e-09, std=2.8247297834127494e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.5753260917961143e-09, std=9.672638157098845e-08\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-3.224267297596839e-09, std=1.0863217880796583e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.9620305380385616e-09, std=2.679435340269265e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=4.3886330125531e-09, std=2.5864969188660325e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=1.580530550882031e-08, std=1.321495687989227e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=3.1970941449799284e-08, std=1.288536850552191e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.504600429304894e-11, std=3.890792186211911e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=3.975246087861706e-08, std=3.9383618855026725e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.1645407971272448e-09, std=1.2378135352264508e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=2.8102423499376528e-08, std=1.0123226275027264e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-8.493039604928754e-12, std=3.5264380926491867e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.8352947606103953e-08, std=3.5738977999244526e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.67458935607101e-08, std=1.5278319551725872e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.8896024300829595e-08, std=1.2613890021384577e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-8.876959611825441e-09, std=2.8717358873109333e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-2.3941511884117972e-08, std=2.392552687524585e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.2705696639823145e-07, std=3.103516428382136e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-3.4481323041291034e-07, std=2.5267807359341532e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-7.959760073283917e-10, std=8.589523531554732e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=4.491882634738431e-07, std=8.634848200017586e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-9.301086123514324e-09, std=3.7372134102042764e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=2.3460700049326988e-07, std=2.459339339111466e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.0094712843411457e-09, std=7.053004537738161e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=3.179253269536275e-07, std=6.99035763318534e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=6.326485646468427e-08, std=8.137055556289852e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.9603612599894404e-07, std=9.008387132780626e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-9.829363989410922e-07, std=0.00010703867155825719\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=2.4112935079756426e-06, std=8.678350422997028e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0016560789663344622, std=0.003970704972743988\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.5688025895506144e-05, std=0.0022004966158419847\n",
            "Grad stats for input_proj.weight: mean=-1.3680515054126374e-10, std=2.0960721158758133e-08\n",
            "Grad stats for input_proj.bias: mean=-6.769804716810768e-10, std=6.346149916680588e-08\n",
            "Grad stats for output_head.0.weight: mean=1.1846241250168532e-06, std=0.0029182671569287777\n",
            "Grad stats for output_head.0.bias: mean=-0.0014003526885062456, std=0.002689837943762541\n",
            "Grad stats for output_head.2.weight: mean=0.00026851080474443734, std=0.0015432090731337667\n",
            "Grad stats for output_head.2.bias: mean=0.0011184136383235455, std=0.0025552373845130205\n",
            "Batch 160, Loss: 0.1203947439789772\n",
            "Hungarian matching: row_ind=[ 2  7  8 10 12 18], col_ind=[2 1 0 3 5 4]\n",
            "conf_loss: 0.6408758163452148, smooth_l1_loss: 0.014491523616015911, ciou_loss: 0.9570605754852295, box_loss: 0.48577603697776794\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-4.859539992629891e-10, std=7.551221870016889e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=7.748411690045032e-08, std=4.102798357052961e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-1.275598515704246e-10, std=5.252371124697675e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.9001252837824723e-07, std=6.602218491025269e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=1.1098788554875227e-11, std=1.1621164475172918e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-8.615650415322307e-09, std=1.2634382073883899e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-8.202978227234148e-12, std=1.1588404902340699e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=2.0671198086574805e-10, std=3.2374879310737015e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.9496920461724585e-09, std=1.3746413287663017e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=1.0360203361869935e-08, std=1.4517638646793785e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-8.685216812409635e-08, std=9.351454650641244e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=3.3758851714082994e-08, std=1.0444741747051012e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-1.36315221263561e-11, std=2.0857704896570795e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-2.2491738249641458e-08, std=3.26021904584195e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=8.668362139196972e-10, std=5.349644425223232e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-9.82599424048658e-09, std=6.976356985433085e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=7.550571279324458e-12, std=1.2736335008867172e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-1.2015888728456048e-08, std=1.4017102500929468e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.2785144054561215e-09, std=4.0251481436826e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-3.391951164388729e-09, std=6.298247967606585e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=9.45668432450475e-10, std=1.0469551625647e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-9.318029015048523e-08, std=1.318469571742753e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=2.1687938556169684e-08, std=4.317677394283237e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-1.7790924289329269e-07, std=5.782787411590107e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=5.903973837595444e-11, std=1.305417299590772e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-9.163181857729796e-08, std=1.7358245258947136e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.3974504886604677e-09, std=4.946496119373478e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-8.418375330165873e-09, std=4.824950337933842e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-2.190692072190359e-12, std=9.64368155109696e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-1.0186929522149057e-08, std=9.90926423583005e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.071735589164291e-08, std=7.86010150477523e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=4.916589091408241e-08, std=1.0563244359218515e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=8.625778491477831e-08, std=1.0844009011634625e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.0924624405106442e-07, std=1.1991163773927838e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=2.323705302842427e-06, std=0.00012169098772574216\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-3.1840793326409766e-06, std=0.00012799244723282754\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=3.98689081748671e-10, std=3.3475491363788024e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=4.29645211852403e-07, std=3.468156501185149e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.25679378015775e-08, std=0.0001683672599028796\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=6.235190994630102e-07, std=0.00012892435188405216\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-6.440288302655972e-10, std=3.355841545271687e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-1.4372318446476129e-06, std=3.304295751149766e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.178637376142433e-06, std=0.0003825204912573099\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=3.455451405898202e-06, std=0.0004688591288868338\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=1.453534423490055e-06, std=0.0003500462044030428\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=4.296185579732992e-06, std=0.00041162563138641417\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.003319587791338563, std=0.010535864159464836\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0009800064144656062, std=0.0075065093114972115\n",
            "Grad stats for input_proj.weight: mean=5.73202001419304e-08, std=5.39403981747455e-06\n",
            "Grad stats for input_proj.bias: mean=3.4797324133251095e-07, std=1.798870653146878e-05\n",
            "Grad stats for output_head.0.weight: mean=-2.0450970623642206e-06, std=0.01385533344000578\n",
            "Grad stats for output_head.0.bias: mean=0.0028343333397060633, std=0.01453928928822279\n",
            "Grad stats for output_head.2.weight: mean=0.0005247991066426039, std=0.030928589403629303\n",
            "Grad stats for output_head.2.bias: mean=0.0022483535576611757, std=0.05624324828386307\n",
            "Hungarian matching: row_ind=[7], col_ind=[0]\n",
            "conf_loss: 0.20274952054023743, smooth_l1_loss: 0.0018570823594927788, ciou_loss: 0.675870418548584, box_loss: 0.3388637602329254\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=3.7675578802576215e-12, std=1.1328491922313333e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=1.540179095371741e-10, std=5.845745221222387e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-7.220209152780654e-11, std=1.9090313330138997e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=4.058542835139178e-09, std=1.4682051130421314e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=1.3112709702778336e-13, std=5.0659028083543944e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=6.861582829698065e-11, std=5.836487737553853e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-9.302784237386064e-12, std=1.8590531780660058e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.506422764308013e-11, std=2.720540059897303e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=5.6170401663280245e-11, std=3.1671877565031537e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=1.4445518115024925e-09, std=3.6496146549325204e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-5.251603596434506e-10, std=2.3460687259557744e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=5.73363134748206e-09, std=2.3814931182641885e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-9.090912918285898e-12, std=7.173790095293953e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-3.6008274140186813e-09, std=7.368015531028504e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.153856177271706e-10, std=2.606317082154419e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.256331927379506e-09, std=2.124283895454937e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.1366242108911138e-12, std=4.9837389326512493e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-1.8178896166176628e-09, std=5.061594876565323e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.5005692244329794e-09, std=3.6815185922023375e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.985997227256121e-09, std=4.0654146005181246e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.9424710728799255e-09, std=4.712173904408701e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.498613368601582e-09, std=4.6749855187044886e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=3.490234234959644e-08, std=4.403747425385518e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=3.346561783246216e-08, std=5.358403996069683e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.5605905456794744e-11, std=1.523343144071987e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.77852630400821e-08, std=1.6028130858103395e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-5.917812018196855e-09, std=5.899871666770196e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-6.901665017267078e-08, std=4.930867817165563e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.3232526185902316e-11, std=1.914474523800891e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-6.252361117731198e-08, std=1.960654572030762e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=3.772780843291912e-08, std=1.2682831766142044e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=4.5740279119854677e-08, std=1.0786157872644253e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.637705496359558e-09, std=1.1337105206621345e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=6.217451300472021e-07, std=1.1932765119126998e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.4728329915669747e-06, std=0.00022798294958192855\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-3.4304080145375337e-06, std=0.00021597350132651627\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.5673604070751708e-09, std=5.591507215285674e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.8733695696937502e-06, std=5.809427602798678e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=1.9817159468971113e-08, std=0.0003184027737006545\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=3.497052603051998e-08, std=0.00020481641695369035\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=2.2083241901782458e-09, std=6.537562876474112e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-2.8882659535156563e-06, std=6.424510502256453e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-8.199488092941465e-07, std=0.0007738836575299501\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.0375046005938202e-06, std=0.0008558769477531314\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=3.7926029108348303e-06, std=0.0007648850441910326\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.7313763237325475e-05, std=0.0007770982338115573\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.001969750504940748, std=0.011260723695158958\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0005783434608019888, std=0.013221971690654755\n",
            "Grad stats for input_proj.weight: mean=1.0602154709715705e-09, std=7.274930879930253e-08\n",
            "Grad stats for input_proj.bias: mean=5.533384417333309e-09, std=2.3379681124424678e-07\n",
            "Grad stats for output_head.0.weight: mean=-2.9124421416781843e-06, std=0.023265786468982697\n",
            "Grad stats for output_head.0.bias: mean=0.0024479846470057964, std=0.024928361177444458\n",
            "Grad stats for output_head.2.weight: mean=0.004714015405625105, std=0.06417889147996902\n",
            "Grad stats for output_head.2.bias: mean=0.020289266481995583, std=0.11451120674610138\n",
            "Hungarian matching: row_ind=[ 7 11 17], col_ind=[0 2 1]\n",
            "conf_loss: 0.378013551235199, smooth_l1_loss: 0.004120777826756239, ciou_loss: 0.8118686079978943, box_loss: 0.40799468755722046\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=6.617290049248936e-12, std=4.3793708215389415e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.8407625423932927e-09, std=2.5220245447599154e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-5.958709914377636e-11, std=4.9039318383847785e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=3.360042910571792e-09, std=4.991651394448127e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=3.6572481154628633e-13, std=1.0612582812541405e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=7.633587650879292e-10, std=1.3673270515823788e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.1870360250298972e-10, std=3.142955762314159e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=5.206124420453762e-10, std=6.063149982082905e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=3.3551783573670946e-10, std=7.447994221365661e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=4.932292352322065e-09, std=1.0270077410723388e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-3.8661625012537115e-09, std=4.192029905425443e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-8.107585713901244e-09, std=3.9317583855336125e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-2.2705707106163153e-11, std=1.1488595674791213e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-9.681881074641296e-09, std=1.1905658681143905e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.530364029944664e-11, std=3.531929451128235e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-6.652736139756144e-10, std=3.0151826990731934e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.0604407069413355e-11, std=7.9395675811611e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-2.3043206454076426e-08, std=7.782951882973066e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.9465785367221997e-09, std=4.6158282884789514e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-5.99904126374895e-09, std=5.166294840819319e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.021618345475872e-10, std=6.6424786382413e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-1.3697452061478543e-08, std=6.684147706437216e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=4.610583914654853e-09, std=6.552688773808768e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-2.563920133979991e-07, std=6.552788363478612e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-5.860156804260441e-11, std=1.9509734556777403e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-6.132266605618497e-08, std=2.0180623323540203e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-8.286992203565546e-10, std=7.070311312418198e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-8.216716196329799e-09, std=5.848669388797134e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=9.964473690615705e-12, std=2.427927029202692e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-2.496620936653926e-07, std=2.4781934371276293e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.8957572340004845e-08, std=1.146959766629152e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-3.081287047734804e-08, std=9.765769391378853e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=7.098262244653597e-08, std=1.563424120831769e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=4.811793132830644e-07, std=1.419637101207627e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=3.551844656612957e-06, std=0.00019378676370251924\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.797832848955295e-06, std=0.0002002271357923746\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.0620934676761635e-09, std=5.205225897952914e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.1647648534562904e-06, std=5.3321469749789685e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=1.175530570662886e-07, std=0.0002903163549490273\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.7689378637442132e-06, std=0.00018178658501710743\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=3.779213386678748e-09, std=6.07652727921959e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-5.041986696596723e-06, std=5.945592056377791e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=3.972300874011125e-06, std=0.0007421772461384535\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.0482557627256028e-05, std=0.0008281897753477097\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=7.760228982078843e-06, std=0.0007044160738587379\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.4430313967750408e-05, std=0.0007221457199193537\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.006349941249936819, std=0.017437178641557693\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.0021699578501284122, std=0.014689808711409569\n",
            "Grad stats for input_proj.weight: mean=3.3736071713974525e-09, std=2.536378929107741e-07\n",
            "Grad stats for input_proj.bias: mean=2.0732095151743124e-08, std=1.046085685629805e-06\n",
            "Grad stats for output_head.0.weight: mean=-4.631583578884602e-06, std=0.02407858334481716\n",
            "Grad stats for output_head.0.bias: mean=0.005390451289713383, std=0.025533169507980347\n",
            "Grad stats for output_head.2.weight: mean=0.0026883098762482405, std=0.062267810106277466\n",
            "Grad stats for output_head.2.bias: mean=0.011731442995369434, std=0.11421860009431839\n",
            "No targets: conf_loss=0.12470658868551254, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=7.928183283489876e-12, std=9.843343029558582e-09\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.2789556080861075e-09, std=4.9848399186203096e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-2.6428061128402902e-11, std=2.640970286904576e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.9404828854874268e-09, std=1.4877714704653044e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-3.578073167614937e-14, std=7.87734766305448e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-7.928556422509558e-11, std=9.019214708416712e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.9966855946407236e-10, std=1.6914091460762393e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=4.4767889395558313e-10, std=1.9936923223440317e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.9783094606928842e-10, std=4.476671833231194e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.3292708589982567e-09, std=4.6187523139451514e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=8.566392040165738e-10, std=2.3466530763016635e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=4.6419312837997495e-11, std=2.2626387874424836e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=7.911717288255904e-12, std=6.906613236878911e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.120505631670767e-09, std=7.124744172415376e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-7.955880398924364e-11, std=1.8454760208896914e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-7.811646884903212e-10, std=1.5540263120783493e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-9.717587845514686e-12, std=3.4377958257891805e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=7.344310049006708e-09, std=3.4573826468431434e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.6220947918199613e-09, std=1.0678222395199555e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=3.3735245708044204e-09, std=1.2254633929842385e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.4372948931604697e-09, std=3.261514507357788e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=7.696522530409311e-09, std=3.396023089408118e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-2.9259403788728378e-09, std=1.439647007828171e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=1.4801026182453825e-08, std=1.493133481744735e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.2799540033702215e-11, std=4.4963394429942127e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.113526586024818e-08, std=4.6144964471750427e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-2.425944112260936e-09, std=1.3867814914192422e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-3.0313916710156263e-08, std=1.1259423899900867e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=5.686145998495817e-12, std=3.925195528609038e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=2.038670210424698e-08, std=4.0150109725800576e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.3497988504695968e-08, std=1.5175711496340227e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.562028728585574e-08, std=1.269993504138256e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-4.810395637377951e-09, std=3.0753428745811107e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-4.4292924883393425e-09, std=2.7991602564725326e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.8178097604959476e-07, std=2.7108761059935205e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-3.8284423453660565e-07, std=2.4669610866112635e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-1.0133588412841732e-09, std=7.992722203198355e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.585555876066792e-07, std=8.213765795517247e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-5.981552675393687e-08, std=3.7282581615727395e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=4.392181267576234e-07, std=2.418050280539319e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-8.023324227224293e-10, std=7.50975004848442e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=6.498652282971307e-07, std=7.282604656211333e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-2.793647411181155e-07, std=8.579358109273016e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-7.157414074754342e-07, std=9.439670975552872e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.1605549161686213e-06, std=0.00010705398744903505\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.2640807653951924e-06, std=8.781634096521884e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0016798304859548807, std=0.0038578733801841736\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.833339673699811e-05, std=0.0022779200226068497\n",
            "Grad stats for input_proj.weight: mean=-3.5432298761683967e-10, std=4.699838740407358e-08\n",
            "Grad stats for input_proj.bias: mean=-1.9138561846432367e-09, std=1.6362646704237704e-07\n",
            "Grad stats for output_head.0.weight: mean=1.445347152184695e-06, std=0.0029829228296875954\n",
            "Grad stats for output_head.0.bias: mean=-0.001450699637643993, std=0.002785415155813098\n",
            "Grad stats for output_head.2.weight: mean=0.0002707257226575166, std=0.0015811675693839788\n",
            "Grad stats for output_head.2.bias: mean=0.0011557447724044323, std=0.002635055920109153\n",
            "Hungarian matching: row_ind=[18], col_ind=[0]\n",
            "conf_loss: 0.21111710369586945, smooth_l1_loss: 0.006481940858066082, ciou_loss: 0.9573317170143127, box_loss: 0.48190683126449585\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.618063599773123e-10, std=2.0050572402396938e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-4.253205077020539e-08, std=1.0629711368892458e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-2.1730206523074003e-10, std=3.388222182820755e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=4.144171228404048e-09, std=2.635975761222653e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.3671550830606236e-12, std=9.833842540274418e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=9.076084328540901e-10, std=1.1768249663646202e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.7414270025994938e-09, std=1.8647078547928686e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=4.36126601499609e-09, std=2.6735466462923796e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-4.277946885622441e-10, std=5.214742486714385e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-3.210660182162428e-08, std=6.507189027615823e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.4405530868752976e-08, std=2.5757651656022063e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.6846614648311515e-09, std=2.434238695059321e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=6.551981179825361e-11, std=7.492491249649902e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=2.7547107706027418e-08, std=7.684351430725656e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-5.005502679011897e-10, std=2.154011326638283e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-7.202121565796915e-09, std=1.7425154510419816e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-4.6815218368578826e-11, std=4.138624660754431e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=4.1881282442091106e-08, std=4.203744197184278e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.6619559894959224e-10, std=1.2157663604739355e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-6.500684435195581e-10, std=1.3681603832083056e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=4.272270359706454e-08, std=3.730637217813637e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-3.2165701213671127e-09, std=3.832630682154559e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=4.594520675027525e-08, std=1.3949295862403233e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=6.638445029238937e-07, std=1.70666171470657e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.3083757128006255e-10, std=5.188930572330719e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=3.080289445733797e-07, std=5.303674697643146e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=6.6586478553176676e-09, std=1.654327024880331e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=7.015783864972036e-08, std=1.3888134162698407e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-3.00702795996699e-11, std=4.330248430051142e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=4.312688872687431e-08, std=4.451431777852122e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-5.431119234344806e-07, std=2.3408470951835625e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-6.25064103587647e-07, std=1.9952411093981937e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=1.378309661959065e-07, std=3.326305522932671e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-5.052912115388608e-07, std=3.34999494953081e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=5.996425898047164e-06, std=0.00040490232640877366\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.4110617485130206e-05, std=0.0004067016998305917\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=7.357907061411595e-10, std=0.00012963828339707106\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-2.812349521263968e-06, std=0.0001316755369771272\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=8.86331008587149e-09, std=0.000626643537543714\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.7274069250561297e-06, std=0.00038956350181251764\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.027178425123566e-09, std=0.00012935491395182908\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-3.3921958220162196e-06, std=0.00012797184172086418\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.354638152406551e-05, std=0.0015214328886941075\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=3.575298978830688e-05, std=0.0017092155758291483\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=3.3559626899659634e-07, std=0.0017746889498084784\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-3.249761357437819e-05, std=0.0015898833516985178\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.01072490494698286, std=0.03851320222020149\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.002556090010330081, std=0.027971887961030006\n",
            "Grad stats for input_proj.weight: mean=-8.767098158557474e-09, std=1.063732725015143e-06\n",
            "Grad stats for input_proj.bias: mean=-4.753256988010435e-08, std=3.863527126668487e-06\n",
            "Grad stats for output_head.0.weight: mean=-6.126181688159704e-06, std=0.04911848157644272\n",
            "Grad stats for output_head.0.bias: mean=0.011950168758630753, std=0.05296451225876808\n",
            "Grad stats for output_head.2.weight: mean=0.006083284039050341, std=0.12337092310190201\n",
            "Grad stats for output_head.2.bias: mean=0.027251679450273514, std=0.2298731803894043\n",
            "No targets: conf_loss=0.1260077953338623, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=5.192916843060891e-12, std=8.280176544417372e-09\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-6.647618566724134e-10, std=3.875876330994288e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.2844563086755745e-11, std=2.235255180949025e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-7.283302849714346e-10, std=1.2550903250030387e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-6.442758652969172e-13, std=6.8225678440114734e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.6281893328317096e-10, std=7.352439990171433e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-5.038154268777184e-11, std=1.46732679340289e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.162678842092646e-10, std=1.711647890090262e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.864959853214998e-10, std=3.8618054531980306e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.3987976049966164e-09, std=3.863569375539555e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.8802310819410195e-09, std=2.1508769521005888e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-7.46609440938073e-10, std=1.9551485763713572e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.270121996418634e-12, std=6.274473918210788e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.743105825293469e-09, std=6.25834175593809e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.6843435807499816e-10, std=1.7323687018233613e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=2.268341736666457e-09, std=1.3974995738408325e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-6.755457304663537e-12, std=3.318888630587935e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=6.589057299777323e-09, std=3.2781706238438346e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.359972495202811e-10, std=1.0279788398293022e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-4.705015266281976e-10, std=1.146465677948072e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.8828814890857757e-09, std=3.131149242108222e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=7.072626928561476e-09, std=3.080268982103007e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.1194671856173954e-09, std=1.3931795592725393e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=4.122543728612982e-08, std=1.434355567653256e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.5138114640176354e-11, std=4.3503726487870154e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=3.808754556189342e-08, std=4.4222872475074837e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-1.8995900408214084e-09, std=1.4847540796836256e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-2.952646838139117e-08, std=1.1115117786175688e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-5.540901071299231e-12, std=4.1626964275565115e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=2.1687423412686258e-08, std=4.2260066379640193e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.451863068131388e-08, std=1.5729638107586652e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-2.8132562945870632e-08, std=1.3178114386391826e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-9.742461060113783e-09, std=3.128256366835558e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-2.830814871401799e-08, std=2.8857768938905792e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-5.174171064936672e-07, std=3.3299289498245344e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-7.832170467736432e-08, std=2.6510635507293046e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-4.2715697645689943e-10, std=8.539551345165819e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.953003104266827e-07, std=8.580510439060163e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-4.6706016831876696e-08, std=3.809161717072129e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=5.306227421897347e-07, std=2.4308947104145773e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.686739719592879e-10, std=7.706720680289436e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=7.878957148932386e-07, std=7.498870672861813e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-2.7182898065802874e-07, std=8.778763731243089e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-6.974485131649999e-07, std=9.639873314881697e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-9.828718248172663e-07, std=0.00012174926087027416\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.1251016758251353e-06, std=8.88959039002657e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0016835886053740978, std=0.0040765246376395226\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.82493121328298e-05, std=0.0022958635818213224\n",
            "Grad stats for input_proj.weight: mean=-9.449369064995494e-10, std=4.5919477997813374e-08\n",
            "Grad stats for input_proj.bias: mean=-4.56664128734019e-09, std=1.3714101498862874e-07\n",
            "Grad stats for output_head.0.weight: mean=7.912349246907979e-07, std=0.0030093349050730467\n",
            "Grad stats for output_head.0.bias: mean=-0.0014624327886849642, std=0.00280944537371397\n",
            "Grad stats for output_head.2.weight: mean=0.0002725402591750026, std=0.0015795619692653418\n",
            "Grad stats for output_head.2.bias: mean=0.0011667296057567, std=0.002662705723196268\n",
            "No targets: conf_loss=0.13115401566028595, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-4.994161972859956e-09, std=2.9833215648977784e-06\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=4.617944284746045e-07, std=1.6621359463897534e-05\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.6988441209342398e-10, std=2.1953856048639864e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-4.6799698338872986e-08, std=2.1583206034847535e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=7.046252470388481e-12, std=1.95246840917207e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-3.7358244497909254e-08, std=2.2232225660445692e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-3.6760372523758633e-10, std=2.0350603335828055e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-2.8587452405304248e-09, std=5.576682724495186e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=3.1145894752171444e-09, std=3.1065833354659844e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-7.382422495538776e-08, std=3.910289251507493e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.5375498207959026e-08, std=8.215727689275809e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.427987493864748e-08, std=1.136060745920986e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=4.4673802851447064e-11, std=2.851811586879194e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=2.1369606528764962e-08, std=2.997525996306649e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.7456961149141534e-09, std=8.98288419648452e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-1.5064768987826938e-08, std=9.516498948869412e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=5.453398149724009e-12, std=2.0062302041878866e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=8.78701200690557e-09, std=2.0408810996741522e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-4.53930137922498e-09, std=4.4392629661160754e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.2016819539439894e-08, std=5.91973332575435e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.1268657118534975e-09, std=1.4208947050065035e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.2314777109168062e-07, std=1.5572503571092966e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-5.955249804401319e-08, std=3.928545538656181e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-3.8665916690661106e-08, std=4.975354841008084e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-2.506886642716921e-10, std=1.517443251941586e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=1.364142576676386e-07, std=1.526372898297268e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-3.0982900689480175e-09, std=5.238427092990605e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=4.67090828237815e-08, std=3.7295708352758083e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-5.076827847005916e-12, std=1.0570399808784714e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-3.4277615412747764e-08, std=1.0539888535276987e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=3.824808558761106e-08, std=3.639498800112051e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=1.1012481593297707e-07, std=4.5565643631562125e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.1808932498524882e-07, std=8.862240065354854e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=6.072411906643538e-07, std=1.02071189758135e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=2.5076698761949956e-07, std=4.330146111897193e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.2740580359604792e-06, std=5.0446386012481526e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.802966830335208e-10, std=1.4384232599695679e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=7.702542461629491e-07, std=1.4352757716551423e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.2999737286634172e-08, std=4.9207508709514514e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-2.587204903647944e-07, std=3.9557871787110344e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-2.383728769927984e-10, std=8.515775334672071e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=4.749178401652898e-07, std=8.31719080451876e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=5.479619744619413e-07, std=8.988291665446013e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.6659004131724942e-06, std=0.00010764173202915117\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-5.048411821917398e-07, std=0.0001173561904579401\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=9.055725058715325e-08, std=0.00010896920139202848\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017099594697356224, std=0.004374573938548565\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=7.695576641708612e-05, std=0.0023574475198984146\n",
            "Grad stats for input_proj.weight: mean=5.891760324061579e-08, std=1.8224274754174985e-05\n",
            "Grad stats for input_proj.bias: mean=4.792203753822832e-07, std=7.159710366977379e-05\n",
            "Grad stats for output_head.0.weight: mean=1.395208528265357e-06, std=0.003134814789518714\n",
            "Grad stats for output_head.0.bias: mean=-0.0015870307106524706, std=0.002939342986792326\n",
            "Grad stats for output_head.2.weight: mean=0.0002790943253785372, std=0.001576187089085579\n",
            "Grad stats for output_head.2.bias: mean=0.0012109536910429597, std=0.002757756505161524\n",
            "Hungarian matching: row_ind=[2 7 8], col_ind=[1 2 0]\n",
            "conf_loss: 0.38315287232398987, smooth_l1_loss: 0.009542779065668583, ciou_loss: 0.9286797046661377, box_loss: 0.46911123394966125\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-8.233284193304158e-11, std=2.32005660905088e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=5.147297699181763e-08, std=1.2726825389108853e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-2.71350802938386e-10, std=3.404283006602782e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.591368103959212e-08, std=3.330146682856139e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-1.1791609355604749e-12, std=8.603335288626113e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.698716361493325e-09, std=1.1127851706760339e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-6.361115523212391e-10, std=1.500940527421335e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-2.1254917825785924e-09, std=2.9406774615381437e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=7.282174863121327e-10, std=4.881960649072425e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=3.3828001733127167e-08, std=6.949806561351579e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-4.362480865438556e-08, std=2.076511236737133e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=1.0295849506292143e-08, std=1.9054652966588037e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-6.1531967021633e-11, std=5.556965447794937e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-2.7146233705366285e-08, std=5.769263111687906e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-3.420248528840375e-10, std=1.5707167904110975e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-4.2247161324837634e-09, std=1.3301282706379425e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=3.6829317373587855e-11, std=2.9056519679215853e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-3.065783360511887e-08, std=2.9894002295804967e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-6.445338485150387e-09, std=8.182058763850364e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.3365889728333968e-08, std=9.337796313957369e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-3.6269625525164884e-08, std=2.7014975785277784e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-4.7827015237089654e-08, std=2.848493750207126e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=2.672237542356015e-09, std=1.0021009984484408e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-2.268084386969349e-07, std=1.1673343578877393e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-2.0393287059050635e-10, std=3.5038040095969336e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-2.6112459750038397e-07, std=3.663840743683977e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=3.07285596967688e-09, std=1.0961724001390394e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=4.755400340172855e-08, std=9.147418495558668e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=9.957923374770417e-12, std=2.6421153052069712e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-6.123353557541122e-08, std=2.727034598137834e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-4.116930796271845e-08, std=1.0932039913313929e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-4.669226427722606e-08, std=9.405806849827059e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.254816753425985e-08, std=2.5493247449048795e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=1.0537191030834947e-07, std=2.226658762083389e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=1.2889081517641898e-06, std=0.00020605938334483653\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=2.6125769636564655e-06, std=0.0001928534038597718\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-1.016113970742083e-09, std=5.328591214492917e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=8.348167170879606e-07, std=5.4408115829573944e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=1.465454602112004e-07, std=0.00028486226801760495\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-2.226051947218366e-06, std=0.0001779760350473225\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-4.6203041392800515e-10, std=6.410779315046966e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.47822470353276e-06, std=6.351095362333581e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=4.13951738664764e-06, std=0.0007324664038605988\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.0873434803215787e-05, std=0.0008243672782555223\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-3.435594408074394e-06, std=0.0008284988580271602\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.3587918147095479e-05, std=0.0006998041644692421\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.005556202493607998, std=0.01508104708045721\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0011357743060216308, std=0.013641619123518467\n",
            "Grad stats for input_proj.weight: mean=1.4068516129839281e-08, std=1.2246066489751684e-06\n",
            "Grad stats for input_proj.bias: mean=8.155038955237615e-08, std=4.476215508475434e-06\n",
            "Grad stats for output_head.0.weight: mean=2.9633083613589406e-06, std=0.024272365495562553\n",
            "Grad stats for output_head.0.bias: mean=-0.003263670252636075, std=0.026185324415564537\n",
            "Grad stats for output_head.2.weight: mean=-0.004402437712997198, std=0.06208719313144684\n",
            "Grad stats for output_head.2.bias: mean=-0.01903313398361206, std=0.11225230991840363\n",
            "Hungarian matching: row_ind=[1], col_ind=[0]\n",
            "conf_loss: 0.20922580361366272, smooth_l1_loss: 0.007197207771241665, ciou_loss: 0.767270565032959, box_loss: 0.3872338831424713\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-2.9116816596674866e-11, std=2.3191967457592e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=3.5885696636484e-09, std=1.1512035769101203e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=5.748652595616299e-11, std=6.632157578678743e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-5.396627145159982e-09, std=3.6136913195150555e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=9.608866436902619e-14, std=2.0119886201541703e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=3.4125258174810824e-11, std=2.1817132989099264e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-5.352860377172419e-10, std=4.29472066798553e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.1294609691958613e-09, std=4.936386588383357e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-5.759844823316485e-10, std=1.0245801007613409e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=4.230929384618776e-09, std=1.1096249608044673e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-5.424613647164733e-09, std=5.711711423828092e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.4312913521052906e-08, std=5.65633570204227e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-7.552292125012627e-12, std=1.6441555317214807e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-8.821018582239049e-09, std=1.6583126694058592e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=6.926174078714098e-10, std=4.641091777557449e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=7.954624514638908e-09, std=4.252038650065515e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=1.9402757178710317e-11, std=9.487129659646598e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-1.5836860711715417e-08, std=9.47733411749141e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-5.024069160697309e-09, std=3.0593224664698937e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.0329246791229707e-08, std=3.4184543551418756e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-8.37993852087493e-09, std=8.237786346398934e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-3.155757610784349e-08, std=8.616464697297488e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-6.094032301007246e-08, std=3.8040068375266856e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-1.2140860405907006e-07, std=4.096204520465108e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-8.953193741945142e-11, std=1.2202924608573085e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-9.020130420367423e-08, std=1.2545993968160474e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.7989904677051527e-08, std=3.566387022146955e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.3442139845665224e-07, std=2.9827358503098367e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=5.090150523301418e-12, std=9.009562518258463e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-1.564039564527775e-08, std=9.278587072003575e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.614028235508158e-07, std=5.4764900596637744e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-1.8935276102638454e-07, std=4.687779437517747e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=7.874014329445345e-09, std=7.21239530321327e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.3492875672891387e-07, std=7.363319582509575e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=1.408514435752295e-06, std=8.489484753226861e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=9.634732123231515e-07, std=9.851490176515654e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=2.7368400878913235e-09, std=3.1037921871757135e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.2553729220599052e-06, std=3.080540045630187e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-5.256211110804543e-08, std=0.00016326821059919894\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=9.68637777987169e-07, std=9.989085810957476e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=3.6130654024191244e-11, std=3.163359724567272e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-2.623829686854151e-07, std=3.0828781746095046e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-5.8209188864566386e-06, std=0.00036853464553132653\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-1.5611256458214484e-05, std=0.000410591863328591\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=7.893162319305702e-07, std=0.0003263005055487156\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-3.6771002669411246e-06, std=0.0003934155101887882\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0013195757055655122, std=0.007330659776926041\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-1.6852209228090942e-05, std=0.00661295372992754\n",
            "Grad stats for input_proj.weight: mean=2.0657959787229174e-09, std=1.0651788073801072e-07\n",
            "Grad stats for input_proj.bias: mean=1.1035563574068874e-08, std=3.7717165923822904e-07\n",
            "Grad stats for output_head.0.weight: mean=-9.051309461938217e-07, std=0.012000120244920254\n",
            "Grad stats for output_head.0.bias: mean=0.0010250172344967723, std=0.012478705495595932\n",
            "Grad stats for output_head.2.weight: mean=0.0025516266468912363, std=0.037363868206739426\n",
            "Grad stats for output_head.2.bias: mean=0.01087535172700882, std=0.06698750704526901\n",
            "Hungarian matching: row_ind=[ 2  7  8 10 12 18], col_ind=[3 1 0 2 5 4]\n",
            "conf_loss: 0.6328351497650146, smooth_l1_loss: 0.013580451719462872, ciou_loss: 0.9083614945411682, box_loss: 0.4609709680080414\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=9.755090069063499e-10, std=7.304794280571514e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.2419297945598373e-07, std=3.965340965805808e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=3.1467606298463124e-12, std=9.700265763967764e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.791612476154114e-07, std=1.2135380529798567e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=2.6647128947843157e-11, std=2.678674491107813e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-1.7880594782582193e-08, std=3.391224936422077e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.6599445151754821e-09, std=4.430073374805943e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=7.608962349081594e-09, std=1.2861695495303138e-06\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=1.0520441406924874e-08, std=2.6325783437641803e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=2.962159584285473e-08, std=2.4714179289730964e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-1.1281045431132952e-08, std=3.313461320431088e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=1.9192162881154218e-07, std=4.7705361794214696e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-4.202431111433036e-11, std=7.684793672524393e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-9.336419992678202e-08, std=1.4194687310009613e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=3.0108950888063646e-09, std=2.3704783416178543e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.905729073494513e-09, std=3.203023197784205e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=4.094713457192256e-11, std=5.639272444568633e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-4.966960887031746e-08, std=6.187453323036607e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-3.2414819717274668e-09, std=1.1675987252601772e-06\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-8.294669839870039e-09, std=1.922196588566294e-06\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.7112114392148214e-08, std=4.203358457743889e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-4.6046199031479773e-07, std=6.206949819898e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.5217830195979332e-07, std=1.1476424333523028e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-1.5603581005052547e-07, std=1.747137139318511e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.7073277781018987e-10, std=3.697412239489495e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-4.387130729810451e-07, std=5.381265509640798e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=2.9160132086758495e-09, std=1.1461777830845676e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=5.935177682658832e-09, std=1.3954030691820662e-05\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-7.94075916132897e-12, std=2.8921058401465416e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=6.700470578380191e-08, std=3.034627525266842e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-4.699635791638457e-09, std=1.115415489039151e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-2.295229251103592e-08, std=1.4979613297327887e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=1.9917592908313964e-07, std=1.8995302525581792e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.3895855772716459e-06, std=3.404351809876971e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=7.639111572643742e-06, std=0.00015317086945287883\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.7583033695700578e-06, std=0.00019828327640425414\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=2.0095807240494423e-09, std=6.0463775298558176e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.0347321222070605e-08, std=6.145781662780792e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-1.7478470226706122e-08, std=0.00022837317374069244\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=9.430495993001387e-07, std=0.0001725481852190569\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=1.6994317064700226e-10, std=4.5549633796326816e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=6.50889319331327e-07, std=4.5084336306899786e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-8.570657428208506e-07, std=0.0004607099399436265\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.423754267510958e-06, std=0.0005574618116952479\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.7810028768726625e-06, std=0.000490090751554817\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-1.0476942406967282e-06, std=0.0005518455873243511\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0007953314343467355, std=0.006499815732240677\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0009167419048026204, std=0.008005285635590553\n",
            "Grad stats for input_proj.weight: mean=-5.843162398377899e-09, std=4.516894023254281e-06\n",
            "Grad stats for input_proj.bias: mean=-6.259227802729583e-08, std=1.491181319579482e-05\n",
            "Grad stats for output_head.0.weight: mean=-3.713362275448162e-07, std=0.013362647965550423\n",
            "Grad stats for output_head.0.bias: mean=0.000291967618977651, std=0.014646649360656738\n",
            "Grad stats for output_head.2.weight: mean=-0.0017345421947538853, std=0.03669476509094238\n",
            "Grad stats for output_head.2.bias: mean=-0.0077071706764400005, std=0.06781062483787537\n",
            "Batch 170, Loss: 1.0938061475753784\n",
            "Hungarian matching: row_ind=[12], col_ind=[0]\n",
            "conf_loss: 0.21637599170207977, smooth_l1_loss: 0.0019039579201489687, ciou_loss: 0.6073024868965149, box_loss: 0.3046032190322876\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-1.7311152511467753e-13, std=5.250770485076828e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.0838142827651609e-08, std=2.9052958439024223e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=2.9595510070423714e-11, std=9.895095587353353e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-3.203459719713919e-09, std=8.220299037020595e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=6.94774099363471e-13, std=2.3544322047541755e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=5.882924147826429e-10, std=2.9637842402507886e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=3.0843552711878885e-10, std=4.885736615278802e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=7.449586503227579e-10, std=7.585116890140853e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=3.116737978814399e-10, std=1.4652242441570706e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-7.252736189400366e-09, std=1.9057732458804821e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.1680435224880057e-10, std=6.676196449006966e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-1.7563550613886036e-08, std=6.432157420022122e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-2.6182942532843034e-12, std=1.9989161614830664e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-6.097824467587998e-10, std=2.03575069690487e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=8.596214851053219e-10, std=6.307125772764266e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=9.855800620073296e-09, std=4.993296442989958e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=2.6935537134065157e-12, std=1.2285639172660012e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-4.5787023061905074e-09, std=1.2525795511919569e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-4.4713743818647345e-10, std=5.601572752311768e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-1.0354250790101105e-09, std=6.344700977933826e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=1.4837787887245213e-08, std=1.0875604630200542e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-3.7223690796395204e-09, std=1.1088552582805278e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=3.262661607550399e-08, std=6.6858719947049394e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=8.922616245854442e-08, std=7.87546014180407e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-1.5905499139989843e-10, std=2.1124665181559976e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.51477749454898e-07, std=2.1572554942395072e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=6.341611236138078e-09, std=9.09709524421487e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=8.007736340687188e-08, std=7.273361006809864e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-1.2362666446108506e-11, std=2.7389844490244286e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.2477092070639628e-07, std=2.791952510960982e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=6.732601320891263e-08, std=2.00571957975626e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=7.913607191767369e-08, std=1.6966409020824358e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=1.0764611602098739e-07, std=1.833994065236766e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-1.9187794464414765e-07, std=1.828308086260222e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.5069317669258453e-06, std=0.00035562171251513064\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=5.696215794159798e-06, std=0.00034833536483347416\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=1.9118109761961932e-08, std=9.712087194202468e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-9.33076717046788e-06, std=9.699077054392546e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-2.054021308595111e-07, std=0.000580278632696718\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=1.7064676285372116e-06, std=0.00035500936792232096\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-3.729994091372646e-09, std=0.00013091151777189225\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=2.1613277567666955e-06, std=0.000130520187667571\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=3.296471049907268e-06, std=0.0014475909993052483\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=8.662846084916964e-06, std=0.001634824089705944\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-2.720014890655875e-06, std=0.0012932539684697986\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=-2.7067655537393875e-05, std=0.001388635253533721\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.014518826268613338, std=0.04795648902654648\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0031464537605643272, std=0.028864260762929916\n",
            "Grad stats for input_proj.weight: mean=-3.3812639355090823e-09, std=2.5555877414262795e-07\n",
            "Grad stats for input_proj.bias: mean=-1.8961117120852578e-08, std=9.723623861646047e-07\n",
            "Grad stats for output_head.0.weight: mean=-1.1340860510244966e-05, std=0.057717110961675644\n",
            "Grad stats for output_head.0.bias: mean=0.012050095945596695, std=0.060374923050403595\n",
            "Grad stats for output_head.2.weight: mean=0.005935047287493944, std=0.12514792382717133\n",
            "Grad stats for output_head.2.bias: mean=0.025518758222460747, std=0.22695210576057434\n",
            "No targets: conf_loss=0.13057036697864532, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.0786038728838321e-10, std=6.039904292265419e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=1.2365528334612463e-07, std=3.3898297715495573e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.791959219898942e-10, std=4.842535759053135e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.1926545084861573e-08, std=5.430587862065295e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-3.9371284010769614e-13, std=6.432255617028204e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-5.9513984851378154e-09, std=7.656834810632063e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-5.663919333542822e-11, std=9.303075643174452e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-3.6152836280223255e-10, std=2.7955812242907996e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.2248727304940985e-09, std=1.0233162583972444e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.748493699300525e-08, std=1.0791073918881011e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-9.897672903491639e-09, std=5.642030487251759e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-2.9079505026174957e-08, std=7.890661777310015e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.4111618991397012e-11, std=1.681864745251005e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=1.587366327271411e-08, std=2.3662509818223043e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=8.651245830826326e-10, std=5.905671400796564e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-6.5835239482225916e-09, std=6.069661253604863e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-3.2576719100063656e-12, std=1.2859926812325284e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=9.956576008107731e-09, std=1.3719933633637993e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-3.2087341672593084e-09, std=2.89221219418323e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-8.113415717048156e-09, std=4.191516893570224e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=7.908713683946189e-10, std=9.084801604331005e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.081749445575042e-07, std=1.201253894578258e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.7301818644455125e-08, std=2.694179556783638e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-4.134695075208583e-08, std=3.924478733097203e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-8.215531727140402e-11, std=9.889432703857892e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=9.790021948674621e-08, std=1.1509207524795784e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=1.212887346113689e-09, std=3.5368559565540636e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-3.9451165889659023e-08, std=3.1764304821990663e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=6.896871962425166e-12, std=7.413401590383728e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-2.2489427209393398e-08, std=7.648607152077602e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-1.5610680748068262e-08, std=2.972286438307492e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-4.874571857271803e-08, std=3.8712664718332235e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-7.517750333363438e-08, std=6.214334462129045e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=3.9253822592399956e-07, std=7.990209269337356e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-1.7437989754398586e-06, std=3.400394052732736e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=1.2522521046776092e-06, std=4.585528586176224e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-3.360677569563819e-10, std=1.2865019925811794e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=6.527088771690615e-07, std=1.3025812222622335e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=1.332246313268115e-08, std=4.498381167650223e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=4.806736910722975e-07, std=3.4696680813794956e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=9.15125752953827e-11, std=8.752813300816342e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=5.013151849198039e-07, std=8.60643012856599e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=6.233109957065608e-07, std=9.177426545647904e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.8139255644200603e-06, std=0.00011295745935058221\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-4.591287279254175e-07, std=9.583286009728909e-05\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=8.124177384161158e-07, std=0.00010969312279485166\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017114835791289806, std=0.004036249127238989\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.917960515944287e-05, std=0.0023809107951819897\n",
            "Grad stats for input_proj.weight: mean=4.350086513227325e-08, std=4.244220235705143e-06\n",
            "Grad stats for input_proj.bias: mean=2.662202405190328e-07, std=1.5437708498211578e-05\n",
            "Grad stats for output_head.0.weight: mean=1.4897232176735997e-06, std=0.0030246193055063486\n",
            "Grad stats for output_head.0.bias: mean=-0.001521347090601921, std=0.0029189675115048885\n",
            "Grad stats for output_head.2.weight: mean=0.0002741555217653513, std=0.001603822223842144\n",
            "Grad stats for output_head.2.bias: mean=0.0012064574984833598, std=0.0027397004887461662\n",
            "No targets: conf_loss=0.1322750747203827, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=1.124555309983677e-11, std=6.66255006720462e-09\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-6.919454453857554e-10, std=2.8188555489805367e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=5.119286071442186e-12, std=2.6682293707835925e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-3.5464742254021075e-10, std=8.971230158749677e-08\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-2.0788861083975707e-13, std=8.491762848450435e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-4.369053036024084e-11, std=8.801871231867153e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-6.546004016616536e-11, std=2.0056637239918018e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-1.3600065518204474e-10, std=2.0010915591228695e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=2.3541818494621225e-10, std=4.778585349640707e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.1694273044658985e-09, std=4.491697680464313e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.1651675180246457e-09, std=2.9549440228038293e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-8.717044863715273e-10, std=2.637519003201305e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=8.667788709004753e-12, std=8.348965252480411e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=6.191516632725325e-09, std=8.395892336920951e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=5.454283136252513e-10, std=2.442388336021395e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=5.8801514768447305e-09, std=1.785411711807683e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-1.1246836795208992e-11, std=4.7203577935306384e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=7.72777219992804e-09, std=4.699514022377116e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-2.8408504437749116e-09, std=1.469682615606871e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-5.792865742648701e-09, std=1.607658504099163e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.968144923760519e-09, std=4.484859346121084e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.337826383007723e-08, std=4.313566535074642e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-6.18738482671688e-09, std=1.934456577146193e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=4.740147119264293e-08, std=1.9399406028242083e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=4.8861952678391773e-11, std=5.831754492646724e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=6.274172648090826e-08, std=5.914649818805628e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=-3.5706015921732615e-10, std=1.8927333940155222e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-1.2135296323378952e-08, std=1.5062504417073797e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-5.7588378510331495e-12, std=5.064454740022484e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=2.1303078412415744e-08, std=5.142861709828139e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=8.410704133154923e-09, std=1.8817707996277022e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=9.66661595214191e-09, std=1.5795783383509843e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-4.82562256820529e-09, std=4.228378202242311e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-4.957053079124307e-08, std=3.692351583595155e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-6.668028618150856e-07, std=3.462350650806911e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-2.6950789333568537e-07, std=3.09449496853631e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-1.0634563230027538e-09, std=1.0356199709349312e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=2.6466250346857123e-07, std=1.020261970552383e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=6.808225094800946e-09, std=4.079799327882938e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.6533181224076543e-07, std=2.7693478841683827e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-3.7277381181866076e-10, std=9.64598984865006e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=9.767487654244178e-07, std=9.296516509493813e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.321665536124783e-06, std=0.00010611593461362645\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=3.4423867418809095e-06, std=0.00011317116877762601\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.0452953347339644e-06, std=0.0001250341592822224\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=2.2266513042268343e-06, std=0.00010288674820913002\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017203872557729483, std=0.003780889557674527\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.00010501843644306064, std=0.002468934515491128\n",
            "Grad stats for input_proj.weight: mean=1.846506419989069e-10, std=3.0206933843146544e-08\n",
            "Grad stats for input_proj.bias: mean=9.628255970284272e-10, std=9.553548352414509e-08\n",
            "Grad stats for output_head.0.weight: mean=2.575732651166618e-06, std=0.0031596184708178043\n",
            "Grad stats for output_head.0.bias: mean=-0.0015872075455263257, std=0.0029809291008859873\n",
            "Grad stats for output_head.2.weight: mean=0.0002749669074546546, std=0.0016497998731210828\n",
            "Grad stats for output_head.2.bias: mean=0.0012211173307150602, std=0.0027699358761310577\n",
            "Hungarian matching: row_ind=[ 7  8 10 17 18], col_ind=[1 0 4 3 2]\n",
            "conf_loss: 0.5351911187171936, smooth_l1_loss: 0.014227638021111488, ciou_loss: 1.0121650695800781, box_loss: 0.5131963491439819\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=3.913052607634748e-12, std=1.1837587265972616e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.621282663677448e-09, std=6.558996687999752e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-1.4949209925507745e-10, std=1.337009081225915e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=1.520790604558897e-08, std=1.459048348806391e-06\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=9.132278266932303e-13, std=2.067861260002246e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-8.52689863162226e-11, std=2.674079979669841e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=6.865327750738004e-11, std=3.1427408231365916e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=6.570866073474235e-11, std=8.882328472736845e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=4.678177845107712e-10, std=2.3285437578124402e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-4.928350172406226e-09, std=2.6354442184128857e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=1.2659528536573816e-08, std=2.7315940087646595e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-5.3810560451950096e-09, std=2.979334396968625e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.78251767785876e-12, std=8.343148749645479e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.416742222484004e-09, std=9.00389522939804e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-1.6530751767440677e-10, std=2.2905324215116707e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=-2.801965770515835e-09, std=2.1181482168231014e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-2.822769795685076e-12, std=4.177365653390552e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=2.8366309301475212e-09, std=4.453850976915419e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.0253770055257405e-09, std=1.5098868288987433e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.0495347641258377e-09, std=1.790987056438098e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=5.123503399317997e-09, std=3.8513718436661293e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=1.1719459180881131e-08, std=4.095509780199791e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=5.3679087841373985e-09, std=1.8699505517361104e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-1.3041443480688031e-08, std=2.2077244921092642e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=2.2504184279958928e-11, std=6.847553777333815e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=2.1629224633556987e-08, std=7.164434236983652e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=2.850347735616765e-11, std=2.1630833089147927e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=8.575682386435801e-10, std=1.8100085981131997e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=2.8246988081903623e-12, std=5.825525022373768e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.2521937264864391e-08, std=6.005029717925936e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=2.3261856885170573e-09, std=3.635491793829715e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=2.932118547960272e-09, std=3.1284835131373256e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=6.986077494275378e-09, std=5.342983513401123e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=2.4427976086371928e-08, std=4.459360297914827e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=6.92607500241138e-08, std=7.588668813696131e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=5.136075742484536e-07, std=6.434431998059154e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=2.3071322630130453e-09, std=1.86583747563418e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-1.3067154895907152e-06, std=1.9200371752958745e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=6.454660450572192e-08, std=0.0001031749343383126\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-7.55811470298795e-07, std=6.539068272104487e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=5.753495457838653e-10, std=2.166833837691229e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-6.825480909355974e-07, std=2.145228791050613e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-9.81919242803997e-07, std=0.0002672291302587837\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-2.5940662453649566e-06, std=0.0003021984884981066\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=2.0279185264371336e-06, std=0.0003319230454508215\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=6.398835466825403e-06, std=0.0002537764376029372\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.002386485692113638, std=0.005289616994559765\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=-0.00010425884102005512, std=0.005237889010459185\n",
            "Grad stats for input_proj.weight: mean=1.3537917453732007e-08, std=7.101046435309399e-07\n",
            "Grad stats for input_proj.bias: mean=8.515266358699591e-08, std=2.951010628748918e-06\n",
            "Grad stats for output_head.0.weight: mean=-1.362697730655782e-06, std=0.00881073996424675\n",
            "Grad stats for output_head.0.bias: mean=0.0011411791201680899, std=0.00948269572108984\n",
            "Grad stats for output_head.2.weight: mean=0.0001597372320247814, std=0.02363242208957672\n",
            "Grad stats for output_head.2.bias: mean=0.0006951207178644836, std=0.043345704674720764\n",
            "No targets: conf_loss=0.1404455006122589, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=5.293323071531297e-12, std=8.655900884946277e-09\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.670674265596972e-09, std=4.1625231261832596e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=9.105093762284966e-11, std=2.9228866438302248e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-4.161591959928046e-09, std=1.4184364260927396e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-8.119238788240057e-13, std=9.482146623440713e-09\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-2.145067179437632e-10, std=9.915445353669838e-09\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=2.781381513994319e-10, std=2.130797582822197e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=5.340766162653665e-10, std=2.1702305730286753e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=3.3858499337569015e-10, std=5.437299321897626e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.6156028454238367e-09, std=5.026725347079264e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=2.4045281321605216e-09, std=3.037047520138003e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=-3.3629063977969054e-09, std=2.7024429982702713e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=9.029286866801822e-12, std=8.76703083463326e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.937155046429552e-09, std=8.562366105024921e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=1.3522299946444605e-10, std=2.4017259647735045e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.5274114740246887e-09, std=2.0108441844968183e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-6.278116915225951e-12, std=4.857556845649924e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=8.119188876776207e-09, std=4.823893462457818e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=-1.8131982582048067e-09, std=1.4519505953103362e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=-3.75989550605027e-09, std=1.6104816324968851e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=4.903089489971535e-09, std=4.5463670517165156e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.219622316119057e-09, std=4.314688908380049e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-4.616033777438133e-09, std=1.8537946289143292e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=4.77627217776444e-08, std=1.8568712221167516e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=6.09494676950817e-11, std=5.439651431515813e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=5.3812485134585586e-08, std=5.454199936139048e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=5.412275627669771e-10, std=1.5990516430974822e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=5.417131632157179e-09, std=1.4174966054270044e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=7.314149286230531e-13, std=4.5353155542215973e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.4731089237329797e-08, std=4.612868451658869e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=4.7827633409269765e-08, std=1.7559161733515793e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=5.561734894854453e-08, std=1.463377998334181e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-1.187146381198545e-09, std=3.4803483686118852e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-5.1720810745337076e-08, std=3.2580580864305375e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-4.1648183923825854e-07, std=3.434591417317279e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=-1.4282542792898312e-07, std=2.8860826205345802e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-8.284980340667047e-11, std=9.680471521278378e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=5.99459681893677e-08, std=9.700432201498188e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=-9.837081194064012e-08, std=4.624172652256675e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=8.435920904048544e-07, std=2.7182662961422466e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=-1.5087309179762087e-09, std=9.431792022951413e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.5192888440651586e-06, std=8.954250006354414e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=-3.1347092317446368e-06, std=0.00010524422395974398\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=-8.190869266400114e-06, std=0.00011291230475762859\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-5.847847432960407e-07, std=0.00013755467080045491\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=3.790901700995164e-06, std=0.00010663932334864512\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0017618932761251926, std=0.0038367984816432\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=6.184910307638347e-05, std=0.0025629273150116205\n",
            "Grad stats for input_proj.weight: mean=-3.1637950592688924e-10, std=5.02750019393261e-08\n",
            "Grad stats for input_proj.bias: mean=-1.2206813337911626e-09, std=1.4817868532190914e-07\n",
            "Grad stats for output_head.0.weight: mean=5.169895302969962e-07, std=0.003188497619703412\n",
            "Grad stats for output_head.0.bias: mean=-0.0016426306683570147, std=0.0031454251147806644\n",
            "Grad stats for output_head.2.weight: mean=0.00027877488173544407, std=0.00164785236120224\n",
            "Grad stats for output_head.2.bias: mean=0.0012911283411085606, std=0.0029144221916794777\n",
            "Hungarian matching: row_ind=[10 17], col_ind=[0 1]\n",
            "conf_loss: 0.2874770164489746, smooth_l1_loss: 0.002657004864886403, ciou_loss: 0.5846827030181885, box_loss: 0.29366984963417053\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-2.084319349060504e-11, std=7.316102568211136e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=4.850229662345384e-10, std=3.399712227292184e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=-4.828109578802753e-10, std=1.7352753900468088e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=2.999011172732935e-08, std=9.37744971452048e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=-1.2390973663789495e-12, std=5.887093479373107e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=-6.908717486986404e-10, std=6.377410954883089e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-3.9818123798163185e-10, std=1.1860395687790515e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-6.30046681493468e-10, std=1.3744485727329447e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=9.189826677413748e-10, std=3.0342050649778685e-07\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-2.042212265962462e-08, std=3.0290317454273463e-07\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=9.954966628811235e-09, std=1.5611643675583764e-06\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=7.375934529818551e-09, std=1.4911170183040667e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=6.683439218724274e-11, std=4.794033543475962e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=3.0648092064211596e-08, std=4.7667072067270055e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=2.79016321158565e-09, std=1.3006653034608462e-06\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=3.179575713829763e-08, std=1.0342733958168537e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-5.180766926571323e-11, std=2.5535928216413595e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=3.596732511823575e-08, std=2.547026554111653e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=3.819923932724123e-09, std=8.165315534824913e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=7.711817850974967e-09, std=8.918530625123822e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=2.3527192638539418e-08, std=2.2449589778261725e-06\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=5.885244647174659e-08, std=2.3348588911176194e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-3.739767606703026e-08, std=1.0073878002003767e-05\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=7.791324918571263e-08, std=1.1184079085069243e-05\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.9593810868820967e-11, std=3.7453780805662973e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=1.7741031399509666e-07, std=3.850675511785084e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=2.6765377469928353e-08, std=1.1175470717716962e-05\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=2.578121609531081e-07, std=8.388416063098703e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=1.4015877347617334e-10, std=2.8328574899205705e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-2.3458558473521407e-07, std=2.8649346859310754e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=-2.297997099276472e-07, std=1.571994107507635e-05\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-2.670051912900817e-07, std=1.3227052477304824e-05\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=7.008999602930999e-08, std=2.253248567285482e-05\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-6.070379185985075e-07, std=2.071342896670103e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=2.2405411073123105e-06, std=0.0003159447223879397\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=8.391578376176767e-06, std=0.000260673783486709\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=6.148506148662136e-09, std=7.54176071495749e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=-2.9865370834158966e-06, std=7.481832290068269e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=3.027728325832868e-07, std=0.00043785767047666013\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-4.863610683969455e-06, std=0.0002606090565677732\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=4.3378634018154116e-10, std=0.0001035454697557725\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=1.4239649317460135e-06, std=0.00010020450281444937\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=8.399808848480461e-08, std=0.0010827980004251003\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=5.69420080864802e-07, std=0.0012096284190192819\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=7.81212656875141e-06, std=0.0013213696656748652\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=2.8293256036704406e-05, std=0.0010321351001039147\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.0064987135119736195, std=0.03235089033842087\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0013138138456270099, std=0.01879887841641903\n",
            "Grad stats for input_proj.weight: mean=-4.98653962566209e-09, std=3.9771597926119284e-07\n",
            "Grad stats for input_proj.bias: mean=-2.3339650212506058e-08, std=1.1406452813389478e-06\n",
            "Grad stats for output_head.0.weight: mean=3.11425537802279e-06, std=0.0350472666323185\n",
            "Grad stats for output_head.0.bias: mean=-0.007822505198419094, std=0.03598247841000557\n",
            "Grad stats for output_head.2.weight: mean=-0.004803078714758158, std=0.07590889185667038\n",
            "Grad stats for output_head.2.bias: mean=-0.02071288973093033, std=0.1386726051568985\n",
            "No targets: conf_loss=0.12859711050987244, box_loss=0.0\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=2.726338425851349e-11, std=2.914554109167966e-08\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-4.1845300557952214e-09, std=1.6119440715556266e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=9.685946489312869e-12, std=4.631889183315252e-08\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.8981332061684952e-09, std=4.800385795533657e-07\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=9.094764871764305e-14, std=1.1422488732648617e-08\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=6.110567607464645e-11, std=1.4570289863513608e-08\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=1.725918366557444e-11, std=2.047990399489663e-08\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=5.221578724956544e-11, std=4.559440824891681e-08\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-2.2923307696487427e-10, std=8.33695139590418e-08\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=-4.906500983281603e-09, std=9.9278437915018e-08\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=3.679337723383469e-09, std=2.4076564386632526e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=2.0464341332626645e-10, std=2.4220838668043143e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=1.1640503665144575e-11, std=7.166349291765073e-08\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=4.190851665697437e-09, std=7.544675639792331e-08\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=7.54569046135245e-11, std=1.8723690686783812e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.1029356317138195e-09, std=1.6753143938785797e-07\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=-5.700884209147716e-12, std=3.479962629171496e-08\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=6.6337624282653e-09, std=3.5813911836157786e-08\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=4.1073253131962417e-10, std=1.1564614510461979e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=8.165503273538377e-10, std=1.3539704468712443e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=3.0816238449915545e-09, std=3.30756677158206e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=8.299833709202176e-09, std=3.385693787549826e-07\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-1.1011032086116757e-09, std=1.5780721014380106e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=4.021897126449403e-08, std=1.6509717397639179e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=3.994619565683699e-11, std=4.876106913798139e-07\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=4.63385028126595e-08, std=5.028664418205153e-07\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=8.808346829702884e-10, std=1.5152014611885534e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=1.0797522875805043e-08, std=1.2644818525586743e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-3.412103932731725e-12, std=4.1810886841631145e-07\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=1.984160213908126e-08, std=4.29113100608447e-07\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=1.8797157164129885e-09, std=1.511918185315153e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=2.362335216332667e-09, std=1.2958851129951654e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=-6.4706782154644316e-09, std=3.432398443692364e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-8.452713728956951e-08, std=3.055667775697657e-06\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=-3.2065804589365143e-07, std=2.8694968932541087e-05\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=6.05124057528883e-08, std=2.5944314984371886e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-2.6705779254676543e-10, std=8.051096301642247e-06\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=1.947408350133628e-07, std=8.363627785001881e-06\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=2.6520567075749568e-08, std=3.7602560041705146e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-3.174425842189521e-07, std=2.4187871531466953e-05\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=2.368949481024174e-11, std=7.548425401182612e-06\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=7.481869488401571e-07, std=7.4563827183737885e-06\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=4.825791393159307e-07, std=8.914072532206774e-05\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=1.2506293387559708e-06, std=9.919819422066212e-05\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.0828900940396124e-06, std=9.647438855608925e-05\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=1.4181380265654298e-06, std=9.059691365109757e-05\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=-0.001701122848317027, std=0.004029575269669294\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=5.6832461268641055e-05, std=0.0023426369298249483\n",
            "Grad stats for input_proj.weight: mean=1.235815227929038e-09, std=1.4113328461462515e-07\n",
            "Grad stats for input_proj.bias: mean=8.409545948495634e-09, std=5.660399438056629e-07\n",
            "Grad stats for output_head.0.weight: mean=1.5134428394958377e-06, std=0.0029921222012490034\n",
            "Grad stats for output_head.0.bias: mean=-0.001498304307460785, std=0.002875829814001918\n",
            "Grad stats for output_head.2.weight: mean=0.00027343397960066795, std=0.0015852864598855376\n",
            "Grad stats for output_head.2.bias: mean=0.0011894110357388854, std=0.0027048191986978054\n",
            "Hungarian matching: row_ind=[ 3 12 14 17], col_ind=[1 0 2 3]\n",
            "conf_loss: 0.4704414904117584, smooth_l1_loss: 0.00748003926128149, ciou_loss: 0.9632282257080078, box_loss: 0.48535412549972534\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_weight: mean=-5.751665810294071e-11, std=8.1165109122594e-07\n",
            "Grad stats for encoder.layers.0.self_attn.in_proj_bias: mean=-1.313591440066375e-07, std=4.834659648622619e-06\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.weight: mean=1.3564116496667111e-09, std=8.062312986112374e-07\n",
            "Grad stats for encoder.layers.0.self_attn.out_proj.bias: mean=-1.3339655424715602e-07, std=1.0209218089585193e-05\n",
            "Grad stats for encoder.layers.0.linear1.weight: mean=3.5298569622810305e-12, std=1.4649818069756293e-07\n",
            "Grad stats for encoder.layers.0.linear1.bias: mean=2.4226731731857853e-10, std=1.8598515794110426e-07\n",
            "Grad stats for encoder.layers.0.linear2.weight: mean=-7.127997636580119e-10, std=1.8375126842329337e-07\n",
            "Grad stats for encoder.layers.0.linear2.bias: mean=-4.904717521014845e-09, std=6.707793431814935e-07\n",
            "Grad stats for encoder.layers.0.norm1.weight: mean=-4.5420556205044704e-11, std=1.5669918411731487e-06\n",
            "Grad stats for encoder.layers.0.norm1.bias: mean=6.378255790195908e-08, std=1.7960829836738412e-06\n",
            "Grad stats for encoder.layers.0.norm2.weight: mean=-6.984745226645828e-08, std=7.511541753046913e-07\n",
            "Grad stats for encoder.layers.0.norm2.bias: mean=6.293004162216675e-08, std=1.2976612424608902e-06\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_weight: mean=-6.182757777972725e-11, std=2.611325555790245e-07\n",
            "Grad stats for encoder.layers.1.self_attn.in_proj_bias: mean=-3.111342294914721e-08, std=4.3462654275572277e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.weight: mean=-9.39666011667839e-10, std=5.065205073151446e-07\n",
            "Grad stats for encoder.layers.1.self_attn.out_proj.bias: mean=1.1657495413430752e-08, std=1.0055506436401629e-06\n",
            "Grad stats for encoder.layers.1.linear1.weight: mean=1.5181272905451237e-11, std=1.3081886152122024e-07\n",
            "Grad stats for encoder.layers.1.linear1.bias: mean=-1.9167355702620625e-08, std=1.5721884949471132e-07\n",
            "Grad stats for encoder.layers.1.linear2.weight: mean=1.8027167258960475e-10, std=4.0922020616562804e-07\n",
            "Grad stats for encoder.layers.1.linear2.bias: mean=2.3948221183900387e-10, std=6.841717663519375e-07\n",
            "Grad stats for encoder.layers.1.norm1.weight: mean=-1.0407706696469177e-08, std=9.300586043536896e-07\n",
            "Grad stats for encoder.layers.1.norm1.bias: mean=-1.1025321811075628e-07, std=1.69519773862703e-06\n",
            "Grad stats for encoder.layers.1.norm2.weight: mean=-9.34462036639161e-08, std=4.389091373013798e-06\n",
            "Grad stats for encoder.layers.1.norm2.bias: mean=-7.201784057997429e-08, std=6.756563834642293e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_weight: mean=-3.799109291047209e-11, std=1.3002808145756717e-06\n",
            "Grad stats for encoder.layers.2.self_attn.in_proj_bias: mean=-1.3271355214783398e-07, std=2.042738515228848e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.weight: mean=4.709978518313562e-10, std=3.6609626477002166e-06\n",
            "Grad stats for encoder.layers.2.self_attn.out_proj.bias: mean=-1.6163369309651898e-08, std=5.261910700937733e-06\n",
            "Grad stats for encoder.layers.2.linear1.weight: mean=-6.495332049993863e-12, std=1.0931109954981366e-06\n",
            "Grad stats for encoder.layers.2.linear1.bias: mean=-2.6227583660443088e-08, std=1.169020379165886e-06\n",
            "Grad stats for encoder.layers.2.linear2.weight: mean=2.963125922406107e-08, std=6.507965281343786e-06\n",
            "Grad stats for encoder.layers.2.linear2.bias: mean=-2.8425830578271416e-08, std=9.122177289100364e-06\n",
            "Grad stats for encoder.layers.2.norm1.weight: mean=3.2172110309147683e-08, std=7.426630418194691e-06\n",
            "Grad stats for encoder.layers.2.norm1.bias: mean=-3.196630871116213e-07, std=1.29996315081371e-05\n",
            "Grad stats for encoder.layers.2.norm2.weight: mean=3.0302487630251562e-06, std=0.00012048631469951943\n",
            "Grad stats for encoder.layers.2.norm2.bias: mean=3.161476570312516e-06, std=0.0001327330683125183\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_weight: mean=-7.52076345644781e-10, std=3.790130722336471e-05\n",
            "Grad stats for encoder.layers.3.self_attn.in_proj_bias: mean=6.475805207628582e-07, std=4.008498217444867e-05\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.weight: mean=4.5607933429892e-08, std=0.0001895641617011279\n",
            "Grad stats for encoder.layers.3.self_attn.out_proj.bias: mean=-1.8241855741507607e-06, std=0.0001348076038993895\n",
            "Grad stats for encoder.layers.3.linear1.weight: mean=1.7789769657383658e-10, std=3.538357850629836e-05\n",
            "Grad stats for encoder.layers.3.linear1.bias: mean=-2.2149536960114347e-07, std=3.500172169879079e-05\n",
            "Grad stats for encoder.layers.3.linear2.weight: mean=1.0545934401307022e-06, std=0.0004305604670662433\n",
            "Grad stats for encoder.layers.3.linear2.bias: mean=2.680238139873836e-06, std=0.0004983892431482673\n",
            "Grad stats for encoder.layers.3.norm1.weight: mean=-1.3111502994433977e-06, std=0.0004174811765551567\n",
            "Grad stats for encoder.layers.3.norm1.bias: mean=2.874557139875833e-06, std=0.00047109997831285\n",
            "Grad stats for encoder.layers.3.norm2.weight: mean=0.0019232116173952818, std=0.007638485170900822\n",
            "Grad stats for encoder.layers.3.norm2.bias: mean=0.0005948406178504229, std=0.007734929211437702\n",
            "Grad stats for input_proj.weight: mean=-8.599538858788947e-08, std=5.172424607735593e-06\n",
            "Grad stats for input_proj.bias: mean=-5.578866080213629e-07, std=2.1486890545929782e-05\n",
            "Grad stats for output_head.0.weight: mean=-1.9007056835107505e-06, std=0.014539603143930435\n",
            "Grad stats for output_head.0.bias: mean=0.0021507637575268745, std=0.015797574073076248\n",
            "Grad stats for output_head.2.weight: mean=-0.0012107465881854296, std=0.03822046145796776\n",
            "Grad stats for output_head.2.bias: mean=-0.005421200301498175, std=0.07151312381029129\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2870547946.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- Training loop ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_with_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1:02d} | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val mean IoU: {val_iou:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1620501003.py\u001b[0m in \u001b[0;36mtrain_epoch_loader\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mframe_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpred_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3470737772.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mscene_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             output = mod(\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    933\u001b[0m             x = self.norm1(\n\u001b[1;32m    934\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                 \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m             )\n\u001b[1;32m    937\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mis_causal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     ) -> Tensor:\n\u001b[0;32m--> 949\u001b[0;31m         x = self.self_attn(\n\u001b[0m\u001b[1;32m    950\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1378\u001b[0m             )\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1381\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6368\u001b[0m     \u001b[0;31m# reshape q, k, v for multihead attention and make them batch first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6369\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6370\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatic_k\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6372\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualization ---\n",
        "def show_boxes(preds, targets, img_w=640, img_h=480):\n",
        "    fig, ax = plt.subplots()\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "    targets = targets.detach().cpu().numpy()\n",
        "    for (x, y, w, h) in preds:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='r', facecolor='none', linewidth=2))\n",
        "    for (x, y, w, h) in targets:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='g', facecolor='none', linewidth=2))\n",
        "    ax.set_xlim(0, img_w)\n",
        "    ax.set_ylim(img_h, 0)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.show()\n",
        "\n",
        "    # --- Example prediction visualization---\n",
        "X, Y = val_pairs[292]\n",
        "X_enc = encode_objects(X).to(device)\n",
        "pred_boxes, pred_conf = model(X_enc)\n",
        "conf_thresh = 0.5\n",
        "nms_thresh = 0.4\n",
        "keep = pred_conf > conf_thresh\n",
        "pred_boxes = pred_boxes[keep]\n",
        "scores = pred_conf[keep]\n",
        "boxes_xyxy = boxes_cxcywh_to_xyxy(pred_boxes)\n",
        "keep_indices = ciou_nms(boxes_xyxy, scores, nms_thresh)\n",
        "pred_boxes = pred_boxes[keep_indices]\n",
        "target_boxes = Y[Y[:,0]==11][:,1:].to(device)\n",
        "show_boxes(pred_boxes, target_boxes)"
      ],
      "metadata": {
        "id": "2z0JjUsznMYt"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using GIoU #Currently not working"
      ],
      "metadata": {
        "id": "tTLafYM634R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.ops import generalized_box_iou_loss\n",
        "# --- Dataset wrapper ---\n",
        "\n",
        "class PairDataset(Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.pairs[idx]\n",
        "\n",
        "train_dataset = PairDataset(train_pairs)\n",
        "\n",
        "# --- Weighted sampling ---\n",
        "\n",
        "labels = []\n",
        "for _, Y in train_pairs:\n",
        "    has_frame = (Y[:,0] == 11).any().item()\n",
        "    labels.append(1 if has_frame else 0)\n",
        "\n",
        "labels = torch.tensor(labels)\n",
        "class_counts = torch.bincount(labels)\n",
        "weights_per_class = 1. / class_counts.float()\n",
        "sample_weights = weights_per_class[labels]\n",
        "\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, sampler=sampler)\n",
        "\n",
        "# --- Encoding ---\n",
        "\n",
        "def encode_objects(boxes, num_classes=12):\n",
        "    feats = []\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        if cls == 11:\n",
        "            continue\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_classes-1)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "    return torch.stack(feats) if feats else torch.zeros((1, num_classes+3))\n",
        "\n",
        "# --- Model ---\n",
        "\n",
        "class SceneLayoutPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=4, num_pred=20):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=8),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 5 * num_pred)\n",
        "        )\n",
        "        self.num_pred = num_pred\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.encoder(x.unsqueeze(1)).squeeze(1)\n",
        "        scene_feat = x.mean(0)\n",
        "        preds = self.output_head(scene_feat).view(self.num_pred, 5)\n",
        "        boxes = preds[:, :4]\n",
        "        confidences = torch.sigmoid(preds[:, 4])\n",
        "        return boxes, confidences\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SceneLayoutPredictor(input_dim=15, num_pred=20).to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# --- Box format conversion and clamping ---\n",
        "\n",
        "def cxcywh_to_xyxy(clamped_boxes):\n",
        "    cx, cy, w, h = clamped_boxes.unbind(-1)\n",
        "    xmin = cx - 0.5 * w\n",
        "    ymin = cy - 0.5 * h\n",
        "    xmax = cx + 0.5 * w\n",
        "    ymax = cy + 0.5 * h\n",
        "    boxes_xyxy = torch.stack((xmin, ymin, xmax, ymax), dim=-1)\n",
        "    # Clamp to [0,1]\n",
        "    boxes_xyxy = boxes_xyxy.clamp(0.0, 1.0)\n",
        "    return boxes_xyxy\n",
        "\n",
        "def clamp_boxes(boxes, min_val=0.0, max_val=1.0, eps=1e-6):\n",
        "    boxes_clamped = boxes.clone()\n",
        "    boxes_clamped[:, 0] = boxes[:, 0].clamp(min_val, max_val)  # cx\n",
        "    boxes_clamped[:, 1] = boxes[:, 1].clamp(min_val, max_val)  # cy\n",
        "    boxes_clamped[:, 2] = boxes[:, 2].clamp(min=eps)           # w\n",
        "    boxes_clamped[:, 3] = boxes[:, 3].clamp(min=eps)           # h\n",
        "    return boxes_clamped\n",
        "\n",
        "# --- Loss calculation using GIoU and clamping/conversion ---\n",
        "\n",
        "def compute_loss(pred_boxes, pred_conf, target_boxes):\n",
        "    n = min(len(target_boxes), pred_boxes.size(0))\n",
        "    if n == 0:\n",
        "        conf_loss = F.binary_cross_entropy(pred_conf, torch.zeros_like(pred_conf))\n",
        "        box_loss = torch.tensor(0., device=pred_boxes.device)\n",
        "    else:\n",
        "        conf_target = torch.zeros_like(pred_conf)\n",
        "        conf_target[:n] = 1.0\n",
        "        conf_loss = F.binary_cross_entropy(pred_conf, conf_target)\n",
        "\n",
        "        pred_boxes_clamped = clamp_boxes(pred_boxes[:n])\n",
        "        target_boxes_clamped = clamp_boxes(target_boxes[:n])\n",
        "\n",
        "        pred_boxes_xyxy = cxcywh_to_xyxy(pred_boxes_clamped)\n",
        "        target_boxes_xyxy = cxcywh_to_xyxy(target_boxes_clamped)\n",
        "\n",
        "        box_loss = generalized_box_iou_loss(pred_boxes_xyxy, target_boxes_xyxy, reduction=\"mean\")\n",
        "\n",
        "    total_loss = conf_loss + box_loss\n",
        "    assert total_loss.dim() == 0, f\"Loss is not scalar: {total_loss.shape}\"\n",
        "    return total_loss\n",
        "\n",
        "# --- Training loop ---\n",
        "\n",
        "def train_epoch_loader(loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X, Y in loader:\n",
        "        X_enc = encode_objects(X[0]).to(device)\n",
        "        frame_boxes = Y[0][Y[0][:,0] == 11][:, 1:].to(device)\n",
        "        opt.zero_grad()\n",
        "        pred_boxes, pred_conf = model(X_enc)\n",
        "        loss = compute_loss(pred_boxes, pred_conf, frame_boxes)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# --- Evaluation with IoU metric ---\n",
        "\n",
        "iou_metric = IntersectionOverUnion(box_format=\"xyxy\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_with_iou(pairs):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    iou_metric.reset()\n",
        "    for X, Y in pairs:\n",
        "        X_enc = encode_objects(X).to(device)\n",
        "        target_boxes = Y[Y[:,0] == 11][:, 1:].to(device)\n",
        "        pred_boxes, pred_conf = model(X_enc)\n",
        "\n",
        "        conf_thresh = 0.5\n",
        "        nms_thresh = 0.4\n",
        "        keep = pred_conf > conf_thresh\n",
        "        if keep.sum() == 0:\n",
        "            continue\n",
        "        pred_boxes_filtered = pred_boxes[keep]\n",
        "        scores = pred_conf[keep]\n",
        "\n",
        "        pred_boxes_clamped = clamp_boxes(pred_boxes_filtered)\n",
        "        pred_boxes_xyxy = cxcywh_to_xyxy(pred_boxes_clamped)\n",
        "        keep_indices = ops.nms(pred_boxes_xyxy, scores, nms_thresh)\n",
        "        pred_boxes_nms = pred_boxes_filtered[keep_indices]\n",
        "\n",
        "        pred_boxes_nms_clamped = clamp_boxes(pred_boxes_nms)\n",
        "        pred_boxes_nms_xyxy = cxcywh_to_xyxy(pred_boxes_nms_clamped)\n",
        "        target_boxes_clamped = clamp_boxes(target_boxes)\n",
        "        target_boxes_xyxy = cxcywh_to_xyxy(target_boxes_clamped)\n",
        "\n",
        "        preds = [{'boxes': pred_boxes_nms_xyxy, 'labels': torch.zeros(len(pred_boxes_nms_xyxy), dtype=torch.int, device=device)}]\n",
        "        targets = [{'boxes': target_boxes_xyxy, 'labels': torch.zeros(len(target_boxes_xyxy), dtype=torch.int, device=device)}]\n",
        "\n",
        "        iou_metric.update(preds, targets)\n",
        "\n",
        "        loss = compute_loss(pred_boxes_nms, pred_conf[keep][keep_indices], target_boxes)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    mean_iou = iou_metric.compute()['iou'].item()\n",
        "    avg_loss = total_loss / len(pairs)\n",
        "    return avg_loss, mean_iou\n",
        "\n",
        "# --- Visualization omitted, same as before ---\n",
        "\n",
        "# --- Run training ---\n",
        "\n",
        "for epoch in range(20):\n",
        "    train_loss = train_epoch_loader(train_loader)\n",
        "    val_loss, val_iou = evaluate_with_iou(val_pairs)\n",
        "    print(f\"Epoch {epoch+1:02d} | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val mean IoU: {val_iou:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v-RBuMs53on",
        "outputId": "426e0d53-2407-47ea-ffc9-ec09fb5b1557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train loss: 0.8328 | Val loss: 0.9594 | Val mean IoU: 0.0147\n",
            "Epoch 02 | Train loss: 0.7432 | Val loss: 1.2287 | Val mean IoU: 0.0154\n",
            "Epoch 03 | Train loss: 0.7532 | Val loss: 0.7582 | Val mean IoU: 0.0144\n",
            "Epoch 04 | Train loss: 0.7664 | Val loss: 1.1227 | Val mean IoU: 0.0151\n",
            "Epoch 05 | Train loss: 0.7894 | Val loss: 1.0979 | Val mean IoU: 0.0152\n",
            "Epoch 06 | Train loss: 0.7492 | Val loss: 0.1003 | Val mean IoU: 0.0108\n",
            "Epoch 07 | Train loss: 0.7703 | Val loss: 1.2707 | Val mean IoU: 0.0157\n",
            "Epoch 08 | Train loss: 0.7314 | Val loss: 0.0000 | Val mean IoU: 0.0000\n",
            "Epoch 09 | Train loss: 0.7528 | Val loss: 1.2601 | Val mean IoU: 0.0157\n",
            "Epoch 10 | Train loss: 0.7521 | Val loss: 0.0000 | Val mean IoU: 0.0000\n",
            "Epoch 11 | Train loss: 0.7657 | Val loss: 1.2058 | Val mean IoU: 0.0155\n",
            "Epoch 12 | Train loss: 0.7472 | Val loss: 1.2692 | Val mean IoU: 0.0157\n",
            "Epoch 13 | Train loss: 0.7665 | Val loss: 0.4535 | Val mean IoU: 0.0112\n",
            "Epoch 14 | Train loss: 0.7722 | Val loss: 1.2520 | Val mean IoU: 0.0157\n",
            "Epoch 15 | Train loss: 0.7553 | Val loss: 0.0023 | Val mean IoU: 0.2527\n",
            "Epoch 16 | Train loss: 0.7564 | Val loss: 1.2533 | Val mean IoU: 0.0157\n",
            "Epoch 17 | Train loss: 0.7761 | Val loss: 0.0000 | Val mean IoU: 0.0000\n",
            "Epoch 18 | Train loss: 0.7229 | Val loss: 1.2669 | Val mean IoU: 0.0157\n",
            "Epoch 19 | Train loss: 0.7450 | Val loss: 1.2672 | Val mean IoU: 0.0157\n",
            "Epoch 20 | Train loss: 0.7196 | Val loss: 0.0000 | Val mean IoU: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualization ---\n",
        "\n",
        "def show_boxes(preds, targets, img_w=640, img_h=480):\n",
        "    fig, ax = plt.subplots()\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "    targets = targets.detach().cpu().numpy()\n",
        "    for (x, y, w, h) in preds:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='r', facecolor='none', linewidth=2))\n",
        "    for (x, y, w, h) in targets:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='g', facecolor='none', linewidth=2))\n",
        "    ax.set_xlim(0, img_w)\n",
        "    ax.set_ylim(img_h, 0)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.show()\n",
        "\n",
        "# --- Example prediction visualization ---\n",
        "\n",
        "X, Y = val_pairs[291]\n",
        "X_enc = encode_objects(X).to(device)\n",
        "pred_boxes, pred_conf = model(X_enc)\n",
        "conf_thresh = 0.1\n",
        "nms_thresh = 0.4\n",
        "keep = pred_conf > conf_thresh\n",
        "pred_boxes = pred_boxes[keep]\n",
        "scores = pred_conf[keep]\n",
        "\n",
        "pred_boxes_xyxy = boxes_cxcywh_to_xyxy(pred_boxes)\n",
        "keep_indices = ops.nms(pred_boxes_xyxy, scores, nms_thresh)\n",
        "pred_boxes = pred_boxes[keep_indices]\n",
        "\n",
        "target_boxes = Y[Y[:,0] == 11][:, 1:].to(device)\n",
        "show_boxes(pred_boxes, target_boxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "sPVmfd3q4Kl1",
        "outputId": "5e667ba1-8bee-40bc-ef40-7679228dc52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other methods of predictions below. Not really working so pivioted back to above methods."
      ],
      "metadata": {
        "id": "KJDgT2WqCfZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "\n",
        "# === Directory setup ===\n",
        "base_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels\"\n",
        "\n",
        "train_input_dir = f\"{base_dir}/train_input\"\n",
        "train_input_aug_dir = f\"{base_dir}/train_input_aug\"\n",
        "val_input_dir = f\"{base_dir}/val_input\"\n",
        "val_input_aug_dir = f\"{base_dir}/val_input_aug\"\n",
        "\n",
        "train_target_dir = f\"{base_dir}/train\"\n",
        "val_target_dir = f\"{base_dir}/val\"\n",
        "\n",
        "\n",
        "# === Utility: Load YOLO labels ===\n",
        "def load_labels(path):\n",
        "    \"\"\"Load bounding boxes from a YOLO-format label file.\"\"\"\n",
        "    boxes = []\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                if len(parts) > 0:\n",
        "                    print(f\" Skipped bad line in {path}: {parts}\")\n",
        "                continue\n",
        "            cls, xc, yc, w, h = map(float, parts)\n",
        "            boxes.append([int(cls), xc, yc, w, h])\n",
        "    return (\n",
        "        torch.tensor(boxes, dtype=torch.float32)\n",
        "        if boxes\n",
        "        else torch.zeros((0, 5), dtype=torch.float32)\n",
        "    )\n",
        "\n",
        "\n",
        "# === Encode bounding boxes (excluding frames) ===\n",
        "def encode_objects(boxes, num_classes=12):\n",
        "    \"\"\"\n",
        "    Encode bounding boxes as one-hot + spatial features.\n",
        "    Excludes picture frames (class 11).\n",
        "    \"\"\"\n",
        "    feats = []\n",
        "    num_obj_classes = num_classes - 1  # excluding class 11\n",
        "\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        if int(cls) == 11:\n",
        "            continue  # skip frames\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_obj_classes)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "\n",
        "    # Fallback if no non-frame objects\n",
        "    return torch.stack(feats) if feats else torch.zeros((1, num_obj_classes + 4))\n",
        "\n",
        "\n",
        "# === Dataset class for lazy loading ===\n",
        "class FramePlacementDataset(Dataset):\n",
        "    def __init__(self, input_dir, target_dir):\n",
        "        self.input_dir = input_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.files = [f for f in os.listdir(input_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]\n",
        "        target_fname = fname.replace(\"_aug.txt\", \".txt\")\n",
        "        input_path = os.path.join(self.input_dir, fname)\n",
        "        target_path = os.path.join(self.target_dir, target_fname)\n",
        "\n",
        "        X = load_labels(input_path)   # scene without (some) frames\n",
        "        Y = load_labels(target_path)  # full scene with all frames\n",
        "\n",
        "        return X, Y\n",
        "\n",
        "\n",
        "# === Combine normal + augmented datasets (lazy loading) ===\n",
        "train_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(train_input_dir, train_target_dir),\n",
        "    FramePlacementDataset(train_input_aug_dir, train_target_dir)\n",
        "])\n",
        "\n",
        "val_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(val_input_dir, val_target_dir),\n",
        "    FramePlacementDataset(val_input_aug_dir, val_target_dir)\n",
        "])\n",
        "\n",
        "# === Dataloaders ===\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\" Dataloaders ready: {len(train_dataset)} train samples, {len(val_dataset)} val samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFyJOybHjB4Y",
        "outputId": "18be4369-879c-463a-bda1-c57106d8653a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dataloaders ready: 2601 train samples, 477 val samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (X, Y) in enumerate(train_loader):\n",
        "    print(f\"Batch {i}: X shape={X.shape}, Y shape={Y.shape}\")\n",
        "    if i == 2: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqDzmOewkBrb",
        "outputId": "f14aa2a7-ab25-4c88-cb54-187af3320408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0: X shape=torch.Size([1, 9, 5]), Y shape=torch.Size([1, 9, 5])\n",
            "Batch 1: X shape=torch.Size([1, 6, 5]), Y shape=torch.Size([1, 8, 5])\n",
            "Batch 2: X shape=torch.Size([1, 5, 5]), Y shape=torch.Size([1, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "# === DETR-style Transformer for Painting Placement ===\n",
        "class DETRPainting(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=128, nhead=4, num_layers=2, num_queries=10):\n",
        "        super().__init__()\n",
        "        self.num_queries = num_queries\n",
        "\n",
        "        # Encode object features\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        # Learnable slot queries\n",
        "        self.query_embed = nn.Parameter(torch.randn(num_queries, d_model))\n",
        "\n",
        "        # Transformer\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model, nhead=nhead,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Predict presence and bbox\n",
        "        self.pred_class = nn.Linear(d_model, 1)  # presence probability\n",
        "        self.pred_bbox = nn.Linear(d_model, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        enc = self.input_proj(x)  # [B, N, d_model]\n",
        "        queries = self.query_embed.unsqueeze(0).expand(batch_size, -1, -1)  # [B, Q, d_model]\n",
        "        out = self.transformer(enc, queries)\n",
        "        pred_class = torch.sigmoid(self.pred_class(out)).squeeze(-1)\n",
        "        pred_bbox = torch.sigmoid(self.pred_bbox(out))\n",
        "        return pred_class, pred_bbox\n",
        "\n",
        "\n",
        "# === Hungarian Matching ===\n",
        "def hungarian_match(pred_boxes, target_boxes, pred_class, target_presence):\n",
        "    \"\"\"\n",
        "    pred_boxes: [Q,4], pred_class: [Q]\n",
        "    target_boxes: [T,4], target_presence: [T]\n",
        "    Returns matched indices (pred_idx, target_idx)\n",
        "    \"\"\"\n",
        "    if target_boxes.numel() == 0:\n",
        "        return torch.tensor([], dtype=torch.long), torch.tensor([], dtype=torch.long)\n",
        "\n",
        "    # Compute cost matrix: L1 + 1-IoU\n",
        "    cost_bbox = torch.cdist(pred_boxes, target_boxes, p=1)\n",
        "    iou_matrix = torchvision.ops.box_iou(xywh_to_xyxy(pred_boxes), xywh_to_xyxy(target_boxes))\n",
        "    cost_iou = 1 - iou_matrix\n",
        "    # Combine costs\n",
        "    cost_matrix = cost_bbox + cost_iou\n",
        "    # Solve Hungarian\n",
        "    pred_idx, tgt_idx = linear_sum_assignment(cost_matrix.detach().cpu())\n",
        "    return torch.tensor(pred_idx, dtype=torch.long), torch.tensor(tgt_idx, dtype=torch.long)\n",
        "\n",
        "\n",
        "# === Loss ===\n",
        "def detr_painting_loss(pred_class, pred_boxes, target_boxes, target_presence):\n",
        "    \"\"\"\n",
        "    pred_class: [B,Q], pred_boxes: [B,Q,4]\n",
        "    target_boxes: list of tensors [Ti,4], target_presence: list of tensors [Ti]\n",
        "    \"\"\"\n",
        "    batch_size, Q, _ = pred_boxes.shape\n",
        "    total_loss = 0.0\n",
        "    for b in range(batch_size):\n",
        "        pb = pred_boxes[b]\n",
        "        pc = pred_class[b]\n",
        "        tb = target_boxes[b]\n",
        "        tp = target_presence[b]\n",
        "        pred_idx, tgt_idx = hungarian_match(pb, tb, pc, tp)\n",
        "\n",
        "        if len(pred_idx) > 0:\n",
        "            # Classification loss for matched slots\n",
        "            cls_loss = F.binary_cross_entropy(pc[pred_idx], tp[tgt_idx])\n",
        "            # Box loss: L1 + GIoU\n",
        "            bbox_l1 = F.l1_loss(pb[pred_idx], tb[tgt_idx])\n",
        "            bbox_giou = 1 - torch.diag(torchvision.ops.generalized_box_iou(\n",
        "                xywh_to_xyxy(pb[pred_idx]),\n",
        "                xywh_to_xyxy(tb[tgt_idx])\n",
        "            )).mean()\n",
        "            total_loss += cls_loss + bbox_l1 + bbox_giou\n",
        "        else:\n",
        "            total_loss += pc.mean()  # penalize false positives\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "\n",
        "# === Helper xywh -> xyxy ===\n",
        "def xywh_to_xyxy(boxes):\n",
        "    x, y, w, h = boxes.unbind(-1)\n",
        "    return torch.stack([x - w/2, y - h/2, x + w/2, y + h/2], dim=-1)\n"
      ],
      "metadata": {
        "id": "wIn95j_ClngN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model v3"
      ],
      "metadata": {
        "id": "A1TrCCoTl6Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Directories ===\n",
        "base_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels\"\n",
        "\n",
        "train_input_dir = f\"{base_dir}/train_input\"\n",
        "train_input_aug_dir = f\"{base_dir}/train_input_aug\"\n",
        "val_input_dir = f\"{base_dir}/val_input\"\n",
        "val_input_aug_dir = f\"{base_dir}/val_input_aug\"\n",
        "\n",
        "train_target_dir = f\"{base_dir}/train\"\n",
        "val_target_dir = f\"{base_dir}/val\"\n",
        "\n",
        "# === Load YOLO labels ===\n",
        "def load_labels(path):\n",
        "    boxes = []\n",
        "    if not os.path.exists(path):\n",
        "        return torch.zeros((0,5), dtype=torch.float32)\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "            cls, xc, yc, w, h = map(float, parts)\n",
        "            boxes.append([int(cls), xc, yc, w, h])\n",
        "    return torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0,5), dtype=torch.float32)\n",
        "\n",
        "# === Dataset ===\n",
        "class FramePlacementDataset(Dataset):\n",
        "    def __init__(self, input_dir, target_dir):\n",
        "        self.input_dir = input_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.files = [f for f in os.listdir(input_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]\n",
        "        target_fname = fname.replace(\"_aug.txt\", \".txt\")\n",
        "        X = load_labels(os.path.join(self.input_dir, fname))\n",
        "        Y = load_labels(os.path.join(self.target_dir, target_fname))\n",
        "        return X, Y\n",
        "\n",
        "# === Encode objects (skipping frames) ===\n",
        "def encode_objects(boxes, num_classes=12):\n",
        "    feats = []\n",
        "    num_obj_classes = num_classes - 1\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        if int(cls) == 11:  # skip frame\n",
        "            continue\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_obj_classes)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "    if feats:\n",
        "        return torch.stack(feats)\n",
        "    else:\n",
        "        return None  # <-- return None for zero objects\n",
        "\n",
        "# === IoU Loss ===\n",
        "def iou_loss(pred_boxes, target_boxes, eps=1e-6):\n",
        "    pred_xy1 = pred_boxes[..., :2] - pred_boxes[..., 2:] / 2\n",
        "    pred_xy2 = pred_boxes[..., :2] + pred_boxes[..., 2:] / 2\n",
        "    target_xy1 = target_boxes[..., :2] - target_boxes[..., 2:] / 2\n",
        "    target_xy2 = target_boxes[..., :2] + target_boxes[..., 2:] / 2\n",
        "\n",
        "    inter_xy1 = torch.max(pred_xy1, target_xy1)\n",
        "    inter_xy2 = torch.min(pred_xy2, target_xy2)\n",
        "    inter_wh = (inter_xy2 - inter_xy1).clamp(min=0)\n",
        "    inter_area = inter_wh[..., 0] * inter_wh[..., 1]\n",
        "\n",
        "    pred_area = pred_boxes[..., 2] * pred_boxes[..., 3]\n",
        "    target_area = target_boxes[..., 2] * target_boxes[..., 3]\n",
        "\n",
        "    union_area = pred_area + target_area - inter_area + eps\n",
        "    iou = inter_area / union_area\n",
        "    return 1 - iou.mean()\n",
        "\n",
        "# === Transformer model ===\n",
        "class PaintingsTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, nhead, num_layers, num_classes=12):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.decoder = nn.Linear(d_model, 5)  # [cls_prob, xc, yc, w, h]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.encoder(x)  # batch_first=True\n",
        "        out = self.decoder(x)\n",
        "        return out\n",
        "\n",
        "# === Training loop ===\n",
        "def train_val_loop(model, train_loader, val_loader, epochs, lr, device):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "    criterion = iou_loss  # or nn.MSELoss() for initial testing\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for X, Y in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
        "            optimizer.zero_grad()\n",
        "            batch_loss = 0\n",
        "            for xi, yi in zip(X, Y):\n",
        "                xi_enc = encode_objects(xi)\n",
        "                yi_enc = encode_objects(yi)\n",
        "                if xi_enc is None or yi_enc is None:\n",
        "                    continue  # skip zero-object scenes\n",
        "                xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                yi_enc = yi_enc.to(device)\n",
        "                pred = model(xi_enc).squeeze(0)\n",
        "                batch_loss += criterion(pred[:, -4:], yi_enc[:, -4:])\n",
        "            if batch_loss > 0:\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += batch_loss.item()\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X, Y in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
        "                batch_loss = 0\n",
        "                for xi, yi in zip(X, Y):\n",
        "                    xi_enc = encode_objects(xi)\n",
        "                    yi_enc = encode_objects(yi)\n",
        "                    if xi_enc is None or yi_enc is None:\n",
        "                        continue\n",
        "                    xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                    yi_enc = yi_enc.to(device)\n",
        "                    pred = model(xi_enc).squeeze(0)\n",
        "                    batch_loss += criterion(pred[:, -4:], yi_enc[:, -4:])\n",
        "                if batch_loss > 0:\n",
        "                    val_loss += batch_loss.item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}\")\n",
        "    return val_loss\n",
        "\n",
        "# === Data Loaders ===\n",
        "train_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(train_input_dir, train_target_dir),\n",
        "    FramePlacementDataset(train_input_aug_dir, train_target_dir)\n",
        "])\n",
        "val_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(val_input_dir, val_target_dir),\n",
        "    FramePlacementDataset(val_input_aug_dir, val_target_dir)\n",
        "])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# === Model & training ===\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = PaintingsTransformer(input_dim=15, d_model=32, nhead=1, num_layers=1).to(device)\n",
        "\n",
        "train_val_loop(model, train_loader, val_loader, epochs=2, lr=1e-3, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDSU-wIqwMU2",
        "outputId": "0ebad13a-afd5-4aa2-f819-5b0413b8bbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Train]: 100%|| 2601/2601 [11:09<00:00,  3.89it/s]\n",
            "Epoch 1 [Val]: 100%|| 477/477 [06:05<00:00,  1.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2: train_loss=0.7348, val_loss=0.6102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|| 2601/2601 [00:55<00:00, 46.93it/s]\n",
            "Epoch 2 [Val]: 100%|| 477/477 [00:06<00:00, 74.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2: train_loss=0.5869, val_loss=0.5214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5214375742326492"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def show_boxes(preds, targets, img_w=640, img_h=480):\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    preds = preds.detach().cpu()\n",
        "    targets = targets.detach().cpu()\n",
        "\n",
        "    # preds assumed to be [num_objs, 5]: [cls_logit, xc, yc, w, h]\n",
        "    # Convert class logits to class IDs\n",
        "    if preds.shape[1] > 4:\n",
        "        cls_pred = preds[:, 0].argmax(dim=-1)  # if logits for multiple classes\n",
        "        preds = preds[cls_pred==11][:, 1:]    # only class 11\n",
        "    # Else, preds already bbox-only\n",
        "\n",
        "    # Draw predictions\n",
        "    for (x, y, w, h) in preds:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='r', facecolor='none', linewidth=2\n",
        "        ))\n",
        "\n",
        "    # Draw targets\n",
        "    for (x, y, w, h) in targets:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='g', facecolor='none', linewidth=2\n",
        "        ))\n",
        "\n",
        "    ax.set_xlim(0, img_w)\n",
        "    ax.set_ylim(img_h, 0)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.show()\n",
        "X, Y = val_dataset[100]  # or any sample\n",
        "X_enc = encode_objects(X)  # this skips class 11\n",
        "preds = model(X_enc.unsqueeze(0).to(device)).squeeze(0)  # [num_objs, 5]\n",
        "\n",
        "# Targets: only class 11\n",
        "targets = Y[Y[:,0]==11][:,1:]  # [xc,yc,w,h]\n",
        "\n",
        "show_boxes(preds, targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "3BKgmVpZyhKk",
        "outputId": "393b1485-7e7f-4ff8-b277-e2cb3f11b1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#v4"
      ],
      "metadata": {
        "id": "YMJba87d6IcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t5XdvZU47-H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "# === Directories ===\n",
        "base_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels\"\n",
        "\n",
        "train_input_dir = f\"{base_dir}/train_input\"\n",
        "train_input_aug_dir = f\"{base_dir}/train_input_aug\"\n",
        "val_input_dir = f\"{base_dir}/val_input\"\n",
        "val_input_aug_dir = f\"{base_dir}/val_input_aug\"\n",
        "\n",
        "train_target_dir = f\"{base_dir}/train\"\n",
        "val_target_dir = f\"{base_dir}/val\"\n",
        "\n",
        "# === Load YOLO labels ===\n",
        "def load_labels(path):\n",
        "    boxes = []\n",
        "    if not os.path.exists(path):\n",
        "        return torch.zeros((0,5), dtype=torch.float32)\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "            cls, xc, yc, w, h = map(float, parts)\n",
        "            boxes.append([int(cls), xc, yc, w, h])\n",
        "    return torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0,5), dtype=torch.float32)\n",
        "\n",
        "# === Dataset ===\n",
        "class FramePlacementDataset(Dataset):\n",
        "    def __init__(self, input_dir, target_dir):\n",
        "        self.input_dir = input_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.files = [f for f in os.listdir(input_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]\n",
        "        target_fname = fname.replace(\"_aug.txt\", \".txt\")\n",
        "        X = load_labels(os.path.join(self.input_dir, fname))\n",
        "        Y = load_labels(os.path.join(self.target_dir, target_fname))\n",
        "        return X, Y\n",
        "\n",
        "# === Encode all objects ===\n",
        "def encode_objects(boxes, num_classes=12):\n",
        "    feats = []\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_classes)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "    if feats:\n",
        "        return torch.stack(feats)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# === IoU loss for box regression ===\n",
        "def iou_loss(pred_boxes, target_boxes, eps=1e-6):\n",
        "    pred_xy1 = pred_boxes[..., :2] - pred_boxes[..., 2:] / 2\n",
        "    pred_xy2 = pred_boxes[..., :2] + pred_boxes[..., 2:] / 2\n",
        "    target_xy1 = target_boxes[..., :2] - target_boxes[..., 2:] / 2\n",
        "    target_xy2 = target_boxes[..., :2] + target_boxes[..., 2:] / 2\n",
        "\n",
        "    inter_xy1 = torch.max(pred_xy1, target_xy1)\n",
        "    inter_xy2 = torch.min(pred_xy2, target_xy2)\n",
        "    inter_wh = (inter_xy2 - inter_xy1).clamp(min=0)\n",
        "    inter_area = inter_wh[...,0] * inter_wh[...,1]\n",
        "\n",
        "    pred_area = pred_boxes[...,2] * pred_boxes[...,3]\n",
        "    target_area = target_boxes[...,2] * target_boxes[...,3]\n",
        "\n",
        "    union_area = pred_area + target_area - inter_area + eps\n",
        "    iou = inter_area / union_area\n",
        "    return 1 - iou.mean()\n",
        "\n",
        "# === Transformer model ===\n",
        "class PaintingsTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=32, nhead=1, num_layers=1, num_classes=12):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.cls_head = nn.Linear(d_model, num_classes)   # class logits\n",
        "        self.box_head = nn.Linear(d_model, 4)            # bbox regression\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.encoder(x)\n",
        "        cls_logits = self.cls_head(x)\n",
        "        bbox_pred = self.box_head(x)\n",
        "        return cls_logits, bbox_pred\n",
        "\n",
        "# === Hungarian matching loss ===\n",
        "def hungarian_loss(pred_cls_logits, pred_boxes, target_boxes, conf_thresh=0.2):\n",
        "    cls_probs = F.softmax(pred_cls_logits, dim=-1)\n",
        "    pred_mask = cls_probs.max(dim=-1).values > conf_thresh\n",
        "    filtered_pred_boxes = pred_boxes[pred_mask]\n",
        "\n",
        "    if target_boxes.shape[0]==0 or filtered_pred_boxes.shape[0]==0:\n",
        "        return torch.tensor(0., device=pred_boxes.device)\n",
        "\n",
        "    cost_matrix = torch.zeros(filtered_pred_boxes.shape[0], target_boxes.shape[0], device=pred_boxes.device)\n",
        "    for i, p in enumerate(filtered_pred_boxes):\n",
        "        for j, t in enumerate(target_boxes):\n",
        "            cost_matrix[i,j] = iou_loss(p.unsqueeze(0), t.unsqueeze(0))\n",
        "\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_matrix.detach().cpu())\n",
        "    matched_pred = filtered_pred_boxes[row_ind]\n",
        "    matched_target = target_boxes[col_ind].to(filtered_pred_boxes.device)\n",
        "    return iou_loss(matched_pred, matched_target)\n",
        "\n",
        "# === Training loop ===\n",
        "def train_val_loop(model, train_loader, val_loader, epochs, lr, device):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for X, Y in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
        "            optimizer.zero_grad()\n",
        "            batch_loss = 0\n",
        "            for xi, yi in zip(X, Y):\n",
        "                xi_enc = encode_objects(xi)\n",
        "                if xi_enc is None:\n",
        "                    continue\n",
        "                xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                yi_boxes = yi[:,1:].to(device)  # use all targets\n",
        "                cls_logits, bbox_pred = model(xi_enc)\n",
        "                cls_logits = cls_logits.squeeze(0)\n",
        "                bbox_pred = bbox_pred.squeeze(0)\n",
        "                batch_loss += hungarian_loss(cls_logits, bbox_pred, yi_boxes)\n",
        "            if batch_loss > 0:\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += batch_loss.item()\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X, Y in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
        "                batch_loss = 0\n",
        "                for xi, yi in zip(X, Y):\n",
        "                    xi_enc = encode_objects(xi)\n",
        "                    if xi_enc is None:\n",
        "                        continue\n",
        "                    xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                    yi_boxes = yi[:,1:].to(device)\n",
        "                    cls_logits, bbox_pred = model(xi_enc)\n",
        "                    cls_logits = cls_logits.squeeze(0)\n",
        "                    bbox_pred = bbox_pred.squeeze(0)\n",
        "                    batch_loss += hungarian_loss(cls_logits, bbox_pred, yi_boxes)\n",
        "                val_loss += batch_loss.item() if batch_loss>0 else 0\n",
        "        val_loss /= len(val_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}\")\n",
        "\n",
        "# === Visualization ===\n",
        "def show_boxes(cls_logits, bbox_pred, targets, img_w=640, img_h=480, conf_thresh=0.5):\n",
        "    cls_probs = F.softmax(cls_logits, dim=-1)\n",
        "    pred_mask = cls_probs.max(dim=-1).values > conf_thresh\n",
        "    pred_boxes = bbox_pred[pred_mask].detach().cpu()\n",
        "    targets = targets.detach().cpu()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    for (x, y, w, h) in pred_boxes:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='r', facecolor='none', linewidth=2\n",
        "        ))\n",
        "    for (x, y, w, h) in targets[:,1:]:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h, edgecolor='g', facecolor='none', linewidth=2\n",
        "        ))\n",
        "    ax.set_xlim(0, img_w)\n",
        "    ax.set_ylim(img_h, 0)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.show()\n",
        "\n",
        "# === Data Loaders ===\n",
        "train_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(train_input_dir, train_target_dir),\n",
        "    FramePlacementDataset(train_input_aug_dir, train_target_dir)\n",
        "])\n",
        "val_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(val_input_dir, val_target_dir),\n",
        "    FramePlacementDataset(val_input_aug_dir, val_target_dir)\n",
        "])\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# === Model & training ===\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = PaintingsTransformer(input_dim=16, d_model=32, nhead=1, num_layers=1).to(device)\n",
        "\n",
        "# === Train ===\n",
        "train_val_loop(model, train_loader, val_loader, epochs=2, lr=1e-3, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1qtyttZHc0r",
        "outputId": "a522bbc0-ab35-4e50-cd42-430082f931c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Train]: 100%|| 2601/2601 [01:45<00:00, 24.63it/s]\n",
            "Epoch 1 [Val]: 100%|| 477/477 [00:06<00:00, 72.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2: train_loss=0.6636, val_loss=0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|| 2601/2601 [01:13<00:00, 35.60it/s]\n",
            "Epoch 2 [Val]: 100%|| 477/477 [00:06<00:00, 73.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2: train_loss=0.7074, val_loss=0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from contextlib import nullcontext\n",
        "\n",
        "\n",
        "# === Dataset and label loading === (unchanged from before)\n",
        "def load_labels(path):\n",
        "    boxes = []\n",
        "    if not os.path.exists(path):\n",
        "        return torch.zeros((0,5), dtype=torch.float32)\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "            cls, xc, yc, w, h = map(float, parts)\n",
        "            boxes.append([int(cls), xc, yc, w, h])\n",
        "    return torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0,5), dtype=torch.float32)\n",
        "\n",
        "class FramePlacementDataset(Dataset):\n",
        "    def __init__(self, input_dir, target_dir):\n",
        "        self.input_dir = input_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.files = [f for f in os.listdir(input_dir) if f.endswith(\".txt\")]\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]\n",
        "        target_fname = fname.replace(\"_aug.txt\", \".txt\")\n",
        "        X = load_labels(os.path.join(self.input_dir, fname))\n",
        "        Y = load_labels(os.path.join(self.target_dir, target_fname))\n",
        "        return X, Y\n",
        "\n",
        "def encode_input_objects(boxes, num_classes=12):\n",
        "    feats = []\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_classes)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "    if feats:\n",
        "        return torch.stack(feats)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def encode_target_class11(boxes):\n",
        "    class11_boxes = boxes[boxes[:, 0] == 11][:, 1:]\n",
        "    if class11_boxes.shape[0] == 0:\n",
        "        return None\n",
        "    return class11_boxes.float()\n",
        "\n",
        "\n",
        "# === Loss functions and model === (unchanged from before)\n",
        "def iou_loss(pred_boxes, target_boxes, eps=1e-6):\n",
        "    pred_xy1 = pred_boxes[:, :2] - pred_boxes[:, 2:] / 2\n",
        "    pred_xy2 = pred_boxes[:, :2] + pred_boxes[:, 2:] / 2\n",
        "    target_xy1 = target_boxes[:, :2] - target_boxes[:, 2:] / 2\n",
        "    target_xy2 = target_boxes[:, :2] + target_boxes[:, 2:] / 2\n",
        "\n",
        "    inter_min = torch.max(pred_xy1, target_xy1)\n",
        "    inter_max = torch.min(pred_xy2, target_xy2)\n",
        "    inter_wh = (inter_max - inter_min).clamp(min=0)\n",
        "    inter_area = inter_wh[:, 0] * inter_wh[:, 1]\n",
        "\n",
        "    pred_area = pred_boxes[:, 2] * pred_boxes[:, 3]\n",
        "    target_area = target_boxes[:, 2] * target_boxes[:, 3]\n",
        "\n",
        "    union_area = pred_area + target_area - inter_area + eps\n",
        "    iou = inter_area / union_area\n",
        "    return 1 - iou.mean()\n",
        "\n",
        "def combined_hungarian_loss(pred_boxes, target_boxes, l1_weight=10.0):\n",
        "    if target_boxes is None or pred_boxes.shape[0] == 0:\n",
        "        return torch.tensor(0., device=pred_boxes.device, requires_grad=True)\n",
        "    cost_matrix = torch.zeros(pred_boxes.shape[0], target_boxes.shape[0], device=pred_boxes.device)\n",
        "    for i, p in enumerate(pred_boxes):\n",
        "        for j, t in enumerate(target_boxes):\n",
        "            iou_comp = 1 - (1 - iou_loss(p.unsqueeze(0), t.unsqueeze(0)))  # IoU itself\n",
        "            l1_comp = F.l1_loss(p, t, reduction='mean')\n",
        "            cost_matrix[i, j] = (1 - iou_comp) + l1_weight * l1_comp\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_matrix.detach().cpu().numpy())\n",
        "    matched_pred = pred_boxes[row_ind]\n",
        "    matched_target = target_boxes[col_ind].to(pred_boxes.device)\n",
        "    return iou_loss(matched_pred, matched_target) + l1_weight * F.l1_loss(matched_pred, matched_target)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=500):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n",
        "\n",
        "class PaintingsTransformer(nn.Module):\n",
        "    def __init__(self, input_dim=16, d_model=64, nhead=4, num_layers=4, dropout=0.2, max_len=100):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.box_head = nn.Linear(d_model, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.pos_enc(x)\n",
        "        x = self.encoder(x)\n",
        "        bbox_pred = self.box_head(x)\n",
        "        return bbox_pred\n",
        "\n",
        "# === Metrics calculation functions ===\n",
        "def box_iou(box1, box2, eps=1e-7):\n",
        "    box1_xy1 = box1[:, :2] - box1[:, 2:] / 2\n",
        "    box1_xy2 = box1[:, :2] + box1[:, 2:] / 2\n",
        "    box2_xy1 = box2[:, :2] - box2[:, 2:] / 2\n",
        "    box2_xy2 = box2[:, :2] + box2[:, 2:] / 2\n",
        "\n",
        "    inter_xy1 = torch.max(box1_xy1[:, None, :], box2_xy1[None, :, :])\n",
        "    inter_xy2 = torch.min(box1_xy2[:, None, :], box2_xy2[None, :, :])\n",
        "    inter_wh = (inter_xy2 - inter_xy1).clamp(min=0)\n",
        "    inter_area = inter_wh[:, :, 0] * inter_wh[:, :, 1]\n",
        "\n",
        "    box1_area = box1[:, 2] * box1[:, 3]\n",
        "    box2_area = box2[:, 2] * box2[:, 3]\n",
        "\n",
        "    union_area = box1_area[:, None] + box2_area[None, :] - inter_area + eps\n",
        "    iou = inter_area / union_area\n",
        "    return iou\n",
        "\n",
        "def precision_recall_f1(pred_boxes, target_boxes, iou_thresh=0.5):\n",
        "    if pred_boxes is None or target_boxes is None or (pred_boxes.shape[0] == 0 and target_boxes.shape[0] == 0):\n",
        "        return 1.0, 1.0, 1.0\n",
        "    elif pred_boxes is None or pred_boxes.shape[0] == 0:\n",
        "        return 0.0, 0.0, 0.0\n",
        "    elif target_boxes is None or target_boxes.shape[0] == 0:\n",
        "        return 0.0, 1.0, 0.0\n",
        "\n",
        "    ious = box_iou(pred_boxes, target_boxes)  # (num_pred, num_target)\n",
        "    matches = ious > iou_thresh\n",
        "\n",
        "    true_positives = matches.any(dim=1).sum().item()\n",
        "    false_positives = (matches.any(dim=1) == 0).sum().item()\n",
        "    false_negatives = (matches.any(dim=0) == 0).sum().item()\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives + 1e-7)\n",
        "    recall = true_positives / (true_positives + false_negatives + 1e-7)\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-7)\n",
        "    return precision, recall, f1\n",
        "\n",
        "\n",
        "# === LR Warmup scheduler helper ===\n",
        "def get_warmup_scheduler(optimizer, warmup_steps):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step >= warmup_steps:\n",
        "            return 1.0\n",
        "        else:\n",
        "            return float(current_step) / float(max(1, warmup_steps))\n",
        "    return LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "\n",
        "# === Training + validation with metrics and early stopping ===\n",
        "def train_val_loop(model, train_loader, val_loader, epochs, lr, warmup_steps, device):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    warmup_scheduler = get_warmup_scheduler(optimizer, warmup_steps)\n",
        "    plateau_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "    model.to(device)\n",
        "\n",
        "    scaler = GradScaler() if torch.cuda.is_available() else None\n",
        "    autocast_context = autocast if torch.cuda.is_available() else nullcontext\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    patience = 3\n",
        "    trigger_times = 0\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for X, Y in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
        "            optimizer.zero_grad()\n",
        "            batch_loss = 0\n",
        "            for xi, yi in zip(X, Y):\n",
        "                xi_enc = encode_input_objects(xi)\n",
        "                if xi_enc is None:\n",
        "                    continue\n",
        "                xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                yi_enc = encode_target_class11(yi)\n",
        "                if yi_enc is None:\n",
        "                    continue\n",
        "                yi_enc = yi_enc.to(device)\n",
        "                with autocast_context():\n",
        "                    bbox_pred = model(xi_enc).squeeze(0)\n",
        "                    loss = combined_hungarian_loss(bbox_pred, yi_enc)\n",
        "                if loss > 0:\n",
        "                    if scaler is not None:\n",
        "                        scaler.scale(loss).backward()\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "                    else:\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    batch_loss += loss.item()\n",
        "                else:\n",
        "                    batch_loss += loss.item()\n",
        "                if global_step < warmup_steps:\n",
        "                    warmup_scheduler.step()\n",
        "                global_step += 1\n",
        "            train_loss += batch_loss\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_precisions, all_recalls, all_f1s = [], [], []\n",
        "        with torch.no_grad():\n",
        "            for X, Y in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
        "                batch_loss = 0\n",
        "                for xi, yi in zip(X, Y):\n",
        "                    xi_enc = encode_input_objects(xi)\n",
        "                    if xi_enc is None:\n",
        "                        continue\n",
        "                    xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                    yi_enc = encode_target_class11(yi)\n",
        "                    if yi_enc is None:\n",
        "                        continue\n",
        "                    yi_enc = yi_enc.to(device)\n",
        "                    with autocast_context():\n",
        "                        bbox_pred = model(xi_enc).squeeze(0)\n",
        "                        loss = combined_hungarian_loss(bbox_pred, yi_enc)\n",
        "                    batch_loss += loss.item()\n",
        "\n",
        "                    # Calculate metrics (clamp boxes to [0,1] for IoU)\n",
        "                    pred_boxes = bbox_pred.clamp(0, 1).cpu()\n",
        "                    target_boxes = yi_enc.cpu()\n",
        "                    prec, rec, f1 = precision_recall_f1(pred_boxes, target_boxes)\n",
        "                    all_precisions.append(prec)\n",
        "                    all_recalls.append(rec)\n",
        "                    all_f1s.append(f1)\n",
        "                val_loss += batch_loss\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        mean_prec = sum(all_precisions) / len(all_precisions) if all_precisions else 0\n",
        "        mean_rec = sum(all_recalls) / len(all_recalls) if all_recalls else 0\n",
        "        mean_f1 = sum(all_f1s) / len(all_f1s) if all_f1s else 0\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}: train_loss={train_loss:.6f}, val_loss={val_loss:.6f}, \"\n",
        "              f\"val_Precision={mean_prec:.4f}, val_Recall={mean_rec:.4f}, val_F1={mean_f1:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            trigger_times = 0\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # LR scheduler step after warmup\n",
        "        if global_step >= warmup_steps:\n",
        "            plateau_scheduler.step(val_loss)\n",
        "\n",
        "    # Load best model weights after training completes/early stopping\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "# === DataLoader setup ===\n",
        "base_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels\"\n",
        "train_input_dir = f\"{base_dir}/train_input\"\n",
        "train_input_aug_dir = f\"{base_dir}/train_input_aug\"\n",
        "val_input_dir = f\"{base_dir}/val_input\"\n",
        "val_input_aug_dir = f\"{base_dir}/val_input_aug\"\n",
        "train_target_dir = f\"{base_dir}/train\"\n",
        "val_target_dir = f\"{base_dir}/val\"\n",
        "\n",
        "num_workers = 2\n",
        "pin_memory = torch.cuda.is_available()\n",
        "\n",
        "train_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(train_input_dir, train_target_dir),\n",
        "    FramePlacementDataset(train_input_aug_dir, train_target_dir)\n",
        "])\n",
        "val_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(val_input_dir, val_target_dir),\n",
        "    FramePlacementDataset(val_input_aug_dir, val_target_dir)\n",
        "])\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = PaintingsTransformer(input_dim=16, d_model=64, nhead=4, num_layers=4, dropout=0.2).to(device)\n",
        "\n",
        "warmup_steps = 1000\n",
        "\n",
        "# Start training\n",
        "train_val_loop(model, train_loader, val_loader, epochs=10, lr=1e-3, warmup_steps=warmup_steps, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xi1j9Rwbaa8",
        "outputId": "d203f1c9-8880-4e39-d640-a3979be981d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Train]: 100%|| 2601/2601 [01:35<00:00, 27.14it/s]\n",
            "Epoch 1 [Val]: 100%|| 477/477 [00:10<00:00, 45.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: train_loss=1.166032, val_loss=1.409517, val_Precision=0.0064, val_Recall=0.0068, val_F1=0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|| 2601/2601 [01:35<00:00, 27.14it/s]\n",
            "Epoch 2 [Val]: 100%|| 477/477 [00:10<00:00, 43.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: train_loss=1.024541, val_loss=1.256212, val_Precision=0.0106, val_Recall=0.0070, val_F1=0.0084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Train]: 100%|| 2601/2601 [01:40<00:00, 25.93it/s]\n",
            "Epoch 3 [Val]: 100%|| 477/477 [00:10<00:00, 44.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: train_loss=1.013722, val_loss=1.297500, val_Precision=0.0088, val_Recall=0.0077, val_F1=0.0073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Train]: 100%|| 2601/2601 [01:36<00:00, 27.08it/s]\n",
            "Epoch 4 [Val]: 100%|| 477/477 [00:10<00:00, 45.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: train_loss=1.006586, val_loss=1.425765, val_Precision=0.0141, val_Recall=0.0103, val_F1=0.0119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Train]: 100%|| 2601/2601 [01:37<00:00, 26.58it/s]\n",
            "Epoch 5 [Val]: 100%|| 477/477 [00:09<00:00, 49.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10: train_loss=1.009543, val_loss=1.325693, val_Precision=0.0141, val_Recall=0.0115, val_F1=0.0125\n",
            "Early stopping at epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_boxes(bbox_pred, targets, img_w=640, img_h=480):\n",
        "    \"\"\"\n",
        "    bbox_pred: [num_pred, 4] - predicted boxes (xc, yc, w, h, normalized)\n",
        "    targets: [num_target, 5] - target boxes (cls, xc, yc, w, h)\n",
        "    \"\"\"\n",
        "\n",
        "    pred_boxes = bbox_pred.detach().cpu()\n",
        "    target_boxes = targets[targets[:, 0] == 11][:, 1:].detach().cpu()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Red = predicted boxes (all assumed class 11)\n",
        "    for (x, y, w, h) in pred_boxes:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h,\n",
        "            edgecolor='r', facecolor='none', linewidth=2\n",
        "        ))\n",
        "\n",
        "    # Green = ground truth boxes class 11\n",
        "    for (x, y, w, h) in target_boxes:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h,\n",
        "            edgecolor='g', facecolor='none', linewidth=2\n",
        "        ))\n",
        "\n",
        "    ax.set_xlim(0, img_w)\n",
        "    ax.set_ylim(img_h, 0)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "X, Y = val_dataset[14]\n",
        "X_enc = encode_input_objects(X)\n",
        "if X_enc is not None:\n",
        "    bbox_pred = model(X_enc.unsqueeze(0).to(device)).squeeze(0)\n",
        "    show_boxes(bbox_pred, Y, img_w=640, img_h=480)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "1RCx1SsdRV2L",
        "outputId": "834470ce-00ef-458c-c4d6-8429c9ef5142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_boxes(cls_logits, bbox_pred, targets, img_w=640, img_h=480, conf_thresh=0.1):\n",
        "    \"\"\"\n",
        "    cls_logits: [num_pred, 12] - class logits\n",
        "    bbox_pred: [num_pred, 4] - predicted boxes (xc, yc, w, h, normalized)\n",
        "    targets: [num_target, 5] - target boxes (cls, xc, yc, w, h)\n",
        "    \"\"\"\n",
        "    cls_probs = F.softmax(cls_logits, dim=-1)\n",
        "\n",
        "    # Only keep predictions where class 11 probability > conf_thresh\n",
        "    pred_mask = cls_probs[:, 11] > conf_thresh\n",
        "    pred_boxes = bbox_pred[pred_mask].detach().cpu()\n",
        "\n",
        "    # Keep only target boxes of class 11\n",
        "    target_boxes = targets[targets[:,0] == 11][:, 1:].detach().cpu()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Red = predictions\n",
        "    for (x, y, w, h) in pred_boxes:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h,\n",
        "            edgecolor='r', facecolor='none', linewidth=2\n",
        "        ))\n",
        "\n",
        "    # Green = targets\n",
        "    for (x, y, w, h) in target_boxes:\n",
        "        ax.add_patch(patches.Rectangle(\n",
        "            ((x - w/2) * img_w, (y - h/2) * img_h),\n",
        "            w * img_w, h * img_h,\n",
        "            edgecolor='g', facecolor='none', linewidth=2\n",
        "        ))\n",
        "\n",
        "    ax.set_xlim(0, img_w)\n",
        "    ax.set_ylim(img_h, 0)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "F36lvrraA-im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = val_dataset[20]\n",
        "X_enc = encode_objects(X)\n",
        "if X_enc is not None:\n",
        "    cls_logits, bbox_pred = model(X_enc.unsqueeze(0).to(device))\n",
        "    cls_logits = cls_logits.squeeze(0)\n",
        "    bbox_pred = bbox_pred.squeeze(0)\n",
        "    show_boxes(cls_logits, bbox_pred, Y, conf_thresh=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "gtfIzzMqBANJ",
        "outputId": "ee9fdbd2-c4c0-4de2-a9b2-4d5a8c7e1e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2291515925.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_enc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcls_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcls_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbbox_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fixed code with everything that was deleted restored (I hope)----------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "_KOriUm6SsHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FIXED CODE HERE"
      ],
      "metadata": {
        "id": "CV-imyCZTppb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, WeightedRandomSampler\n",
        "import itertools\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from contextlib import nullcontext\n",
        "import matplotlib.patches as patches\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "# === Dataset and label loading ===\n",
        "\n",
        "def load_labels(path):\n",
        "    boxes = []\n",
        "    if not os.path.exists(path):\n",
        "        return torch.zeros((0,5), dtype=torch.float32)\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "            cls, xc, yc, w, h = map(float, parts)\n",
        "            boxes.append([int(cls), xc, yc, w, h])\n",
        "    return torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0,5), dtype=torch.float32)\n",
        "\n",
        "class FramePlacementDataset(Dataset):\n",
        "    def __init__(self, input_dir, target_dir):\n",
        "        self.input_dir = input_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.files = [f for f in os.listdir(input_dir) if f.endswith(\".txt\")]\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]\n",
        "        target_fname = fname.replace(\"_aug.txt\", \".txt\")\n",
        "        X = load_labels(os.path.join(self.input_dir, fname))\n",
        "        Y = load_labels(os.path.join(self.target_dir, target_fname))\n",
        "        return X, Y\n",
        "\n",
        "def encode_input_objects(boxes, num_classes=12):\n",
        "    feats = []\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_classes)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "    if feats:\n",
        "        return torch.stack(feats)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def encode_target_class11(boxes):\n",
        "    class11_boxes = boxes[boxes[:, 0] == 11][:, 1:]\n",
        "    if class11_boxes.shape[0] == 0:\n",
        "        return None\n",
        "    return class11_boxes.float()\n",
        "\n",
        "# === Loss functions ===\n",
        "\n",
        "def iou_loss(pred_boxes, target_boxes, eps=1e-6):\n",
        "    pred_xy1 = pred_boxes[:, :2] - pred_boxes[:, 2:] / 2\n",
        "    pred_xy2 = pred_boxes[:, :2] + pred_boxes[:, 2:] / 2\n",
        "    target_xy1 = target_boxes[:, :2] - target_boxes[:, 2:] / 2\n",
        "    target_xy2 = target_boxes[:, :2] + target_boxes[:, 2:] / 2\n",
        "\n",
        "    inter_min = torch.max(pred_xy1, target_xy1)\n",
        "    inter_max = torch.min(pred_xy2, target_xy2)\n",
        "    inter_wh = (inter_max - inter_min).clamp(min=0)\n",
        "    inter_area = inter_wh[:, 0] * inter_wh[:, 1]\n",
        "\n",
        "    pred_area = pred_boxes[:, 2] * pred_boxes[:, 3]\n",
        "    target_area = target_boxes[:, 2] * target_boxes[:, 3]\n",
        "\n",
        "    union_area = pred_area + target_area - inter_area + eps\n",
        "    iou = inter_area / union_area\n",
        "    return 1 - iou.mean()\n",
        "\n",
        "def combined_hungarian_loss(pred_boxes, target_boxes, l1_weight=10.0):\n",
        "    \"\"\"\n",
        "    pred_boxes: Tensor of shape (N_pred, 4)\n",
        "    target_boxes: Tensor of shape (N_target, 4)\n",
        "\n",
        "    Computes Hungarian matching loss combining IoU and L1 loss.\n",
        "    This version vectorizes cost matrix computation using torch.cdist\n",
        "    and performs optimal matching with scipy's linear_sum_assignment.\n",
        "    \"\"\"\n",
        "    if target_boxes is None or pred_boxes.shape[0] == 0:\n",
        "        return torch.tensor(0., device=pred_boxes.device, requires_grad=True)\n",
        "\n",
        "    # Calculate L1 cost matrix (shape: N_pred x N_target)\n",
        "    l1_cost = torch.cdist(pred_boxes, target_boxes, p=1)  # pairwise L1 distance\n",
        "\n",
        "    # Calculate IoU cost matrix\n",
        "    # For vectorized IoU, compute pairwise IoU between all pred and target boxes\n",
        "    pred_xy1 = pred_boxes[:, :2] - pred_boxes[:, 2:] / 2\n",
        "    pred_xy2 = pred_boxes[:, :2] + pred_boxes[:, 2:] / 2\n",
        "    target_xy1 = target_boxes[:, :2] - target_boxes[:, 2:] / 2\n",
        "    target_xy2 = target_boxes[:, :2] + target_boxes[:, 2:] / 2\n",
        "\n",
        "    inter_min = torch.max(pred_xy1[:, None, :], target_xy1[None, :, :])\n",
        "    inter_max = torch.min(pred_xy2[:, None, :], target_xy2[None, :, :])\n",
        "    inter_wh = (inter_max - inter_min).clamp(min=0)  # shape (N_pred x N_target x 2)\n",
        "    inter_area = inter_wh[..., 0] * inter_wh[..., 1]\n",
        "\n",
        "    pred_area = (pred_boxes[:, 2] * pred_boxes[:, 3])[:, None]  # (N_pred, 1)\n",
        "    target_area = (target_boxes[:, 2] * target_boxes[:, 3])[None, :]  # (1, N_target)\n",
        "\n",
        "    union_area = pred_area + target_area - inter_area + 1e-6\n",
        "    iou_cost = 1 - (inter_area / union_area)  # IoU cost matrix\n",
        "\n",
        "    # Combine costs: IoU + weighted L1\n",
        "    cost_matrix = iou_cost + l1_weight * l1_cost\n",
        "\n",
        "    # Solve assignment using Hungarian algorithm (in numpy)\n",
        "    cost_cpu = cost_matrix.detach().cpu().numpy()\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_cpu)\n",
        "\n",
        "    matched_pred = pred_boxes[row_ind]\n",
        "    matched_target = target_boxes[col_ind].to(pred_boxes.device)\n",
        "\n",
        "    # Compute final loss: IoU loss + weighted L1 loss on matched pairs\n",
        "    loss = (iou_cost[row_ind, col_ind]).mean() + l1_weight * F.l1_loss(matched_pred, matched_target)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# === Positional Encoding ===\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=500):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n",
        "\n",
        "# === PaintingsTransformer Model ===\n",
        "\n",
        "class PaintingsTransformer(nn.Module):\n",
        "    def __init__(self, input_dim=16, d_model=64, nhead=4, num_layers=4, dropout=0.2, max_len=100):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.box_head = nn.Linear(d_model, 4)\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.pos_enc(x)\n",
        "        x = self.encoder(x)\n",
        "        bbox_pred = self.box_head(x)\n",
        "        return bbox_pred\n",
        "\n",
        "# === Training/validation loop (with warmup, early stop, mixed precision) ===\n",
        "\n",
        "def get_warmup_scheduler(optimizer, warmup_steps):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step >= warmup_steps:\n",
        "            return 1.0\n",
        "        else:\n",
        "            return float(current_step) / float(max(1, warmup_steps))\n",
        "    return LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "def train_val_loop(model, train_loader, val_loader, epochs, lr, warmup_steps, device):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    warmup_scheduler = get_warmup_scheduler(optimizer, warmup_steps)\n",
        "    plateau_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "    model.to(device)\n",
        "\n",
        "    scaler = GradScaler() if torch.cuda.is_available() else None\n",
        "    autocast_context = autocast if torch.cuda.is_available() else nullcontext\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    patience = 3\n",
        "    trigger_times = 0\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for X, Y in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
        "            optimizer.zero_grad()\n",
        "            batch_loss = 0\n",
        "            for xi, yi in zip(X, Y):\n",
        "                xi_enc = encode_input_objects(xi)\n",
        "                if xi_enc is None:\n",
        "                    continue\n",
        "                xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                yi_enc = encode_target_class11(yi)\n",
        "                if yi_enc is None:\n",
        "                    continue\n",
        "                yi_enc = yi_enc.to(device)\n",
        "                with autocast_context():\n",
        "                    bbox_pred = model(xi_enc).squeeze(0)\n",
        "                    loss = combined_hungarian_loss(bbox_pred, yi_enc)\n",
        "                if loss > 0:\n",
        "                    if scaler is not None:\n",
        "                        scaler.scale(loss).backward()\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "                    else:\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    batch_loss += loss.item()\n",
        "                else:\n",
        "                    batch_loss += loss.item()\n",
        "                if global_step < warmup_steps:\n",
        "                    warmup_scheduler.step()\n",
        "                global_step += 1\n",
        "            train_loss += batch_loss\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X, Y in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
        "                batch_loss = 0\n",
        "                for xi, yi in zip(X, Y):\n",
        "                    xi_enc = encode_input_objects(xi)\n",
        "                    if xi_enc is None:\n",
        "                        continue\n",
        "                    xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                    yi_enc = encode_target_class11(yi)\n",
        "                    if yi_enc is None:\n",
        "                        continue\n",
        "                    yi_enc = yi_enc.to(device)\n",
        "                    with autocast_context():\n",
        "                        bbox_pred = model(xi_enc).squeeze(0)\n",
        "                        loss = combined_hungarian_loss(bbox_pred, yi_enc)\n",
        "                    batch_loss += loss.item()\n",
        "                val_loss += batch_loss\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}: train_loss={train_loss:.6f}, val_loss={val_loss:.6f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            trigger_times = 0\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        if global_step >= warmup_steps:\n",
        "            plateau_scheduler.step(val_loss)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "# === Hyperparameter grid search ===\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "def evaluate_val_loss(model, val_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for X, Y in val_loader:\n",
        "            for xi, yi in zip(X, Y):\n",
        "                xi_enc = encode_input_objects(xi)\n",
        "                if xi_enc is None:\n",
        "                    continue\n",
        "                xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                yi_enc = encode_target_class11(yi)\n",
        "                if yi_enc is None:\n",
        "                    continue\n",
        "                yi_enc = yi_enc.to(device)\n",
        "                bbox_pred = model(xi_enc).squeeze(0)\n",
        "                loss = combined_hungarian_loss(bbox_pred, yi_enc)\n",
        "                total_loss += loss.item()\n",
        "                count += 1\n",
        "    return total_loss / max(count,1)\n",
        "\n",
        "def grid_search(param_grid, train_dataset, val_dataset, device, epochs=3, warmup_steps=100, log_csv_path=\"grid_search_log.csv\"):\n",
        "    keys = list(param_grid.keys())\n",
        "    best_val_loss = float('inf')\n",
        "    best_params = None\n",
        "    best_model_wts = None\n",
        "\n",
        "    def has_class_11(sample):\n",
        "        X, Y = sample\n",
        "        return (Y[:,0] == 11).any().item()\n",
        "\n",
        "    sample_weights = []\n",
        "    for i in range(len(train_dataset)):\n",
        "        sample = train_dataset[i]\n",
        "        sample_weights.append(5.0 if has_class_11(sample) else 1.0) # Oversample class 11 by 5x\n",
        "\n",
        "    sample_weights = torch.DoubleTensor(sample_weights)\n",
        "    train_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "    with open(log_csv_path, mode='w', newline='') as log_file:\n",
        "        writer = csv.writer(log_file)\n",
        "        writer.writerow(keys + [\"val_loss\"])\n",
        "\n",
        "        for values in itertools.product(*param_grid.values()):\n",
        "            params = dict(zip(keys, values))\n",
        "            print(f\"\\nTesting params: {params}\")\n",
        "\n",
        "            train_loader = DataLoader(train_dataset,\n",
        "                                      batch_size=params['batch_size'],\n",
        "                                      sampler=train_sampler,\n",
        "                                      num_workers=4,\n",
        "                                      pin_memory=torch.cuda.is_available(),\n",
        "                                      collate_fn=collate_fn)\n",
        "            val_loader = DataLoader(val_dataset,\n",
        "                                    batch_size=params['batch_size'],\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=4,\n",
        "                                    pin_memory=torch.cuda.is_available(),\n",
        "                                    collate_fn=collate_fn)\n",
        "            model = PaintingsTransformer(input_dim=16, d_model=params['d_model'],\n",
        "                                         nhead=4, num_layers=params['num_layers'], dropout=0.2).to(device)\n",
        "            train_val_loop(model, train_loader, val_loader, epochs=epochs, lr=params['lr'], warmup_steps=warmup_steps, device=device)\n",
        "            val_loss = evaluate_val_loss(model, val_loader, device)\n",
        "            print(f\"Validation loss: {val_loss:.6f}\")\n",
        "            writer.writerow(list(values) + [val_loss])\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_params = params\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(\"\\nBest hyperparameters found:\", best_params)\n",
        "    torch.save(best_model_wts, \"best_model.pth\")\n",
        "    print(\"Best model saved as 'best_model.pth'\")\n",
        "    return best_params, best_model_wts\n",
        "\n",
        "# === Dataset and DataLoader Setup ===\n",
        "\n",
        "base_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels\"\n",
        "train_input_dir = f\"{base_dir}/train_input\"\n",
        "train_input_aug_dir = f\"{base_dir}/train_input_aug\"\n",
        "val_input_dir = f\"{base_dir}/val_input\"\n",
        "val_input_aug_dir = f\"{base_dir}/val_input_aug\"\n",
        "train_target_dir = f\"{base_dir}/train\"\n",
        "val_target_dir = f\"{base_dir}/val\"\n",
        "\n",
        "num_workers = 4\n",
        "pin_memory = torch.cuda.is_available()\n",
        "\n",
        "train_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(train_input_dir, train_target_dir),\n",
        "    FramePlacementDataset(train_input_aug_dir, train_target_dir)\n",
        "])\n",
        "val_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(val_input_dir, val_target_dir),\n",
        "    FramePlacementDataset(val_input_aug_dir, val_target_dir)\n",
        "])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "param_grid = {\n",
        "    'lr': [1e-4, 1e-3],\n",
        "    'batch_size': [1, 4],\n",
        "    'num_layers': [3, 4],\n",
        "    'd_model': [64, 128]\n",
        "}\n",
        "\n",
        "# Run grid search to find best hyperparameters\n",
        "best_params, best_weights = grid_search(param_grid, train_dataset, val_dataset, device, epochs=5, warmup_steps=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "0t5y3ovpTjpb",
        "outputId": "9e2da49b-2983-4ba8-d992-456af70f025a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-392781965.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;31m# Run grid search to find best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m \u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-392781965.py\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(param_grid, train_dataset, val_dataset, device, epochs, warmup_steps, log_csv_path)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0msample_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_class_11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Oversample class 11 by 5x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-392781965.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtarget_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_aug.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-392781965.py\u001b[0m in \u001b[0;36mload_labels\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skipping param search to run with best ones"
      ],
      "metadata": {
        "id": "Y8Hzon79T8MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "\n",
        "# --- Dataset class as per your setup ---\n",
        "\n",
        "class FramePlacementDataset(Dataset):\n",
        "    def __init__(self, input_dir, target_dir):\n",
        "        self.input_dir = input_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.files = [f for f in os.listdir(input_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]\n",
        "        target_fname = fname.replace(\"_aug.txt\", \".txt\")\n",
        "        X = self.load_labels(os.path.join(self.input_dir, fname))\n",
        "        Y = self.load_labels(os.path.join(self.target_dir, target_fname))\n",
        "        return X, Y\n",
        "\n",
        "    @staticmethod\n",
        "    def load_labels(path):\n",
        "        boxes = []\n",
        "        if not os.path.exists(path):\n",
        "            return torch.zeros((0, 5), dtype=torch.float32)\n",
        "        with open(path, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) != 5:\n",
        "                    continue\n",
        "                cls, xc, yc, w, h = map(float, parts)\n",
        "                boxes.append([int(cls), xc, yc, w, h])\n",
        "        return torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0,5), dtype=torch.float32)\n",
        "\n",
        "# --- Paths (replace with your dataset paths) ---\n",
        "\n",
        "base_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels\"\n",
        "train_input_dir = f\"{base_dir}/train_input\"\n",
        "train_input_aug_dir = f\"{base_dir}/train_input_aug\"\n",
        "train_target_dir = f\"{base_dir}/train\"\n",
        "\n",
        "# --- Create train dataset by concatenating normal and augmented ---\n",
        "\n",
        "train_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(train_input_dir, train_target_dir),\n",
        "    FramePlacementDataset(train_input_aug_dir, train_target_dir)\n",
        "])\n",
        "\n",
        "# --- Custom collate_fn to handle variable length tensors ---\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # batch is list of tuples (X, Y)\n",
        "    # Return as tuple of lists, no stacking to avoid size mismatch\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "# --- Worker number finder ---\n",
        "\n",
        "def find_best_num_workers(dataset, batch_size=1, max_workers=8):\n",
        "    results = {}\n",
        "    max_test_workers = min(max_workers, os.cpu_count() or 4)\n",
        "    print(f\"Testing num_workers in [0, ..., {max_test_workers}]\")\n",
        "\n",
        "    for workers in range(max_test_workers + 1):\n",
        "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=workers, pin_memory=torch.cuda.is_available(),\n",
        "                            collate_fn=collate_fn)\n",
        "        start = time.time()\n",
        "        # Iterate once over full loader to time\n",
        "        for _ in loader:\n",
        "            pass\n",
        "        elapsed = time.time() - start\n",
        "        results[workers] = elapsed\n",
        "        print(f\"num_workers={workers} took {elapsed:.2f} seconds\")\n",
        "\n",
        "    best_workers = min(results, key=results.get)\n",
        "    print(f\"Best num_workers: {best_workers} with time {results[best_workers]:.2f}s\")\n",
        "    return best_workers\n",
        "\n",
        "# --- Example usage ---\n",
        "\n",
        "batch_size = 4\n",
        "best_num_workers = find_best_num_workers(train_dataset, batch_size=batch_size, max_workers=8)\n",
        "print(f\"Use num_workers={best_num_workers} in your DataLoader for optimal performance.\")\n",
        "\n",
        "# --- Create final DataLoader with best num_workers ---\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=best_num_workers, pin_memory=torch.cuda.is_available(),\n",
        "                          collate_fn=collate_fn)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "w9EHe1qxX678",
        "outputId": "d00f0528-3b12-425e-bf9d-fbec6a113619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing num_workers in [0, ..., 2]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-496697709.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mbest_num_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_num_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Use num_workers={best_num_workers} in your DataLoader for optimal performance.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-496697709.py\u001b[0m in \u001b[0;36mfind_best_num_workers\u001b[0;34m(dataset, batch_size, max_workers)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Iterate once over full loader to time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-496697709.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtarget_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_aug.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-496697709.py\u001b[0m in \u001b[0;36mload_labels\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, WeightedRandomSampler\n",
        "import itertools\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from contextlib import nullcontext\n",
        "import matplotlib.patches as patches\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "# === Dataset and label loading ===\n",
        "\n",
        "def load_labels(path):\n",
        "    boxes = []\n",
        "    if not os.path.exists(path):\n",
        "        return torch.zeros((0,5), dtype=torch.float32)\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "            cls, xc, yc, w, h = map(float, parts)\n",
        "            boxes.append([int(cls), xc, yc, w, h])\n",
        "    return torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0,5), dtype=torch.float32)\n",
        "\n",
        "class FramePlacementDataset(Dataset):\n",
        "    def __init__(self, input_dir, target_dir):\n",
        "        self.input_dir = input_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.files = [f for f in os.listdir(input_dir) if f.endswith(\".txt\")]\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]\n",
        "        target_fname = fname.replace(\"_aug.txt\", \".txt\")\n",
        "        X = load_labels(os.path.join(self.input_dir, fname))\n",
        "        Y = load_labels(os.path.join(self.target_dir, target_fname))\n",
        "        return X, Y\n",
        "\n",
        "def encode_input_objects(boxes, num_classes=12):\n",
        "    feats = []\n",
        "    for b in boxes:\n",
        "        cls, xc, yc, w, h = b\n",
        "        onehot = F.one_hot(torch.tensor(int(cls)), num_classes=num_classes)\n",
        "        feats.append(torch.cat([onehot.float(), torch.tensor([xc, yc, w, h])]))\n",
        "    if feats:\n",
        "        return torch.stack(feats)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def encode_target_class11(boxes):\n",
        "    class11_boxes = boxes[boxes[:, 0] == 11][:, 1:]\n",
        "    if class11_boxes.shape[0] == 0:\n",
        "        return None\n",
        "    return class11_boxes.float()\n",
        "\n",
        "# === Loss functions ===\n",
        "\n",
        "def iou_loss(pred_boxes, target_boxes, eps=1e-6):\n",
        "    pred_xy1 = pred_boxes[:, :2] - pred_boxes[:, 2:] / 2\n",
        "    pred_xy2 = pred_boxes[:, :2] + pred_boxes[:, 2:] / 2\n",
        "    target_xy1 = target_boxes[:, :2] - target_boxes[:, 2:] / 2\n",
        "    target_xy2 = target_boxes[:, :2] + target_boxes[:, 2:] / 2\n",
        "\n",
        "    inter_min = torch.max(pred_xy1, target_xy1)\n",
        "    inter_max = torch.min(pred_xy2, target_xy2)\n",
        "    inter_wh = (inter_max - inter_min).clamp(min=0)\n",
        "    inter_area = inter_wh[:, 0] * inter_wh[:, 1]\n",
        "\n",
        "    pred_area = pred_boxes[:, 2] * pred_boxes[:, 3]\n",
        "    target_area = target_boxes[:, 2] * target_boxes[:, 3]\n",
        "\n",
        "    union_area = pred_area + target_area - inter_area + eps\n",
        "    iou = inter_area / union_area\n",
        "    return 1 - iou.mean()\n",
        "\n",
        "def combined_hungarian_loss(pred_boxes, target_boxes, l1_weight=10.0):\n",
        "    if target_boxes is None or pred_boxes.shape[0] == 0:\n",
        "        return torch.tensor(0., device=pred_boxes.device, requires_grad=True)\n",
        "    cost_matrix = torch.zeros(pred_boxes.shape[0], target_boxes.shape[0], device=pred_boxes.device)\n",
        "    for i, p in enumerate(pred_boxes):\n",
        "        for j, t in enumerate(target_boxes):\n",
        "            iou_comp = 1 - (1 - iou_loss(p.unsqueeze(0), t.unsqueeze(0)))  # IoU itself\n",
        "            l1_comp = F.l1_loss(p, t, reduction='mean')\n",
        "            cost_matrix[i, j] = (1 - iou_comp) + l1_weight * l1_comp\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_matrix.detach().cpu().numpy())\n",
        "    matched_pred = pred_boxes[row_ind]\n",
        "    matched_target = target_boxes[col_ind].to(pred_boxes.device)\n",
        "    return iou_loss(matched_pred, matched_target) + l1_weight * F.l1_loss(matched_pred, matched_target)\n",
        "\n",
        "# === Positional Encoding ===\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=500):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n",
        "\n",
        "# === PaintingsTransformer Model ===\n",
        "\n",
        "class PaintingsTransformer(nn.Module):\n",
        "    def __init__(self, input_dim=16, d_model=64, nhead=4, num_layers=4, dropout=0.2, max_len=100):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.box_head = nn.Linear(d_model, 4)\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.pos_enc(x)\n",
        "        x = self.encoder(x)\n",
        "        bbox_pred = self.box_head(x)\n",
        "        return bbox_pred\n",
        "\n",
        "# === Training/validation loop (with warmup, early stop, mixed precision) ===\n",
        "\n",
        "def get_warmup_scheduler(optimizer, warmup_steps):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step >= warmup_steps:\n",
        "            return 1.0\n",
        "        else:\n",
        "            return float(current_step) / float(max(1, warmup_steps))\n",
        "    return LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "def train_val_loop(model, train_loader, val_loader, epochs, lr, warmup_steps, device):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    warmup_scheduler = get_warmup_scheduler(optimizer, warmup_steps)\n",
        "    plateau_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "    model.to(device)\n",
        "\n",
        "    scaler = GradScaler() if torch.cuda.is_available() else None\n",
        "    autocast_context = autocast if torch.cuda.is_available() else nullcontext\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    patience = 3\n",
        "    trigger_times = 0\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for X, Y in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
        "            optimizer.zero_grad()\n",
        "            batch_loss = 0\n",
        "            for xi, yi in zip(X, Y):\n",
        "                xi_enc = encode_input_objects(xi)\n",
        "                if xi_enc is None:\n",
        "                    continue\n",
        "                xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                yi_enc = encode_target_class11(yi)\n",
        "                if yi_enc is None:\n",
        "                    continue\n",
        "                yi_enc = yi_enc.to(device)\n",
        "                with autocast_context():\n",
        "                    bbox_pred = model(xi_enc).squeeze(0)\n",
        "                    loss = combined_hungarian_loss(bbox_pred, yi_enc)\n",
        "                if loss > 0:\n",
        "                    if scaler is not None:\n",
        "                        scaler.scale(loss).backward()\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "                    else:\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    batch_loss += loss.item()\n",
        "                else:\n",
        "                    batch_loss += loss.item()\n",
        "                if global_step < warmup_steps:\n",
        "                    warmup_scheduler.step()\n",
        "                global_step += 1\n",
        "            train_loss += batch_loss\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X, Y in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
        "                batch_loss = 0\n",
        "                for xi, yi in zip(X, Y):\n",
        "                    xi_enc = encode_input_objects(xi)\n",
        "                    if xi_enc is None:\n",
        "                        continue\n",
        "                    xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                    yi_enc = encode_target_class11(yi)\n",
        "                    if yi_enc is None:\n",
        "                        continue\n",
        "                    yi_enc = yi_enc.to(device)\n",
        "                    with autocast_context():\n",
        "                        bbox_pred = model(xi_enc).squeeze(0)\n",
        "                        loss = combined_hungarian_loss(bbox_pred, yi_enc)\n",
        "                    batch_loss += loss.item()\n",
        "                val_loss += batch_loss\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}: train_loss={train_loss:.6f}, val_loss={val_loss:.6f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            trigger_times = 0\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        if global_step >= warmup_steps:\n",
        "            plateau_scheduler.step(val_loss)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "# === Hyperparameter grid search ===\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "def evaluate_val_loss(model, val_loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for X, Y in val_loader:\n",
        "            for xi, yi in zip(X, Y):\n",
        "                xi_enc = encode_input_objects(xi)\n",
        "                if xi_enc is None:\n",
        "                    continue\n",
        "                xi_enc = xi_enc.unsqueeze(0).to(device)\n",
        "                yi_enc = encode_target_class11(yi)\n",
        "                if yi_enc is None:\n",
        "                    continue\n",
        "                yi_enc = yi_enc.to(device)\n",
        "                bbox_pred = model(xi_enc).squeeze(0)\n",
        "                loss = combined_hungarian_loss(bbox_pred, yi_enc)\n",
        "                total_loss += loss.item()\n",
        "                count += 1\n",
        "    return total_loss / max(count,1)\n",
        "\n",
        "def grid_search(param_grid, train_dataset, val_dataset, device, epochs=3, warmup_steps=100, log_csv_path=\"grid_search_log.csv\"):\n",
        "    keys = list(param_grid.keys())\n",
        "    best_val_loss = float('inf')\n",
        "    best_params = None\n",
        "    best_model_wts = None\n",
        "\n",
        "    def has_class_11(sample):\n",
        "        X, Y = sample\n",
        "        return (Y[:,0] == 11).any().item()\n",
        "\n",
        "    sample_weights = []\n",
        "    for i in range(len(train_dataset)):\n",
        "        sample = train_dataset[i]\n",
        "        sample_weights.append(5.0 if has_class_11(sample) else 1.0) # Oversample class 11 by 5x\n",
        "\n",
        "    sample_weights = torch.DoubleTensor(sample_weights)\n",
        "    train_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "    with open(log_csv_path, mode='w', newline='') as log_file:\n",
        "        writer = csv.writer(log_file)\n",
        "        writer.writerow(keys + [\"val_loss\"])\n",
        "\n",
        "        for values in itertools.product(*param_grid.values()):\n",
        "            params = dict(zip(keys, values))\n",
        "            print(f\"\\nTesting params: {params}\")\n",
        "\n",
        "            train_loader = DataLoader(train_dataset,\n",
        "                                      batch_size=params['batch_size'],\n",
        "                                      sampler=train_sampler,\n",
        "                                      num_workers=2,\n",
        "                                      pin_memory=torch.cuda.is_available(),\n",
        "                                      collate_fn=collate_fn)\n",
        "            val_loader = DataLoader(val_dataset,\n",
        "                                    batch_size=params['batch_size'],\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=2,\n",
        "                                    pin_memory=torch.cuda.is_available(),\n",
        "                                    collate_fn=collate_fn)\n",
        "            model = PaintingsTransformer(input_dim=16, d_model=params['d_model'],\n",
        "                                         nhead=4, num_layers=params['num_layers'], dropout=0.2).to(device)\n",
        "            train_val_loop(model, train_loader, val_loader, epochs=epochs, lr=params['lr'], warmup_steps=warmup_steps, device=device)\n",
        "            val_loss = evaluate_val_loss(model, val_loader, device)\n",
        "            print(f\"Validation loss: {val_loss:.6f}\")\n",
        "            writer.writerow(list(values) + [val_loss])\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_params = params\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(\"\\nBest hyperparameters found:\", best_params)\n",
        "    torch.save(best_model_wts, \"best_model.pth\")\n",
        "    print(\"Best model saved as 'best_model.pth'\")\n",
        "    return best_params, best_model_wts\n",
        "\n",
        "# === Dataset and DataLoader Setup ===\n",
        "\n",
        "base_dir = \"/content/drive/My Drive/SmartSpace/homeobjects-3K/labels\"\n",
        "train_input_dir = f\"{base_dir}/train_input\"\n",
        "train_input_aug_dir = f\"{base_dir}/train_input_aug\"\n",
        "val_input_dir = f\"{base_dir}/val_input\"\n",
        "val_input_aug_dir = f\"{base_dir}/val_input_aug\"\n",
        "train_target_dir = f\"{base_dir}/train\"\n",
        "val_target_dir = f\"{base_dir}/val\"\n",
        "\n",
        "num_workers = 2\n",
        "pin_memory = torch.cuda.is_available()\n",
        "\n",
        "train_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(train_input_dir, train_target_dir),\n",
        "    FramePlacementDataset(train_input_aug_dir, train_target_dir)\n",
        "])\n",
        "val_dataset = ConcatDataset([\n",
        "    FramePlacementDataset(val_input_dir, val_target_dir),\n",
        "    FramePlacementDataset(val_input_aug_dir, val_target_dir)\n",
        "])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "param_grid = {\n",
        "    'lr': [1e-4, 1e-3],\n",
        "    'batch_size': [1, 4],\n",
        "    'num_layers': [3, 4],\n",
        "    'd_model': [64, 128]\n",
        "}\n",
        "\n",
        "# Run grid search to find best hyperparameters\n",
        "best_params, best_weights = grid_search(param_grid, train_dataset, val_dataset, device, epochs=5, warmup_steps=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "pmAF_vQDUCeV",
        "outputId": "d11226ec-d4ab-44e8-f502-5c031d30d4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing params: {'lr': 0.0001, 'batch_size': 1, 'num_layers': 4, 'd_model': 128}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Train]: 100%|| 2601/2601 [02:41<00:00, 16.11it/s]\n",
            "Epoch 1 [Val]: 100%|| 477/477 [00:10<00:00, 46.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5: train_loss=1.878120, val_loss=1.414454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|| 2601/2601 [02:39<00:00, 16.31it/s]\n",
            "Epoch 2 [Val]: 100%|| 477/477 [00:09<00:00, 48.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5: train_loss=1.678628, val_loss=1.345743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Train]: 100%|| 2601/2601 [02:36<00:00, 16.67it/s]\n",
            "Epoch 3 [Val]: 100%|| 477/477 [00:10<00:00, 45.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5: train_loss=1.597626, val_loss=1.169025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Train]:  11%|         | 288/2601 [00:16<02:15, 17.01it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2753752408.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;31m# Run grid search to find best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m \u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2753752408.py\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(param_grid, train_dataset, val_dataset, device, epochs, warmup_steps, log_csv_path)\u001b[0m\n\u001b[1;32m    290\u001b[0m             model = PaintingsTransformer(input_dim=16, d_model=params['d_model'],\n\u001b[1;32m    291\u001b[0m                                          nhead=4, num_layers=params['num_layers'], dropout=0.2).to(device)\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mtrain_val_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_val_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation loss: {val_loss:.6f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2753752408.py\u001b[0m in \u001b[0;36mtrain_val_loop\u001b[0;34m(model, train_loader, val_loader, epochs, lr, warmup_steps, device)\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                             )\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdevice_beta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;31m# Nested if is necessary to bypass jitscript rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}